{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/weather_data_total.csv\")\n",
    "timestamp=200 # timestamp : 반영할 학습 데이터 일 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 생성\n",
    "TARGET = \"max_Temp\"\n",
    "df[\"target\"] = df[TARGET].shift(-1*timestamp)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# 데이터 분할\n",
    "X = df.drop([\"date\",\"target\"], axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "# 50일치 데이터를 보고 1일치 데이터를 예측하는 데이터셋 생성\n",
    "def create_dataset(X, y, time_steps=timestamp):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)\n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 50\n",
    "X_train, y_train = create_dataset(X, y, time_steps)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "# X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "# # y_train과 y_test도 예측하기\n",
    "# y_scaler = MinMaxScaler()\n",
    "# y_train = y_scaler.fit_transform(y_train.reshape(-1, y_train.shape[-1])).reshape(y_train.shape)\n",
    "# y_test = y_scaler.transform(y_test.reshape(-1, y_test.shape[-1])).reshape(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch로 LSTM 모델 구성하기\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "y_test = torch.FloatTensor(y_test)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# 50일치 데이터를 보고 1일치 데이터를 예측하는 모델이므로 input_size는 X.shape[1]\n",
    "model = LSTM(X.shape[1], 64, 2, 1)\n",
    "\n",
    "# 모델 컴파일\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\TEXT_017_220_38\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 275.2408, Test Loss: 173.9606\n",
      "Epoch [2/100], Train Loss: 146.9455, Test Loss: 119.7807\n",
      "Epoch [3/100], Train Loss: 113.5579, Test Loss: 103.8068\n",
      "Epoch [4/100], Train Loss: 102.4295, Test Loss: 99.7399\n",
      "Epoch [5/100], Train Loss: 100.5003, Test Loss: 99.0828\n",
      "Epoch [6/100], Train Loss: 102.7759, Test Loss: 98.8042\n",
      "Epoch [7/100], Train Loss: 96.8871, Test Loss: 91.6477\n",
      "Epoch [8/100], Train Loss: 89.6594, Test Loss: 82.9234\n",
      "Epoch [9/100], Train Loss: 80.1424, Test Loss: 86.8955\n",
      "Epoch [10/100], Train Loss: 72.4136, Test Loss: 70.0149\n",
      "Epoch [11/100], Train Loss: 60.6075, Test Loss: 57.4565\n",
      "Epoch [12/100], Train Loss: 54.4315, Test Loss: 61.7054\n",
      "Epoch [13/100], Train Loss: 54.2489, Test Loss: 53.0423\n",
      "Epoch [14/100], Train Loss: 48.6865, Test Loss: 62.8925\n",
      "Epoch [15/100], Train Loss: 43.7978, Test Loss: 53.4912\n",
      "Epoch [16/100], Train Loss: 41.8894, Test Loss: 44.8732\n",
      "Epoch [17/100], Train Loss: 40.4462, Test Loss: 41.1065\n",
      "Epoch [18/100], Train Loss: 40.2920, Test Loss: 38.8263\n",
      "Epoch [19/100], Train Loss: 37.7773, Test Loss: 38.1556\n",
      "Epoch [20/100], Train Loss: 33.9175, Test Loss: 44.5570\n",
      "Epoch [21/100], Train Loss: 34.1241, Test Loss: 40.6608\n",
      "Epoch [22/100], Train Loss: 36.4478, Test Loss: 36.6065\n",
      "Epoch [23/100], Train Loss: 33.2396, Test Loss: 36.5176\n",
      "Epoch [24/100], Train Loss: 28.8085, Test Loss: 29.8802\n",
      "Epoch [25/100], Train Loss: 24.9847, Test Loss: 26.8227\n",
      "Epoch [26/100], Train Loss: 27.2358, Test Loss: 24.4836\n",
      "Epoch [27/100], Train Loss: 21.3302, Test Loss: 22.4880\n",
      "Epoch [28/100], Train Loss: 20.3122, Test Loss: 21.2241\n",
      "Epoch [29/100], Train Loss: 23.4597, Test Loss: 22.8226\n",
      "Epoch [30/100], Train Loss: 20.6587, Test Loss: 19.4815\n",
      "Epoch [31/100], Train Loss: 20.7031, Test Loss: 20.6869\n",
      "Epoch [32/100], Train Loss: 21.2160, Test Loss: 21.5229\n",
      "Epoch [33/100], Train Loss: 17.8800, Test Loss: 17.4832\n",
      "Epoch [34/100], Train Loss: 15.9730, Test Loss: 15.9002\n",
      "Epoch [35/100], Train Loss: 17.2056, Test Loss: 27.7567\n",
      "Epoch [36/100], Train Loss: 19.4179, Test Loss: 17.4871\n",
      "Epoch [37/100], Train Loss: 18.1469, Test Loss: 21.5300\n",
      "Epoch [38/100], Train Loss: 17.9068, Test Loss: 16.7514\n",
      "Epoch [39/100], Train Loss: 14.3597, Test Loss: 17.2568\n",
      "Epoch [40/100], Train Loss: 13.3862, Test Loss: 17.4750\n",
      "Epoch [41/100], Train Loss: 13.2894, Test Loss: 16.2872\n",
      "Epoch [42/100], Train Loss: 13.4618, Test Loss: 16.5510\n",
      "Epoch [43/100], Train Loss: 14.4828, Test Loss: 18.3714\n",
      "Epoch [44/100], Train Loss: 14.2427, Test Loss: 16.7617\n",
      "Epoch [45/100], Train Loss: 15.6805, Test Loss: 19.6652\n",
      "Epoch [46/100], Train Loss: 14.1789, Test Loss: 16.0474\n",
      "Epoch [47/100], Train Loss: 13.8582, Test Loss: 15.3192\n",
      "Epoch [48/100], Train Loss: 12.6950, Test Loss: 15.1359\n",
      "Epoch [49/100], Train Loss: 12.2617, Test Loss: 16.4177\n",
      "Epoch [50/100], Train Loss: 13.1421, Test Loss: 14.7710\n",
      "Epoch [51/100], Train Loss: 15.0591, Test Loss: 19.7033\n",
      "Epoch [52/100], Train Loss: 14.6752, Test Loss: 18.7831\n",
      "Epoch [53/100], Train Loss: 13.7768, Test Loss: 15.6698\n",
      "Epoch [54/100], Train Loss: 12.5380, Test Loss: 15.3482\n",
      "Epoch [55/100], Train Loss: 12.0629, Test Loss: 15.4143\n",
      "Epoch [56/100], Train Loss: 11.4398, Test Loss: 13.5725\n",
      "Epoch [57/100], Train Loss: 21.1402, Test Loss: 16.1218\n",
      "Epoch [58/100], Train Loss: 16.7165, Test Loss: 16.8016\n",
      "Epoch [59/100], Train Loss: 14.1773, Test Loss: 16.2633\n",
      "Epoch [60/100], Train Loss: 12.4688, Test Loss: 15.4646\n",
      "Epoch [61/100], Train Loss: 11.3007, Test Loss: 15.3143\n",
      "Epoch [62/100], Train Loss: 12.2731, Test Loss: 13.7378\n",
      "Epoch [63/100], Train Loss: 11.4790, Test Loss: 20.5437\n",
      "Epoch [64/100], Train Loss: 15.7855, Test Loss: 17.5947\n",
      "Epoch [65/100], Train Loss: 12.8829, Test Loss: 14.4259\n",
      "Epoch [66/100], Train Loss: 11.2980, Test Loss: 14.6314\n",
      "Epoch [67/100], Train Loss: 10.7283, Test Loss: 15.8541\n",
      "Epoch [68/100], Train Loss: 11.0459, Test Loss: 13.9674\n",
      "Epoch [69/100], Train Loss: 10.1366, Test Loss: 14.2728\n",
      "Epoch [70/100], Train Loss: 10.0081, Test Loss: 14.4203\n",
      "Epoch [71/100], Train Loss: 9.4740, Test Loss: 13.1145\n",
      "Epoch [72/100], Train Loss: 10.1990, Test Loss: 16.8398\n",
      "Epoch [73/100], Train Loss: 10.1916, Test Loss: 13.3103\n",
      "Epoch [74/100], Train Loss: 9.6866, Test Loss: 17.7757\n",
      "Epoch [75/100], Train Loss: 11.5795, Test Loss: 13.2088\n",
      "Epoch [76/100], Train Loss: 9.8361, Test Loss: 14.7131\n",
      "Epoch [77/100], Train Loss: 9.8238, Test Loss: 12.8639\n",
      "Epoch [78/100], Train Loss: 9.4963, Test Loss: 13.8907\n",
      "Epoch [79/100], Train Loss: 9.0114, Test Loss: 12.8714\n",
      "Epoch [80/100], Train Loss: 10.2888, Test Loss: 12.9490\n",
      "Epoch [81/100], Train Loss: 12.6069, Test Loss: 16.5394\n",
      "Epoch [82/100], Train Loss: 10.9981, Test Loss: 14.7426\n",
      "Epoch [83/100], Train Loss: 9.9980, Test Loss: 13.2095\n",
      "Epoch [84/100], Train Loss: 9.1759, Test Loss: 15.2622\n",
      "Epoch [85/100], Train Loss: 9.0508, Test Loss: 12.8432\n",
      "Epoch [86/100], Train Loss: 8.5826, Test Loss: 12.9014\n",
      "Epoch [87/100], Train Loss: 8.3316, Test Loss: 13.0764\n",
      "Epoch [88/100], Train Loss: 8.0921, Test Loss: 13.9500\n",
      "Epoch [89/100], Train Loss: 8.2000, Test Loss: 12.7865\n",
      "Epoch [90/100], Train Loss: 7.9125, Test Loss: 12.8520\n",
      "Epoch [91/100], Train Loss: 7.9077, Test Loss: 12.6712\n",
      "Epoch [92/100], Train Loss: 8.0059, Test Loss: 12.5411\n",
      "Epoch [93/100], Train Loss: 7.7450, Test Loss: 12.0944\n",
      "Epoch [94/100], Train Loss: 9.0729, Test Loss: 13.9069\n",
      "Epoch [95/100], Train Loss: 8.6713, Test Loss: 12.7818\n",
      "Epoch [96/100], Train Loss: 8.4039, Test Loss: 12.5425\n",
      "Epoch [97/100], Train Loss: 7.9002, Test Loss: 13.1059\n",
      "Epoch [98/100], Train Loss: 8.0281, Test Loss: 12.9162\n",
      "Epoch [99/100], Train Loss: 7.9577, Test Loss: 12.3331\n",
      "Epoch [100/100], Train Loss: 7.5474, Test Loss: 11.7675\n"
     ]
    }
   ],
   "source": [
    "# 학습 함수\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output.squeeze(), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "# 평가 함수\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output.squeeze(), target)\n",
    "            running_loss += loss.item()\n",
    "    return running_loss / len(test_loader)\n",
    "\n",
    "# 학습 및 평가\n",
    "num_epochs = 400\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss = evaluate(model, test_loader, criterion, device)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/400], Train Loss: 288.1157, Test Loss: 197.8853\n",
      "Epoch [2/400], Train Loss: 164.1484, Test Loss: 133.6024\n",
      "Epoch [3/400], Train Loss: 121.1246, Test Loss: 107.4496\n",
      "Epoch [4/400], Train Loss: 104.8818, Test Loss: 97.8039\n",
      "Epoch [5/400], Train Loss: 99.6153, Test Loss: 94.8048\n",
      "Epoch [6/400], Train Loss: 98.2819, Test Loss: 94.0603\n",
      "Epoch [7/400], Train Loss: 97.6898, Test Loss: 93.7348\n",
      "Epoch [8/400], Train Loss: 95.3644, Test Loss: 90.4105\n",
      "Epoch [9/400], Train Loss: 90.2365, Test Loss: 82.7591\n",
      "Epoch [10/400], Train Loss: 81.0546, Test Loss: 71.6013\n",
      "Epoch [11/400], Train Loss: 65.0912, Test Loss: 51.8175\n",
      "Epoch [12/400], Train Loss: 53.3124, Test Loss: 43.9513\n",
      "Epoch [13/400], Train Loss: 43.9493, Test Loss: 37.8275\n",
      "Epoch [14/400], Train Loss: 46.3894, Test Loss: 40.4871\n",
      "Epoch [15/400], Train Loss: 40.1643, Test Loss: 35.4212\n",
      "Epoch [16/400], Train Loss: 35.6598, Test Loss: 32.0190\n",
      "Epoch [17/400], Train Loss: 34.4831, Test Loss: 32.4703\n",
      "Epoch [18/400], Train Loss: 30.9081, Test Loss: 27.8724\n",
      "Epoch [19/400], Train Loss: 28.8390, Test Loss: 26.6542\n",
      "Epoch [20/400], Train Loss: 27.9614, Test Loss: 44.4731\n",
      "Epoch [21/400], Train Loss: 28.9562, Test Loss: 26.5658\n",
      "Epoch [22/400], Train Loss: 27.4232, Test Loss: 27.1213\n",
      "Epoch [23/400], Train Loss: 26.6587, Test Loss: 32.2057\n",
      "Epoch [24/400], Train Loss: 26.6109, Test Loss: 24.4302\n",
      "Epoch [25/400], Train Loss: 28.0291, Test Loss: 27.9616\n",
      "Epoch [26/400], Train Loss: 25.8018, Test Loss: 24.2865\n",
      "Epoch [27/400], Train Loss: 24.9921, Test Loss: 29.1282\n",
      "Epoch [28/400], Train Loss: 23.5585, Test Loss: 23.5215\n",
      "Epoch [29/400], Train Loss: 22.6444, Test Loss: 23.4355\n",
      "Epoch [30/400], Train Loss: 22.3526, Test Loss: 22.0499\n",
      "Epoch [31/400], Train Loss: 22.4036, Test Loss: 23.5074\n",
      "Epoch [32/400], Train Loss: 26.0905, Test Loss: 26.9882\n",
      "Epoch [33/400], Train Loss: 23.7460, Test Loss: 25.3331\n",
      "Epoch [34/400], Train Loss: 23.3216, Test Loss: 22.0054\n",
      "Epoch [35/400], Train Loss: 25.8317, Test Loss: 20.4195\n",
      "Epoch [36/400], Train Loss: 19.0361, Test Loss: 17.4587\n",
      "Epoch [37/400], Train Loss: 20.9760, Test Loss: 23.1787\n",
      "Epoch [38/400], Train Loss: 18.4529, Test Loss: 28.3250\n",
      "Epoch [39/400], Train Loss: 22.5726, Test Loss: 19.8735\n",
      "Epoch [40/400], Train Loss: 16.6724, Test Loss: 18.6918\n",
      "Epoch [41/400], Train Loss: 14.7659, Test Loss: 16.7974\n",
      "Epoch [42/400], Train Loss: 12.9384, Test Loss: 22.1179\n",
      "Epoch [43/400], Train Loss: 14.0496, Test Loss: 16.8310\n",
      "Epoch [44/400], Train Loss: 12.2717, Test Loss: 16.6650\n",
      "Epoch [45/400], Train Loss: 12.0180, Test Loss: 16.3937\n",
      "Epoch [46/400], Train Loss: 12.4235, Test Loss: 17.7591\n",
      "Epoch [47/400], Train Loss: 30.2948, Test Loss: 76.8518\n",
      "Epoch [48/400], Train Loss: 36.2934, Test Loss: 33.2749\n",
      "Epoch [49/400], Train Loss: 27.3846, Test Loss: 25.0715\n",
      "Epoch [50/400], Train Loss: 20.3749, Test Loss: 20.7769\n",
      "Epoch [51/400], Train Loss: 52.4464, Test Loss: 44.2763\n",
      "Epoch [52/400], Train Loss: 44.4999, Test Loss: 34.9526\n",
      "Epoch [53/400], Train Loss: 39.5997, Test Loss: 38.1923\n",
      "Epoch [54/400], Train Loss: 35.4737, Test Loss: 33.0326\n",
      "Epoch [55/400], Train Loss: 30.1608, Test Loss: 26.2114\n",
      "Epoch [56/400], Train Loss: 27.1365, Test Loss: 24.0118\n",
      "Epoch [57/400], Train Loss: 25.9656, Test Loss: 20.6197\n",
      "Epoch [58/400], Train Loss: 20.9074, Test Loss: 19.7347\n",
      "Epoch [59/400], Train Loss: 19.7421, Test Loss: 19.3465\n",
      "Epoch [60/400], Train Loss: 17.8293, Test Loss: 20.2658\n",
      "Epoch [61/400], Train Loss: 18.0380, Test Loss: 20.0424\n",
      "Epoch [62/400], Train Loss: 17.7143, Test Loss: 18.5353\n",
      "Epoch [63/400], Train Loss: 16.7410, Test Loss: 18.0382\n",
      "Epoch [64/400], Train Loss: 15.9185, Test Loss: 17.7998\n",
      "Epoch [65/400], Train Loss: 14.8824, Test Loss: 17.9235\n",
      "Epoch [66/400], Train Loss: 16.1191, Test Loss: 19.5400\n",
      "Epoch [67/400], Train Loss: 16.8255, Test Loss: 17.5351\n",
      "Epoch [68/400], Train Loss: 14.6999, Test Loss: 19.6628\n",
      "Epoch [69/400], Train Loss: 13.7343, Test Loss: 15.0037\n",
      "Epoch [70/400], Train Loss: 13.2858, Test Loss: 15.8691\n",
      "Epoch [71/400], Train Loss: 12.3801, Test Loss: 16.4894\n",
      "Epoch [72/400], Train Loss: 14.1953, Test Loss: 16.2779\n",
      "Epoch [73/400], Train Loss: 12.5999, Test Loss: 14.9817\n",
      "Epoch [74/400], Train Loss: 12.0889, Test Loss: 14.7626\n",
      "Epoch [75/400], Train Loss: 11.4784, Test Loss: 15.1701\n",
      "Epoch [76/400], Train Loss: 11.7320, Test Loss: 16.3877\n",
      "Epoch [77/400], Train Loss: 11.7230, Test Loss: 15.3527\n",
      "Epoch [78/400], Train Loss: 11.0531, Test Loss: 16.1611\n",
      "Epoch [79/400], Train Loss: 11.6143, Test Loss: 16.2321\n",
      "Epoch [80/400], Train Loss: 11.0865, Test Loss: 17.4896\n",
      "Epoch [81/400], Train Loss: 11.3574, Test Loss: 14.8003\n",
      "Epoch [82/400], Train Loss: 10.4740, Test Loss: 17.2270\n",
      "Epoch [83/400], Train Loss: 10.3527, Test Loss: 15.5981\n",
      "Epoch [84/400], Train Loss: 10.9898, Test Loss: 15.5940\n",
      "Epoch [85/400], Train Loss: 10.3601, Test Loss: 14.6758\n",
      "Epoch [86/400], Train Loss: 10.4111, Test Loss: 14.8973\n",
      "Epoch [87/400], Train Loss: 10.2031, Test Loss: 14.6952\n",
      "Epoch [88/400], Train Loss: 10.0885, Test Loss: 14.4604\n",
      "Epoch [89/400], Train Loss: 10.1570, Test Loss: 13.6302\n",
      "Epoch [90/400], Train Loss: 9.6088, Test Loss: 14.7397\n",
      "Epoch [91/400], Train Loss: 9.3464, Test Loss: 14.8112\n",
      "Epoch [92/400], Train Loss: 9.7331, Test Loss: 16.5235\n",
      "Epoch [93/400], Train Loss: 9.4425, Test Loss: 14.8974\n",
      "Epoch [94/400], Train Loss: 14.1225, Test Loss: 17.5023\n",
      "Epoch [95/400], Train Loss: 17.7732, Test Loss: 17.6860\n",
      "Epoch [96/400], Train Loss: 16.1821, Test Loss: 16.2341\n",
      "Epoch [97/400], Train Loss: 14.2905, Test Loss: 16.7721\n",
      "Epoch [98/400], Train Loss: 13.3811, Test Loss: 16.2212\n",
      "Epoch [99/400], Train Loss: 11.9394, Test Loss: 15.0499\n",
      "Epoch [100/400], Train Loss: 9.9568, Test Loss: 14.6872\n",
      "Epoch [101/400], Train Loss: 9.6328, Test Loss: 13.8068\n",
      "Epoch [102/400], Train Loss: 9.3830, Test Loss: 15.0653\n",
      "Epoch [103/400], Train Loss: 9.9499, Test Loss: 13.1842\n",
      "Epoch [104/400], Train Loss: 9.3696, Test Loss: 16.0519\n",
      "Epoch [105/400], Train Loss: 9.9680, Test Loss: 14.0930\n",
      "Epoch [106/400], Train Loss: 8.9376, Test Loss: 14.4396\n",
      "Epoch [107/400], Train Loss: 8.6375, Test Loss: 13.8202\n",
      "Epoch [108/400], Train Loss: 8.7670, Test Loss: 14.9520\n",
      "Epoch [109/400], Train Loss: 8.6959, Test Loss: 13.8218\n",
      "Epoch [110/400], Train Loss: 8.2704, Test Loss: 13.3620\n",
      "Epoch [111/400], Train Loss: 8.7305, Test Loss: 13.8141\n",
      "Epoch [112/400], Train Loss: 8.4261, Test Loss: 13.4996\n",
      "Epoch [113/400], Train Loss: 8.8061, Test Loss: 14.3607\n",
      "Epoch [114/400], Train Loss: 8.1542, Test Loss: 13.0096\n",
      "Epoch [115/400], Train Loss: 8.0477, Test Loss: 14.1249\n",
      "Epoch [116/400], Train Loss: 7.9521, Test Loss: 14.3919\n",
      "Epoch [117/400], Train Loss: 8.2150, Test Loss: 13.6393\n",
      "Epoch [118/400], Train Loss: 7.8168, Test Loss: 13.7291\n",
      "Epoch [119/400], Train Loss: 8.1288, Test Loss: 13.1171\n",
      "Epoch [120/400], Train Loss: 8.0255, Test Loss: 13.1301\n",
      "Epoch [121/400], Train Loss: 7.9908, Test Loss: 13.7795\n",
      "Epoch [122/400], Train Loss: 7.1610, Test Loss: 14.9381\n",
      "Epoch [123/400], Train Loss: 7.4365, Test Loss: 14.5154\n",
      "Epoch [124/400], Train Loss: 7.9307, Test Loss: 13.3307\n",
      "Epoch [125/400], Train Loss: 11.4803, Test Loss: 19.9693\n",
      "Epoch [126/400], Train Loss: 13.2585, Test Loss: 22.0003\n",
      "Epoch [127/400], Train Loss: 11.7438, Test Loss: 14.7893\n",
      "Epoch [128/400], Train Loss: 9.0884, Test Loss: 15.4787\n",
      "Epoch [129/400], Train Loss: 10.8166, Test Loss: 15.8859\n",
      "Epoch [130/400], Train Loss: 8.5017, Test Loss: 13.1236\n",
      "Epoch [131/400], Train Loss: 7.6941, Test Loss: 12.4111\n",
      "Epoch [132/400], Train Loss: 7.7533, Test Loss: 12.8608\n",
      "Epoch [133/400], Train Loss: 7.7045, Test Loss: 14.0988\n",
      "Epoch [134/400], Train Loss: 9.3972, Test Loss: 11.9989\n",
      "Epoch [135/400], Train Loss: 8.0902, Test Loss: 13.4981\n",
      "Epoch [136/400], Train Loss: 7.7440, Test Loss: 12.6013\n",
      "Epoch [137/400], Train Loss: 7.1667, Test Loss: 13.3478\n",
      "Epoch [138/400], Train Loss: 7.0724, Test Loss: 13.0798\n",
      "Epoch [139/400], Train Loss: 7.2871, Test Loss: 14.0729\n",
      "Epoch [140/400], Train Loss: 7.1262, Test Loss: 12.1480\n",
      "Epoch [141/400], Train Loss: 6.7883, Test Loss: 12.7216\n",
      "Epoch [142/400], Train Loss: 6.6843, Test Loss: 13.4977\n",
      "Epoch [143/400], Train Loss: 6.8807, Test Loss: 13.0874\n",
      "Epoch [144/400], Train Loss: 6.5336, Test Loss: 13.1320\n",
      "Epoch [145/400], Train Loss: 6.7060, Test Loss: 12.5002\n",
      "Epoch [146/400], Train Loss: 6.3884, Test Loss: 12.6626\n",
      "Epoch [147/400], Train Loss: 6.2933, Test Loss: 11.8596\n",
      "Epoch [148/400], Train Loss: 6.2985, Test Loss: 11.9712\n",
      "Epoch [149/400], Train Loss: 5.9520, Test Loss: 12.2964\n",
      "Epoch [150/400], Train Loss: 5.9386, Test Loss: 12.1576\n",
      "Epoch [151/400], Train Loss: 5.8014, Test Loss: 11.9046\n",
      "Epoch [152/400], Train Loss: 5.8320, Test Loss: 12.4994\n",
      "Epoch [153/400], Train Loss: 13.9785, Test Loss: 20.0115\n",
      "Epoch [154/400], Train Loss: 29.1327, Test Loss: 20.7979\n",
      "Epoch [155/400], Train Loss: 17.3368, Test Loss: 16.1351\n",
      "Epoch [156/400], Train Loss: 12.5365, Test Loss: 16.0286\n",
      "Epoch [157/400], Train Loss: 13.2554, Test Loss: 18.5135\n",
      "Epoch [158/400], Train Loss: 11.8876, Test Loss: 15.3273\n",
      "Epoch [159/400], Train Loss: 9.1798, Test Loss: 15.2322\n",
      "Epoch [160/400], Train Loss: 8.5474, Test Loss: 13.9369\n",
      "Epoch [161/400], Train Loss: 7.4643, Test Loss: 13.8205\n",
      "Epoch [162/400], Train Loss: 7.3583, Test Loss: 13.4020\n",
      "Epoch [163/400], Train Loss: 7.3427, Test Loss: 13.0094\n",
      "Epoch [164/400], Train Loss: 7.4339, Test Loss: 13.2825\n",
      "Epoch [165/400], Train Loss: 6.8339, Test Loss: 13.5461\n",
      "Epoch [166/400], Train Loss: 6.7494, Test Loss: 12.8495\n",
      "Epoch [167/400], Train Loss: 7.0063, Test Loss: 12.8853\n",
      "Epoch [168/400], Train Loss: 6.6646, Test Loss: 12.9919\n",
      "Epoch [169/400], Train Loss: 8.0084, Test Loss: 12.8635\n",
      "Epoch [170/400], Train Loss: 6.4873, Test Loss: 13.0754\n",
      "Epoch [171/400], Train Loss: 5.9570, Test Loss: 12.2142\n",
      "Epoch [172/400], Train Loss: 6.1851, Test Loss: 11.7712\n",
      "Epoch [173/400], Train Loss: 5.7220, Test Loss: 13.6256\n",
      "Epoch [174/400], Train Loss: 5.6155, Test Loss: 12.8768\n",
      "Epoch [175/400], Train Loss: 5.4900, Test Loss: 11.8495\n",
      "Epoch [176/400], Train Loss: 5.6001, Test Loss: 13.6733\n",
      "Epoch [177/400], Train Loss: 6.0695, Test Loss: 12.6498\n",
      "Epoch [178/400], Train Loss: 6.8654, Test Loss: 14.6314\n",
      "Epoch [179/400], Train Loss: 5.8969, Test Loss: 12.3526\n",
      "Epoch [180/400], Train Loss: 5.7583, Test Loss: 13.0365\n",
      "Epoch [181/400], Train Loss: 5.4364, Test Loss: 12.6792\n",
      "Epoch [182/400], Train Loss: 5.2518, Test Loss: 13.4167\n",
      "Epoch [183/400], Train Loss: 4.9705, Test Loss: 12.1106\n",
      "Epoch [184/400], Train Loss: 4.9186, Test Loss: 13.4401\n",
      "Epoch [185/400], Train Loss: 4.9652, Test Loss: 11.3974\n",
      "Epoch [186/400], Train Loss: 4.9034, Test Loss: 12.1624\n",
      "Epoch [187/400], Train Loss: 4.7902, Test Loss: 12.4732\n",
      "Epoch [188/400], Train Loss: 4.8178, Test Loss: 12.2048\n",
      "Epoch [189/400], Train Loss: 4.8161, Test Loss: 11.1416\n",
      "Epoch [190/400], Train Loss: 4.9840, Test Loss: 12.6008\n",
      "Epoch [191/400], Train Loss: 4.7399, Test Loss: 11.3499\n",
      "Epoch [192/400], Train Loss: 4.4466, Test Loss: 11.3267\n",
      "Epoch [193/400], Train Loss: 4.2100, Test Loss: 11.9896\n",
      "Epoch [194/400], Train Loss: 4.4000, Test Loss: 11.5554\n",
      "Epoch [195/400], Train Loss: 4.2162, Test Loss: 11.7706\n",
      "Epoch [196/400], Train Loss: 5.0873, Test Loss: 20.5519\n",
      "Epoch [197/400], Train Loss: 21.3606, Test Loss: 25.0438\n",
      "Epoch [198/400], Train Loss: 16.0936, Test Loss: 13.2914\n",
      "Epoch [199/400], Train Loss: 7.8131, Test Loss: 13.7540\n",
      "Epoch [200/400], Train Loss: 6.5165, Test Loss: 12.7709\n",
      "Epoch [201/400], Train Loss: 5.9481, Test Loss: 13.4361\n",
      "Epoch [202/400], Train Loss: 5.1580, Test Loss: 12.5535\n",
      "Epoch [203/400], Train Loss: 5.0121, Test Loss: 13.9237\n",
      "Epoch [204/400], Train Loss: 5.0417, Test Loss: 12.8999\n",
      "Epoch [205/400], Train Loss: 4.6373, Test Loss: 12.4854\n",
      "Epoch [206/400], Train Loss: 4.3114, Test Loss: 12.4559\n",
      "Epoch [207/400], Train Loss: 4.3591, Test Loss: 12.9383\n",
      "Epoch [208/400], Train Loss: 4.5695, Test Loss: 12.8239\n",
      "Epoch [209/400], Train Loss: 4.1094, Test Loss: 12.7272\n",
      "Epoch [210/400], Train Loss: 4.0559, Test Loss: 12.4537\n",
      "Epoch [211/400], Train Loss: 4.2309, Test Loss: 12.7115\n",
      "Epoch [212/400], Train Loss: 3.9858, Test Loss: 12.5099\n",
      "Epoch [213/400], Train Loss: 3.7620, Test Loss: 13.1556\n",
      "Epoch [214/400], Train Loss: 3.9192, Test Loss: 13.1267\n",
      "Epoch [215/400], Train Loss: 4.0435, Test Loss: 11.8929\n",
      "Epoch [216/400], Train Loss: 4.0128, Test Loss: 13.5890\n",
      "Epoch [217/400], Train Loss: 4.3805, Test Loss: 12.7161\n",
      "Epoch [218/400], Train Loss: 3.9884, Test Loss: 11.6597\n",
      "Epoch [219/400], Train Loss: 3.6016, Test Loss: 12.5981\n",
      "Epoch [220/400], Train Loss: 3.5978, Test Loss: 12.6103\n",
      "Epoch [221/400], Train Loss: 3.4891, Test Loss: 12.5178\n",
      "Epoch [222/400], Train Loss: 3.6102, Test Loss: 13.1037\n",
      "Epoch [223/400], Train Loss: 4.2682, Test Loss: 13.1760\n",
      "Epoch [224/400], Train Loss: 3.9555, Test Loss: 14.0482\n",
      "Epoch [225/400], Train Loss: 3.6615, Test Loss: 12.8288\n",
      "Epoch [226/400], Train Loss: 4.7051, Test Loss: 13.1300\n",
      "Epoch [227/400], Train Loss: 4.0982, Test Loss: 13.0729\n",
      "Epoch [228/400], Train Loss: 3.3688, Test Loss: 12.4254\n",
      "Epoch [229/400], Train Loss: 3.4298, Test Loss: 12.4493\n",
      "Epoch [230/400], Train Loss: 3.2831, Test Loss: 11.8501\n",
      "Epoch [231/400], Train Loss: 3.7088, Test Loss: 12.7813\n",
      "Epoch [232/400], Train Loss: 3.0318, Test Loss: 12.7351\n",
      "Epoch [233/400], Train Loss: 3.1358, Test Loss: 12.5396\n",
      "Epoch [234/400], Train Loss: 3.2528, Test Loss: 12.4148\n",
      "Epoch [235/400], Train Loss: 3.0964, Test Loss: 12.1899\n",
      "Epoch [236/400], Train Loss: 2.9788, Test Loss: 13.1244\n",
      "Epoch [237/400], Train Loss: 3.2640, Test Loss: 12.3129\n",
      "Epoch [238/400], Train Loss: 3.0230, Test Loss: 13.8139\n",
      "Epoch [239/400], Train Loss: 3.0219, Test Loss: 11.6024\n",
      "Epoch [240/400], Train Loss: 2.8213, Test Loss: 12.3147\n",
      "Epoch [241/400], Train Loss: 3.4517, Test Loss: 12.9314\n",
      "Epoch [242/400], Train Loss: 4.0913, Test Loss: 12.7438\n",
      "Epoch [243/400], Train Loss: 3.2704, Test Loss: 11.5183\n",
      "Epoch [244/400], Train Loss: 3.0948, Test Loss: 12.1764\n",
      "Epoch [245/400], Train Loss: 2.7960, Test Loss: 12.3858\n",
      "Epoch [246/400], Train Loss: 3.1829, Test Loss: 11.9884\n",
      "Epoch [247/400], Train Loss: 2.8406, Test Loss: 11.6065\n",
      "Epoch [248/400], Train Loss: 2.7502, Test Loss: 11.9789\n",
      "Epoch [249/400], Train Loss: 2.5540, Test Loss: 12.4649\n",
      "Epoch [250/400], Train Loss: 2.3220, Test Loss: 11.7069\n",
      "Epoch [251/400], Train Loss: 2.5048, Test Loss: 12.6474\n",
      "Epoch [252/400], Train Loss: 2.8236, Test Loss: 13.5401\n",
      "Epoch [253/400], Train Loss: 2.7676, Test Loss: 11.3130\n",
      "Epoch [254/400], Train Loss: 3.3359, Test Loss: 12.3949\n",
      "Epoch [255/400], Train Loss: 2.6329, Test Loss: 12.2522\n",
      "Epoch [256/400], Train Loss: 3.2911, Test Loss: 13.1429\n",
      "Epoch [257/400], Train Loss: 15.2797, Test Loss: 37.5988\n",
      "Epoch [258/400], Train Loss: 43.9430, Test Loss: 43.8695\n",
      "Epoch [259/400], Train Loss: 26.1916, Test Loss: 20.4511\n",
      "Epoch [260/400], Train Loss: 17.4784, Test Loss: 17.9020\n",
      "Epoch [261/400], Train Loss: 14.6462, Test Loss: 17.4099\n",
      "Epoch [262/400], Train Loss: 12.9211, Test Loss: 18.7261\n",
      "Epoch [263/400], Train Loss: 12.5892, Test Loss: 19.0955\n",
      "Epoch [264/400], Train Loss: 12.5079, Test Loss: 17.2958\n",
      "Epoch [265/400], Train Loss: 11.6126, Test Loss: 17.9365\n",
      "Epoch [266/400], Train Loss: 10.4648, Test Loss: 16.4713\n",
      "Epoch [267/400], Train Loss: 9.2674, Test Loss: 16.8300\n",
      "Epoch [268/400], Train Loss: 8.6977, Test Loss: 16.0614\n",
      "Epoch [269/400], Train Loss: 8.3538, Test Loss: 14.9392\n",
      "Epoch [270/400], Train Loss: 7.6934, Test Loss: 15.7441\n",
      "Epoch [271/400], Train Loss: 7.4881, Test Loss: 16.9725\n",
      "Epoch [272/400], Train Loss: 7.5238, Test Loss: 14.6243\n",
      "Epoch [273/400], Train Loss: 6.7687, Test Loss: 14.6880\n",
      "Epoch [274/400], Train Loss: 6.9155, Test Loss: 14.4400\n",
      "Epoch [275/400], Train Loss: 6.1923, Test Loss: 14.4251\n",
      "Epoch [276/400], Train Loss: 6.0665, Test Loss: 15.3257\n",
      "Epoch [277/400], Train Loss: 5.7186, Test Loss: 13.4124\n",
      "Epoch [278/400], Train Loss: 5.7102, Test Loss: 14.3467\n",
      "Epoch [279/400], Train Loss: 5.1266, Test Loss: 13.6587\n",
      "Epoch [280/400], Train Loss: 5.5788, Test Loss: 14.4068\n",
      "Epoch [281/400], Train Loss: 5.0195, Test Loss: 13.3460\n",
      "Epoch [282/400], Train Loss: 4.5785, Test Loss: 13.6874\n",
      "Epoch [283/400], Train Loss: 4.4974, Test Loss: 13.8614\n",
      "Epoch [284/400], Train Loss: 4.4622, Test Loss: 15.3476\n",
      "Epoch [285/400], Train Loss: 4.5404, Test Loss: 14.6696\n",
      "Epoch [286/400], Train Loss: 4.4288, Test Loss: 14.5055\n",
      "Epoch [287/400], Train Loss: 4.1916, Test Loss: 13.6527\n",
      "Epoch [288/400], Train Loss: 3.9550, Test Loss: 13.9420\n",
      "Epoch [289/400], Train Loss: 4.9618, Test Loss: 16.8804\n",
      "Epoch [290/400], Train Loss: 4.3723, Test Loss: 13.4329\n",
      "Epoch [291/400], Train Loss: 4.2227, Test Loss: 14.0766\n",
      "Epoch [292/400], Train Loss: 3.6917, Test Loss: 14.1600\n",
      "Epoch [293/400], Train Loss: 3.5573, Test Loss: 13.8365\n",
      "Epoch [294/400], Train Loss: 3.6054, Test Loss: 13.4769\n",
      "Epoch [295/400], Train Loss: 3.5449, Test Loss: 14.3514\n",
      "Epoch [296/400], Train Loss: 3.6642, Test Loss: 13.9127\n",
      "Epoch [297/400], Train Loss: 3.3576, Test Loss: 13.2254\n",
      "Epoch [298/400], Train Loss: 3.4139, Test Loss: 14.2417\n",
      "Epoch [299/400], Train Loss: 3.4884, Test Loss: 15.6973\n",
      "Epoch [300/400], Train Loss: 3.8147, Test Loss: 14.7669\n",
      "Epoch [301/400], Train Loss: 3.2836, Test Loss: 12.8650\n",
      "Epoch [302/400], Train Loss: 3.0018, Test Loss: 13.4497\n",
      "Epoch [303/400], Train Loss: 2.9077, Test Loss: 12.6080\n",
      "Epoch [304/400], Train Loss: 2.8507, Test Loss: 13.5458\n",
      "Epoch [305/400], Train Loss: 3.1864, Test Loss: 13.6856\n",
      "Epoch [306/400], Train Loss: 2.9541, Test Loss: 13.4586\n",
      "Epoch [307/400], Train Loss: 2.9998, Test Loss: 13.5359\n",
      "Epoch [308/400], Train Loss: 2.9857, Test Loss: 12.9097\n",
      "Epoch [309/400], Train Loss: 3.1510, Test Loss: 13.3462\n",
      "Epoch [310/400], Train Loss: 2.7918, Test Loss: 13.2744\n",
      "Epoch [311/400], Train Loss: 2.8548, Test Loss: 12.8540\n",
      "Epoch [312/400], Train Loss: 2.8631, Test Loss: 12.6118\n",
      "Epoch [313/400], Train Loss: 2.9948, Test Loss: 13.2396\n",
      "Epoch [314/400], Train Loss: 2.6560, Test Loss: 14.0728\n",
      "Epoch [315/400], Train Loss: 21.6261, Test Loss: 29.4139\n",
      "Epoch [316/400], Train Loss: 22.7955, Test Loss: 22.3791\n",
      "Epoch [317/400], Train Loss: 15.0403, Test Loss: 22.4314\n",
      "Epoch [318/400], Train Loss: 12.0955, Test Loss: 17.6055\n",
      "Epoch [319/400], Train Loss: 9.7696, Test Loss: 16.0937\n",
      "Epoch [320/400], Train Loss: 8.8697, Test Loss: 16.4808\n",
      "Epoch [321/400], Train Loss: 8.3529, Test Loss: 15.3603\n",
      "Epoch [322/400], Train Loss: 7.6954, Test Loss: 14.8226\n",
      "Epoch [323/400], Train Loss: 6.7105, Test Loss: 14.4018\n",
      "Epoch [324/400], Train Loss: 5.8439, Test Loss: 14.3534\n",
      "Epoch [325/400], Train Loss: 6.0350, Test Loss: 15.4058\n",
      "Epoch [326/400], Train Loss: 5.4574, Test Loss: 14.8441\n",
      "Epoch [327/400], Train Loss: 5.5875, Test Loss: 14.7095\n",
      "Epoch [328/400], Train Loss: 5.5345, Test Loss: 15.1716\n",
      "Epoch [329/400], Train Loss: 4.5340, Test Loss: 15.8071\n",
      "Epoch [330/400], Train Loss: 4.3090, Test Loss: 14.0795\n",
      "Epoch [331/400], Train Loss: 4.2389, Test Loss: 15.8787\n",
      "Epoch [332/400], Train Loss: 4.1276, Test Loss: 14.0040\n",
      "Epoch [333/400], Train Loss: 3.8796, Test Loss: 13.6945\n",
      "Epoch [334/400], Train Loss: 3.4413, Test Loss: 13.9498\n",
      "Epoch [335/400], Train Loss: 3.6174, Test Loss: 14.6914\n",
      "Epoch [336/400], Train Loss: 3.5638, Test Loss: 13.8800\n",
      "Epoch [337/400], Train Loss: 4.2029, Test Loss: 13.9136\n",
      "Epoch [338/400], Train Loss: 3.8564, Test Loss: 14.1019\n",
      "Epoch [339/400], Train Loss: 3.1647, Test Loss: 14.0697\n",
      "Epoch [340/400], Train Loss: 3.2349, Test Loss: 14.2198\n",
      "Epoch [341/400], Train Loss: 2.8960, Test Loss: 13.8373\n",
      "Epoch [342/400], Train Loss: 2.9030, Test Loss: 13.5696\n",
      "Epoch [343/400], Train Loss: 3.1919, Test Loss: 13.2680\n",
      "Epoch [344/400], Train Loss: 2.9633, Test Loss: 13.6016\n",
      "Epoch [345/400], Train Loss: 2.7638, Test Loss: 13.7190\n",
      "Epoch [346/400], Train Loss: 2.8349, Test Loss: 12.5764\n",
      "Epoch [347/400], Train Loss: 2.6197, Test Loss: 12.7124\n",
      "Epoch [348/400], Train Loss: 2.6350, Test Loss: 12.9793\n",
      "Epoch [349/400], Train Loss: 2.8411, Test Loss: 13.7101\n",
      "Epoch [350/400], Train Loss: 2.4440, Test Loss: 12.5016\n",
      "Epoch [351/400], Train Loss: 2.3957, Test Loss: 14.7084\n",
      "Epoch [352/400], Train Loss: 2.6839, Test Loss: 13.9158\n",
      "Epoch [353/400], Train Loss: 2.3900, Test Loss: 12.6075\n",
      "Epoch [354/400], Train Loss: 2.2633, Test Loss: 12.9059\n",
      "Epoch [355/400], Train Loss: 2.2457, Test Loss: 12.8720\n",
      "Epoch [356/400], Train Loss: 2.1525, Test Loss: 12.0524\n",
      "Epoch [357/400], Train Loss: 2.0984, Test Loss: 13.7927\n",
      "Epoch [358/400], Train Loss: 2.2566, Test Loss: 12.8416\n",
      "Epoch [359/400], Train Loss: 2.1600, Test Loss: 13.3455\n",
      "Epoch [360/400], Train Loss: 2.0410, Test Loss: 12.6378\n",
      "Epoch [361/400], Train Loss: 2.1083, Test Loss: 13.7014\n",
      "Epoch [362/400], Train Loss: 2.0374, Test Loss: 13.3514\n",
      "Epoch [363/400], Train Loss: 2.0815, Test Loss: 13.2876\n",
      "Epoch [364/400], Train Loss: 2.0504, Test Loss: 13.1661\n",
      "Epoch [365/400], Train Loss: 2.1825, Test Loss: 12.3213\n",
      "Epoch [366/400], Train Loss: 2.0649, Test Loss: 13.2580\n",
      "Epoch [367/400], Train Loss: 2.0296, Test Loss: 12.5207\n",
      "Epoch [368/400], Train Loss: 2.0334, Test Loss: 13.0099\n",
      "Epoch [369/400], Train Loss: 1.8773, Test Loss: 13.7366\n",
      "Epoch [370/400], Train Loss: 2.0005, Test Loss: 12.8955\n",
      "Epoch [371/400], Train Loss: 1.8955, Test Loss: 13.3818\n",
      "Epoch [372/400], Train Loss: 1.8689, Test Loss: 12.6200\n",
      "Epoch [373/400], Train Loss: 1.8681, Test Loss: 12.1488\n",
      "Epoch [374/400], Train Loss: 1.7628, Test Loss: 12.7702\n",
      "Epoch [375/400], Train Loss: 1.9715, Test Loss: 12.5027\n",
      "Epoch [376/400], Train Loss: 2.2026, Test Loss: 13.1054\n",
      "Epoch [377/400], Train Loss: 1.8512, Test Loss: 12.3885\n",
      "Epoch [378/400], Train Loss: 1.8502, Test Loss: 12.7283\n",
      "Epoch [379/400], Train Loss: 1.9647, Test Loss: 13.1282\n",
      "Epoch [380/400], Train Loss: 1.8833, Test Loss: 12.7492\n",
      "Epoch [381/400], Train Loss: 3.5211, Test Loss: 12.1465\n",
      "Epoch [382/400], Train Loss: 2.4271, Test Loss: 12.7587\n",
      "Epoch [383/400], Train Loss: 1.5669, Test Loss: 12.0944\n",
      "Epoch [384/400], Train Loss: 1.5548, Test Loss: 13.0480\n",
      "Epoch [385/400], Train Loss: 1.5504, Test Loss: 12.6467\n",
      "Epoch [386/400], Train Loss: 1.3746, Test Loss: 12.3285\n",
      "Epoch [387/400], Train Loss: 1.3886, Test Loss: 12.2165\n",
      "Epoch [388/400], Train Loss: 1.6546, Test Loss: 13.2989\n",
      "Epoch [389/400], Train Loss: 2.0316, Test Loss: 14.0360\n",
      "Epoch [390/400], Train Loss: 1.7159, Test Loss: 12.8409\n",
      "Epoch [391/400], Train Loss: 1.4814, Test Loss: 12.6342\n",
      "Epoch [392/400], Train Loss: 1.5867, Test Loss: 12.1433\n",
      "Epoch [393/400], Train Loss: 1.4910, Test Loss: 12.8635\n",
      "Epoch [394/400], Train Loss: 1.5813, Test Loss: 13.1697\n",
      "Epoch [395/400], Train Loss: 1.9339, Test Loss: 12.9888\n",
      "Epoch [396/400], Train Loss: 1.4383, Test Loss: 12.7452\n",
      "Epoch [397/400], Train Loss: 1.3817, Test Loss: 12.9843\n",
      "Epoch [398/400], Train Loss: 1.3635, Test Loss: 12.5945\n",
      "Epoch [399/400], Train Loss: 1.4259, Test Loss: 12.4390\n",
      "Epoch [400/400], Train Loss: 1.3770, Test Loss: 12.2925\n",
      "Epoch [1/400], Train Loss: 125.9600, Test Loss: 118.9857\n",
      "Epoch [2/400], Train Loss: 99.9347, Test Loss: 89.5359\n",
      "Epoch [3/400], Train Loss: 90.4238, Test Loss: 101.9713\n",
      "Epoch [4/400], Train Loss: 82.9571, Test Loss: 68.6334\n",
      "Epoch [5/400], Train Loss: 60.6567, Test Loss: 56.6765\n",
      "Epoch [6/400], Train Loss: 54.1940, Test Loss: 50.4359\n",
      "Epoch [7/400], Train Loss: 48.4710, Test Loss: 56.2381\n",
      "Epoch [8/400], Train Loss: 50.2345, Test Loss: 43.2244\n",
      "Epoch [9/400], Train Loss: 43.3617, Test Loss: 42.2254\n",
      "Epoch [10/400], Train Loss: 33.0130, Test Loss: 39.1438\n",
      "Epoch [11/400], Train Loss: 30.1964, Test Loss: 28.4883\n",
      "Epoch [12/400], Train Loss: 24.6862, Test Loss: 35.5425\n",
      "Epoch [13/400], Train Loss: 37.1011, Test Loss: 28.3601\n",
      "Epoch [14/400], Train Loss: 23.2317, Test Loss: 20.1848\n",
      "Epoch [15/400], Train Loss: 19.7500, Test Loss: 23.8028\n",
      "Epoch [16/400], Train Loss: 20.5888, Test Loss: 24.0480\n",
      "Epoch [17/400], Train Loss: 21.9502, Test Loss: 19.6957\n",
      "Epoch [18/400], Train Loss: 16.9498, Test Loss: 15.8926\n",
      "Epoch [19/400], Train Loss: 16.5572, Test Loss: 20.1807\n",
      "Epoch [20/400], Train Loss: 16.8416, Test Loss: 16.4502\n",
      "Epoch [21/400], Train Loss: 15.9090, Test Loss: 16.7012\n",
      "Epoch [22/400], Train Loss: 15.0571, Test Loss: 17.7038\n",
      "Epoch [23/400], Train Loss: 15.3265, Test Loss: 15.1734\n",
      "Epoch [24/400], Train Loss: 14.8065, Test Loss: 16.0049\n",
      "Epoch [25/400], Train Loss: 14.9618, Test Loss: 15.5730\n",
      "Epoch [26/400], Train Loss: 14.0012, Test Loss: 16.5825\n",
      "Epoch [27/400], Train Loss: 14.5016, Test Loss: 16.5200\n",
      "Epoch [28/400], Train Loss: 14.0814, Test Loss: 17.7495\n",
      "Epoch [29/400], Train Loss: 14.8406, Test Loss: 15.2890\n",
      "Epoch [30/400], Train Loss: 13.6337, Test Loss: 14.8475\n",
      "Epoch [31/400], Train Loss: 13.6763, Test Loss: 14.9851\n",
      "Epoch [32/400], Train Loss: 12.9511, Test Loss: 15.2037\n",
      "Epoch [33/400], Train Loss: 12.6724, Test Loss: 16.0955\n",
      "Epoch [34/400], Train Loss: 12.3335, Test Loss: 16.1938\n",
      "Epoch [35/400], Train Loss: 11.9883, Test Loss: 15.7607\n",
      "Epoch [36/400], Train Loss: 11.4065, Test Loss: 15.7467\n",
      "Epoch [37/400], Train Loss: 12.4028, Test Loss: 14.8075\n",
      "Epoch [38/400], Train Loss: 11.8907, Test Loss: 15.8901\n",
      "Epoch [39/400], Train Loss: 11.2035, Test Loss: 15.2594\n",
      "Epoch [40/400], Train Loss: 11.5315, Test Loss: 16.3896\n",
      "Epoch [41/400], Train Loss: 11.6906, Test Loss: 15.4318\n",
      "Epoch [42/400], Train Loss: 11.2612, Test Loss: 15.2786\n",
      "Epoch [43/400], Train Loss: 10.3113, Test Loss: 14.9086\n",
      "Epoch [44/400], Train Loss: 10.4354, Test Loss: 15.5448\n",
      "Epoch [45/400], Train Loss: 11.6055, Test Loss: 25.3923\n",
      "Epoch [46/400], Train Loss: 13.2187, Test Loss: 16.4860\n",
      "Epoch [47/400], Train Loss: 11.8632, Test Loss: 16.6983\n",
      "Epoch [48/400], Train Loss: 11.0546, Test Loss: 15.3804\n",
      "Epoch [49/400], Train Loss: 9.9694, Test Loss: 15.2357\n",
      "Epoch [50/400], Train Loss: 10.2770, Test Loss: 16.4282\n",
      "Epoch [51/400], Train Loss: 10.4113, Test Loss: 18.3825\n",
      "Epoch [52/400], Train Loss: 16.3923, Test Loss: 32.6645\n",
      "Epoch [53/400], Train Loss: 27.6055, Test Loss: 18.4833\n",
      "Epoch [54/400], Train Loss: 18.3965, Test Loss: 19.2005\n",
      "Epoch [55/400], Train Loss: 20.8385, Test Loss: 31.8687\n",
      "Epoch [56/400], Train Loss: 27.5995, Test Loss: 27.4332\n",
      "Epoch [57/400], Train Loss: 18.3821, Test Loss: 16.7181\n",
      "Epoch [58/400], Train Loss: 14.1202, Test Loss: 15.9192\n",
      "Epoch [59/400], Train Loss: 13.6427, Test Loss: 16.3047\n",
      "Epoch [60/400], Train Loss: 12.2197, Test Loss: 16.3605\n",
      "Epoch [61/400], Train Loss: 12.1800, Test Loss: 15.7402\n",
      "Epoch [62/400], Train Loss: 11.2633, Test Loss: 17.1745\n",
      "Epoch [63/400], Train Loss: 13.0258, Test Loss: 16.4602\n",
      "Epoch [64/400], Train Loss: 11.5819, Test Loss: 18.2794\n",
      "Epoch [65/400], Train Loss: 11.2733, Test Loss: 17.9819\n",
      "Epoch [66/400], Train Loss: 12.6691, Test Loss: 16.1068\n",
      "Epoch [67/400], Train Loss: 11.7421, Test Loss: 16.2896\n",
      "Epoch [68/400], Train Loss: 10.5158, Test Loss: 16.2694\n",
      "Epoch [69/400], Train Loss: 10.3306, Test Loss: 16.6107\n",
      "Epoch [70/400], Train Loss: 9.4909, Test Loss: 15.9599\n",
      "Epoch [71/400], Train Loss: 9.3879, Test Loss: 17.1797\n",
      "Epoch [72/400], Train Loss: 10.4835, Test Loss: 16.9390\n",
      "Epoch [73/400], Train Loss: 9.1404, Test Loss: 16.2482\n",
      "Epoch [74/400], Train Loss: 9.8004, Test Loss: 16.0438\n",
      "Epoch [75/400], Train Loss: 9.0868, Test Loss: 17.5563\n",
      "Epoch [76/400], Train Loss: 11.8069, Test Loss: 20.0690\n",
      "Epoch [77/400], Train Loss: 19.3839, Test Loss: 19.3234\n",
      "Epoch [78/400], Train Loss: 12.6290, Test Loss: 17.5541\n",
      "Epoch [79/400], Train Loss: 10.3493, Test Loss: 17.7003\n",
      "Epoch [80/400], Train Loss: 9.6189, Test Loss: 18.2192\n",
      "Epoch [81/400], Train Loss: 9.3703, Test Loss: 16.1082\n",
      "Epoch [82/400], Train Loss: 9.0948, Test Loss: 17.0398\n",
      "Epoch [83/400], Train Loss: 8.8681, Test Loss: 16.9757\n",
      "Epoch [84/400], Train Loss: 8.5204, Test Loss: 17.1641\n",
      "Epoch [85/400], Train Loss: 8.3408, Test Loss: 17.1524\n",
      "Epoch [86/400], Train Loss: 8.1717, Test Loss: 17.6701\n",
      "Epoch [87/400], Train Loss: 51.4318, Test Loss: 52.6461\n",
      "Epoch [88/400], Train Loss: 45.5932, Test Loss: 36.3192\n",
      "Epoch [89/400], Train Loss: 31.6190, Test Loss: 25.0382\n",
      "Epoch [90/400], Train Loss: 25.4146, Test Loss: 19.4830\n",
      "Epoch [91/400], Train Loss: 17.8943, Test Loss: 17.6013\n",
      "Epoch [92/400], Train Loss: 16.1637, Test Loss: 17.6217\n",
      "Epoch [93/400], Train Loss: 15.2933, Test Loss: 15.4053\n",
      "Epoch [94/400], Train Loss: 14.8184, Test Loss: 16.8932\n",
      "Epoch [95/400], Train Loss: 13.7340, Test Loss: 16.2656\n",
      "Epoch [96/400], Train Loss: 13.8664, Test Loss: 16.0068\n",
      "Epoch [97/400], Train Loss: 12.8543, Test Loss: 15.4395\n",
      "Epoch [98/400], Train Loss: 12.2049, Test Loss: 14.8326\n",
      "Epoch [99/400], Train Loss: 24.4681, Test Loss: 47.4348\n",
      "Epoch [100/400], Train Loss: 31.7009, Test Loss: 24.9623\n",
      "Epoch [101/400], Train Loss: 17.6767, Test Loss: 17.4901\n",
      "Epoch [102/400], Train Loss: 14.3889, Test Loss: 16.8405\n",
      "Epoch [103/400], Train Loss: 13.2684, Test Loss: 16.0846\n",
      "Epoch [104/400], Train Loss: 12.3000, Test Loss: 15.7825\n",
      "Epoch [105/400], Train Loss: 11.9247, Test Loss: 15.6403\n",
      "Epoch [106/400], Train Loss: 11.3852, Test Loss: 16.6877\n",
      "Epoch [107/400], Train Loss: 25.8109, Test Loss: 40.1540\n",
      "Epoch [108/400], Train Loss: 19.0407, Test Loss: 16.7540\n",
      "Epoch [109/400], Train Loss: 13.5843, Test Loss: 16.9115\n",
      "Epoch [110/400], Train Loss: 12.7132, Test Loss: 16.0342\n",
      "Epoch [111/400], Train Loss: 13.6877, Test Loss: 16.2411\n",
      "Epoch [112/400], Train Loss: 12.4123, Test Loss: 15.5608\n",
      "Epoch [113/400], Train Loss: 11.3670, Test Loss: 16.3627\n",
      "Epoch [114/400], Train Loss: 10.8934, Test Loss: 17.0603\n",
      "Epoch [115/400], Train Loss: 10.5148, Test Loss: 15.5832\n",
      "Epoch [116/400], Train Loss: 10.2209, Test Loss: 16.4357\n",
      "Epoch [117/400], Train Loss: 10.0863, Test Loss: 15.7167\n",
      "Epoch [118/400], Train Loss: 9.7828, Test Loss: 16.1267\n",
      "Epoch [119/400], Train Loss: 9.3445, Test Loss: 16.0865\n",
      "Epoch [120/400], Train Loss: 9.4382, Test Loss: 16.0898\n",
      "Epoch [121/400], Train Loss: 9.2412, Test Loss: 16.2600\n",
      "Epoch [122/400], Train Loss: 9.5911, Test Loss: 39.6217\n",
      "Epoch [123/400], Train Loss: 22.3103, Test Loss: 20.2252\n",
      "Epoch [124/400], Train Loss: 12.6969, Test Loss: 17.4149\n",
      "Epoch [125/400], Train Loss: 10.8691, Test Loss: 19.6843\n",
      "Epoch [126/400], Train Loss: 14.2678, Test Loss: 17.6201\n",
      "Epoch [127/400], Train Loss: 10.7379, Test Loss: 17.6868\n",
      "Epoch [128/400], Train Loss: 9.8228, Test Loss: 16.9447\n",
      "Epoch [129/400], Train Loss: 10.4820, Test Loss: 18.5455\n",
      "Epoch [130/400], Train Loss: 10.0071, Test Loss: 17.9961\n",
      "Epoch [131/400], Train Loss: 9.0687, Test Loss: 16.8300\n",
      "Epoch [132/400], Train Loss: 8.7311, Test Loss: 16.5135\n",
      "Epoch [133/400], Train Loss: 8.4296, Test Loss: 15.8540\n",
      "Epoch [134/400], Train Loss: 8.3025, Test Loss: 16.5456\n",
      "Epoch [135/400], Train Loss: 8.1142, Test Loss: 16.7353\n",
      "Epoch [136/400], Train Loss: 7.8006, Test Loss: 16.9227\n",
      "Epoch [137/400], Train Loss: 7.6693, Test Loss: 16.6241\n",
      "Epoch [138/400], Train Loss: 7.3861, Test Loss: 17.2136\n",
      "Epoch [139/400], Train Loss: 7.1899, Test Loss: 16.7997\n",
      "Epoch [140/400], Train Loss: 7.2187, Test Loss: 16.8636\n",
      "Epoch [141/400], Train Loss: 7.0139, Test Loss: 17.1620\n",
      "Epoch [142/400], Train Loss: 6.8732, Test Loss: 16.2501\n",
      "Epoch [143/400], Train Loss: 7.1519, Test Loss: 17.0675\n",
      "Epoch [144/400], Train Loss: 6.6760, Test Loss: 16.4624\n",
      "Epoch [145/400], Train Loss: 6.3609, Test Loss: 16.5676\n",
      "Epoch [146/400], Train Loss: 6.8280, Test Loss: 16.8007\n",
      "Epoch [147/400], Train Loss: 6.4916, Test Loss: 17.3102\n",
      "Epoch [148/400], Train Loss: 6.4240, Test Loss: 17.3381\n",
      "Epoch [149/400], Train Loss: 6.8579, Test Loss: 16.6873\n",
      "Epoch [150/400], Train Loss: 6.1002, Test Loss: 17.8451\n",
      "Epoch [151/400], Train Loss: 6.1411, Test Loss: 16.9044\n",
      "Epoch [152/400], Train Loss: 5.8201, Test Loss: 17.4852\n",
      "Epoch [153/400], Train Loss: 6.2737, Test Loss: 17.6122\n",
      "Epoch [154/400], Train Loss: 5.9646, Test Loss: 18.3993\n",
      "Epoch [155/400], Train Loss: 5.7310, Test Loss: 18.2625\n",
      "Epoch [156/400], Train Loss: 6.0801, Test Loss: 17.2646\n",
      "Epoch [157/400], Train Loss: 5.7780, Test Loss: 17.5409\n",
      "Epoch [158/400], Train Loss: 5.7705, Test Loss: 17.6205\n",
      "Epoch [159/400], Train Loss: 5.2974, Test Loss: 18.1457\n",
      "Epoch [160/400], Train Loss: 5.1827, Test Loss: 17.3912\n",
      "Epoch [161/400], Train Loss: 5.3652, Test Loss: 17.1638\n",
      "Epoch [162/400], Train Loss: 5.1242, Test Loss: 18.2178\n",
      "Epoch [163/400], Train Loss: 4.9507, Test Loss: 18.2117\n",
      "Epoch [164/400], Train Loss: 8.3302, Test Loss: 42.5204\n",
      "Epoch [165/400], Train Loss: 35.6310, Test Loss: 26.2073\n",
      "Epoch [166/400], Train Loss: 26.6653, Test Loss: 35.4177\n",
      "Epoch [167/400], Train Loss: 54.8531, Test Loss: 68.4328\n",
      "Epoch [168/400], Train Loss: 48.9389, Test Loss: 41.9693\n",
      "Epoch [169/400], Train Loss: 32.2540, Test Loss: 64.3748\n",
      "Epoch [170/400], Train Loss: 44.1616, Test Loss: 30.2599\n",
      "Epoch [171/400], Train Loss: 25.2567, Test Loss: 24.7191\n",
      "Epoch [172/400], Train Loss: 17.5420, Test Loss: 21.3393\n",
      "Epoch [173/400], Train Loss: 24.1367, Test Loss: 36.2444\n",
      "Epoch [174/400], Train Loss: 24.1340, Test Loss: 23.6077\n",
      "Epoch [175/400], Train Loss: 17.0695, Test Loss: 20.6379\n",
      "Epoch [176/400], Train Loss: 13.7464, Test Loss: 20.1963\n",
      "Epoch [177/400], Train Loss: 13.1046, Test Loss: 20.4998\n",
      "Epoch [178/400], Train Loss: 11.2845, Test Loss: 19.5271\n",
      "Epoch [179/400], Train Loss: 14.7805, Test Loss: 22.7713\n",
      "Epoch [180/400], Train Loss: 27.3474, Test Loss: 22.8858\n",
      "Epoch [181/400], Train Loss: 18.4193, Test Loss: 18.9429\n",
      "Epoch [182/400], Train Loss: 13.7777, Test Loss: 17.4743\n",
      "Epoch [183/400], Train Loss: 12.8113, Test Loss: 17.8582\n",
      "Epoch [184/400], Train Loss: 11.9445, Test Loss: 17.4932\n",
      "Epoch [185/400], Train Loss: 10.8704, Test Loss: 17.5015\n",
      "Epoch [186/400], Train Loss: 9.9824, Test Loss: 17.9680\n",
      "Epoch [187/400], Train Loss: 9.5916, Test Loss: 17.2035\n",
      "Epoch [188/400], Train Loss: 9.2200, Test Loss: 17.6631\n",
      "Epoch [189/400], Train Loss: 9.0903, Test Loss: 16.8301\n",
      "Epoch [190/400], Train Loss: 8.9810, Test Loss: 17.4404\n",
      "Epoch [191/400], Train Loss: 8.4802, Test Loss: 17.1661\n",
      "Epoch [192/400], Train Loss: 8.0728, Test Loss: 17.0388\n",
      "Epoch [193/400], Train Loss: 8.0596, Test Loss: 17.5677\n",
      "Epoch [194/400], Train Loss: 7.6742, Test Loss: 18.7869\n",
      "Epoch [195/400], Train Loss: 8.0265, Test Loss: 17.5719\n",
      "Epoch [196/400], Train Loss: 7.5421, Test Loss: 17.8350\n",
      "Epoch [197/400], Train Loss: 7.2744, Test Loss: 18.3799\n",
      "Epoch [198/400], Train Loss: 7.0741, Test Loss: 18.2560\n",
      "Epoch [199/400], Train Loss: 6.6298, Test Loss: 16.9840\n",
      "Epoch [200/400], Train Loss: 6.5067, Test Loss: 16.6816\n",
      "Epoch [201/400], Train Loss: 6.4032, Test Loss: 17.3008\n",
      "Epoch [202/400], Train Loss: 6.5313, Test Loss: 17.4911\n",
      "Epoch [203/400], Train Loss: 22.2786, Test Loss: 46.1491\n",
      "Epoch [204/400], Train Loss: 23.1128, Test Loss: 28.0965\n",
      "Epoch [205/400], Train Loss: 14.3767, Test Loss: 20.8326\n",
      "Epoch [206/400], Train Loss: 10.1953, Test Loss: 21.0846\n",
      "Epoch [207/400], Train Loss: 8.9423, Test Loss: 19.6705\n",
      "Epoch [208/400], Train Loss: 8.0163, Test Loss: 19.7922\n",
      "Epoch [209/400], Train Loss: 7.8313, Test Loss: 18.6270\n",
      "Epoch [210/400], Train Loss: 7.4693, Test Loss: 19.1501\n",
      "Epoch [211/400], Train Loss: 6.5607, Test Loss: 19.3381\n",
      "Epoch [212/400], Train Loss: 6.4996, Test Loss: 18.1993\n",
      "Epoch [213/400], Train Loss: 6.1833, Test Loss: 18.5947\n",
      "Epoch [214/400], Train Loss: 6.3477, Test Loss: 17.9003\n",
      "Epoch [215/400], Train Loss: 5.9766, Test Loss: 19.1818\n",
      "Epoch [216/400], Train Loss: 5.9643, Test Loss: 20.3555\n",
      "Epoch [217/400], Train Loss: 5.7308, Test Loss: 18.9217\n",
      "Epoch [218/400], Train Loss: 5.6337, Test Loss: 19.0607\n",
      "Epoch [219/400], Train Loss: 5.4450, Test Loss: 18.3573\n",
      "Epoch [220/400], Train Loss: 5.2136, Test Loss: 19.2772\n",
      "Epoch [221/400], Train Loss: 5.3862, Test Loss: 17.3939\n",
      "Epoch [222/400], Train Loss: 5.0196, Test Loss: 19.0887\n",
      "Epoch [223/400], Train Loss: 4.9646, Test Loss: 18.5568\n",
      "Epoch [224/400], Train Loss: 4.6319, Test Loss: 18.0008\n",
      "Epoch [225/400], Train Loss: 4.9406, Test Loss: 18.1841\n",
      "Epoch [226/400], Train Loss: 4.6013, Test Loss: 18.5787\n",
      "Epoch [227/400], Train Loss: 4.4360, Test Loss: 18.8040\n",
      "Epoch [228/400], Train Loss: 4.5118, Test Loss: 17.8231\n",
      "Epoch [229/400], Train Loss: 4.5185, Test Loss: 18.4599\n",
      "Epoch [230/400], Train Loss: 4.2580, Test Loss: 18.6251\n",
      "Epoch [231/400], Train Loss: 3.9939, Test Loss: 18.0101\n",
      "Epoch [232/400], Train Loss: 3.9084, Test Loss: 17.3922\n",
      "Epoch [233/400], Train Loss: 4.1252, Test Loss: 19.4190\n",
      "Epoch [234/400], Train Loss: 3.9868, Test Loss: 17.5847\n",
      "Epoch [235/400], Train Loss: 3.9687, Test Loss: 18.3357\n",
      "Epoch [236/400], Train Loss: 4.6702, Test Loss: 20.5793\n",
      "Epoch [237/400], Train Loss: 4.8219, Test Loss: 19.9557\n",
      "Epoch [238/400], Train Loss: 4.7020, Test Loss: 18.0659\n",
      "Epoch [239/400], Train Loss: 4.2011, Test Loss: 18.2075\n",
      "Epoch [240/400], Train Loss: 3.8473, Test Loss: 18.1760\n",
      "Epoch [241/400], Train Loss: 3.3793, Test Loss: 17.9820\n",
      "Epoch [242/400], Train Loss: 3.4400, Test Loss: 17.8640\n",
      "Epoch [243/400], Train Loss: 3.7372, Test Loss: 18.0217\n",
      "Epoch [244/400], Train Loss: 4.0490, Test Loss: 20.1067\n",
      "Epoch [245/400], Train Loss: 3.2831, Test Loss: 18.6406\n",
      "Epoch [246/400], Train Loss: 3.4991, Test Loss: 17.9297\n",
      "Epoch [247/400], Train Loss: 3.0226, Test Loss: 19.3470\n",
      "Epoch [248/400], Train Loss: 3.2634, Test Loss: 17.5575\n",
      "Epoch [249/400], Train Loss: 3.6542, Test Loss: 19.8153\n",
      "Epoch [250/400], Train Loss: 4.2796, Test Loss: 17.7637\n",
      "Epoch [251/400], Train Loss: 3.2862, Test Loss: 19.0672\n",
      "Epoch [252/400], Train Loss: 3.2547, Test Loss: 17.3305\n",
      "Epoch [253/400], Train Loss: 2.7908, Test Loss: 17.4985\n",
      "Epoch [254/400], Train Loss: 2.8516, Test Loss: 17.6371\n",
      "Epoch [255/400], Train Loss: 3.4359, Test Loss: 17.4053\n",
      "Epoch [256/400], Train Loss: 2.7872, Test Loss: 17.2890\n",
      "Epoch [257/400], Train Loss: 2.6776, Test Loss: 16.9496\n",
      "Epoch [258/400], Train Loss: 2.7519, Test Loss: 18.1866\n",
      "Epoch [259/400], Train Loss: 2.4635, Test Loss: 17.3321\n",
      "Epoch [260/400], Train Loss: 2.4359, Test Loss: 16.7859\n",
      "Epoch [261/400], Train Loss: 2.5485, Test Loss: 17.2989\n",
      "Epoch [262/400], Train Loss: 2.6756, Test Loss: 17.3175\n",
      "Epoch [263/400], Train Loss: 2.3443, Test Loss: 17.6339\n",
      "Epoch [264/400], Train Loss: 2.3127, Test Loss: 16.9977\n",
      "Epoch [265/400], Train Loss: 2.3473, Test Loss: 17.4624\n",
      "Epoch [266/400], Train Loss: 2.3904, Test Loss: 16.8949\n",
      "Epoch [267/400], Train Loss: 2.1935, Test Loss: 17.0254\n",
      "Epoch [268/400], Train Loss: 2.1789, Test Loss: 17.1491\n",
      "Epoch [269/400], Train Loss: 2.2474, Test Loss: 17.7682\n",
      "Epoch [270/400], Train Loss: 2.3910, Test Loss: 17.3495\n",
      "Epoch [271/400], Train Loss: 1.9028, Test Loss: 17.0864\n",
      "Epoch [272/400], Train Loss: 2.1024, Test Loss: 17.5620\n",
      "Epoch [273/400], Train Loss: 1.8968, Test Loss: 16.8100\n",
      "Epoch [274/400], Train Loss: 1.7833, Test Loss: 17.5129\n",
      "Epoch [275/400], Train Loss: 1.8102, Test Loss: 17.4199\n",
      "Epoch [276/400], Train Loss: 1.7802, Test Loss: 17.6525\n",
      "Epoch [277/400], Train Loss: 1.6807, Test Loss: 17.0669\n",
      "Epoch [278/400], Train Loss: 1.7956, Test Loss: 17.4212\n",
      "Epoch [279/400], Train Loss: 1.6309, Test Loss: 17.5004\n",
      "Epoch [280/400], Train Loss: 1.6794, Test Loss: 17.4132\n",
      "Epoch [281/400], Train Loss: 1.7516, Test Loss: 17.8900\n",
      "Epoch [282/400], Train Loss: 1.6442, Test Loss: 17.1978\n",
      "Epoch [283/400], Train Loss: 1.4960, Test Loss: 17.3477\n",
      "Epoch [284/400], Train Loss: 1.4049, Test Loss: 17.6645\n",
      "Epoch [285/400], Train Loss: 1.4384, Test Loss: 17.8404\n",
      "Epoch [286/400], Train Loss: 1.5548, Test Loss: 17.3603\n",
      "Epoch [287/400], Train Loss: 1.8762, Test Loss: 16.9287\n",
      "Epoch [288/400], Train Loss: 2.0705, Test Loss: 18.5962\n",
      "Epoch [289/400], Train Loss: 1.9309, Test Loss: 16.9883\n",
      "Epoch [290/400], Train Loss: 1.4215, Test Loss: 17.3834\n",
      "Epoch [291/400], Train Loss: 1.6039, Test Loss: 17.7190\n",
      "Epoch [292/400], Train Loss: 1.3591, Test Loss: 16.5800\n",
      "Epoch [293/400], Train Loss: 1.3990, Test Loss: 17.9495\n",
      "Epoch [294/400], Train Loss: 2.7569, Test Loss: 19.4734\n",
      "Epoch [295/400], Train Loss: 3.8465, Test Loss: 18.2578\n",
      "Epoch [296/400], Train Loss: 2.2444, Test Loss: 17.5905\n",
      "Epoch [297/400], Train Loss: 1.7968, Test Loss: 17.5008\n",
      "Epoch [298/400], Train Loss: 1.5309, Test Loss: 17.3875\n",
      "Epoch [299/400], Train Loss: 1.2606, Test Loss: 17.7233\n",
      "Epoch [300/400], Train Loss: 1.0590, Test Loss: 17.6483\n",
      "Epoch [301/400], Train Loss: 1.0069, Test Loss: 17.6026\n",
      "Epoch [302/400], Train Loss: 1.0520, Test Loss: 17.8019\n",
      "Epoch [303/400], Train Loss: 1.0594, Test Loss: 18.1939\n",
      "Epoch [304/400], Train Loss: 1.0230, Test Loss: 17.2375\n",
      "Epoch [305/400], Train Loss: 0.9930, Test Loss: 17.6011\n",
      "Epoch [306/400], Train Loss: 0.8878, Test Loss: 17.2018\n",
      "Epoch [307/400], Train Loss: 0.9537, Test Loss: 17.7304\n",
      "Epoch [308/400], Train Loss: 0.9111, Test Loss: 17.6267\n",
      "Epoch [309/400], Train Loss: 0.8825, Test Loss: 17.2296\n",
      "Epoch [310/400], Train Loss: 0.8645, Test Loss: 18.0155\n",
      "Epoch [311/400], Train Loss: 0.8413, Test Loss: 17.7474\n",
      "Epoch [312/400], Train Loss: 0.8502, Test Loss: 17.8431\n",
      "Epoch [313/400], Train Loss: 0.8288, Test Loss: 17.3270\n",
      "Epoch [314/400], Train Loss: 0.8267, Test Loss: 17.6688\n",
      "Epoch [315/400], Train Loss: 0.9446, Test Loss: 17.5823\n",
      "Epoch [316/400], Train Loss: 1.0460, Test Loss: 17.7785\n",
      "Epoch [317/400], Train Loss: 0.8703, Test Loss: 17.2568\n",
      "Epoch [318/400], Train Loss: 0.8305, Test Loss: 17.2046\n",
      "Epoch [319/400], Train Loss: 0.7022, Test Loss: 17.6914\n",
      "Epoch [320/400], Train Loss: 0.9450, Test Loss: 18.3535\n",
      "Epoch [321/400], Train Loss: 0.8354, Test Loss: 16.9784\n",
      "Epoch [322/400], Train Loss: 0.7766, Test Loss: 17.7466\n",
      "Epoch [323/400], Train Loss: 0.7609, Test Loss: 17.8024\n",
      "Epoch [324/400], Train Loss: 0.7000, Test Loss: 17.9220\n",
      "Epoch [325/400], Train Loss: 0.8310, Test Loss: 17.3501\n",
      "Epoch [326/400], Train Loss: 1.1146, Test Loss: 18.3523\n",
      "Epoch [327/400], Train Loss: 0.8965, Test Loss: 17.3871\n",
      "Epoch [328/400], Train Loss: 0.8232, Test Loss: 17.4496\n",
      "Epoch [329/400], Train Loss: 1.2279, Test Loss: 17.8470\n",
      "Epoch [330/400], Train Loss: 1.0082, Test Loss: 17.2666\n",
      "Epoch [331/400], Train Loss: 0.8675, Test Loss: 17.8131\n",
      "Epoch [332/400], Train Loss: 0.6795, Test Loss: 17.3775\n",
      "Epoch [333/400], Train Loss: 0.7129, Test Loss: 18.1769\n",
      "Epoch [334/400], Train Loss: 0.5716, Test Loss: 18.1061\n",
      "Epoch [335/400], Train Loss: 0.4194, Test Loss: 18.0178\n",
      "Epoch [336/400], Train Loss: 0.4542, Test Loss: 17.6838\n",
      "Epoch [337/400], Train Loss: 0.4150, Test Loss: 17.8623\n",
      "Epoch [338/400], Train Loss: 0.4178, Test Loss: 18.2128\n",
      "Epoch [339/400], Train Loss: 0.4945, Test Loss: 18.6948\n",
      "Epoch [340/400], Train Loss: 0.5871, Test Loss: 18.8452\n",
      "Epoch [341/400], Train Loss: 5.8098, Test Loss: 26.3879\n",
      "Epoch [342/400], Train Loss: 51.9645, Test Loss: 52.3490\n",
      "Epoch [343/400], Train Loss: 32.8122, Test Loss: 27.7953\n",
      "Epoch [344/400], Train Loss: 17.1763, Test Loss: 22.9306\n",
      "Epoch [345/400], Train Loss: 13.2911, Test Loss: 20.4446\n",
      "Epoch [346/400], Train Loss: 15.8596, Test Loss: 37.4265\n",
      "Epoch [347/400], Train Loss: 15.2517, Test Loss: 18.6499\n",
      "Epoch [348/400], Train Loss: 9.9260, Test Loss: 19.2830\n",
      "Epoch [349/400], Train Loss: 8.5756, Test Loss: 20.0508\n",
      "Epoch [350/400], Train Loss: 7.6141, Test Loss: 19.4223\n",
      "Epoch [351/400], Train Loss: 7.2410, Test Loss: 18.7827\n",
      "Epoch [352/400], Train Loss: 6.3102, Test Loss: 18.7108\n",
      "Epoch [353/400], Train Loss: 5.8554, Test Loss: 18.8953\n",
      "Epoch [354/400], Train Loss: 5.6606, Test Loss: 19.2356\n",
      "Epoch [355/400], Train Loss: 5.3361, Test Loss: 19.9643\n",
      "Epoch [356/400], Train Loss: 4.9330, Test Loss: 19.4109\n",
      "Epoch [357/400], Train Loss: 4.6915, Test Loss: 19.6264\n",
      "Epoch [358/400], Train Loss: 4.4261, Test Loss: 18.5523\n",
      "Epoch [359/400], Train Loss: 4.1143, Test Loss: 19.3500\n",
      "Epoch [360/400], Train Loss: 4.0795, Test Loss: 19.0683\n",
      "Epoch [361/400], Train Loss: 3.8503, Test Loss: 20.0317\n",
      "Epoch [362/400], Train Loss: 3.5765, Test Loss: 18.3202\n",
      "Epoch [363/400], Train Loss: 3.3067, Test Loss: 19.5421\n",
      "Epoch [364/400], Train Loss: 3.2211, Test Loss: 18.9633\n",
      "Epoch [365/400], Train Loss: 3.1624, Test Loss: 18.6412\n",
      "Epoch [366/400], Train Loss: 3.1745, Test Loss: 19.6525\n",
      "Epoch [367/400], Train Loss: 3.0835, Test Loss: 18.8012\n",
      "Epoch [368/400], Train Loss: 2.8663, Test Loss: 19.1446\n",
      "Epoch [369/400], Train Loss: 2.7798, Test Loss: 18.8873\n",
      "Epoch [370/400], Train Loss: 5.9319, Test Loss: 25.4957\n",
      "Epoch [371/400], Train Loss: 9.3393, Test Loss: 23.2040\n",
      "Epoch [372/400], Train Loss: 5.2486, Test Loss: 21.1383\n",
      "Epoch [373/400], Train Loss: 4.0014, Test Loss: 19.7424\n",
      "Epoch [374/400], Train Loss: 3.2194, Test Loss: 19.5589\n",
      "Epoch [375/400], Train Loss: 2.8894, Test Loss: 19.2545\n",
      "Epoch [376/400], Train Loss: 2.5931, Test Loss: 19.1715\n",
      "Epoch [377/400], Train Loss: 2.4719, Test Loss: 19.5582\n",
      "Epoch [378/400], Train Loss: 2.2999, Test Loss: 19.7174\n",
      "Epoch [379/400], Train Loss: 2.2127, Test Loss: 19.0297\n",
      "Epoch [380/400], Train Loss: 2.1495, Test Loss: 19.0792\n",
      "Epoch [381/400], Train Loss: 1.9751, Test Loss: 18.9691\n",
      "Epoch [382/400], Train Loss: 1.9044, Test Loss: 19.2155\n",
      "Epoch [383/400], Train Loss: 1.8522, Test Loss: 19.7210\n",
      "Epoch [384/400], Train Loss: 2.0881, Test Loss: 18.6175\n",
      "Epoch [385/400], Train Loss: 1.7514, Test Loss: 19.9967\n",
      "Epoch [386/400], Train Loss: 1.6178, Test Loss: 19.1564\n",
      "Epoch [387/400], Train Loss: 1.4869, Test Loss: 19.3369\n",
      "Epoch [388/400], Train Loss: 4.8282, Test Loss: 23.9164\n",
      "Epoch [389/400], Train Loss: 8.5406, Test Loss: 20.1507\n",
      "Epoch [390/400], Train Loss: 4.6597, Test Loss: 18.9778\n",
      "Epoch [391/400], Train Loss: 3.8011, Test Loss: 19.1818\n",
      "Epoch [392/400], Train Loss: 3.1954, Test Loss: 20.1349\n",
      "Epoch [393/400], Train Loss: 2.4325, Test Loss: 19.2049\n",
      "Epoch [394/400], Train Loss: 2.2236, Test Loss: 19.3362\n",
      "Epoch [395/400], Train Loss: 1.8033, Test Loss: 19.7915\n",
      "Epoch [396/400], Train Loss: 1.7308, Test Loss: 19.6069\n",
      "Epoch [397/400], Train Loss: 1.5693, Test Loss: 19.2375\n",
      "Epoch [398/400], Train Loss: 1.4636, Test Loss: 19.8749\n",
      "Epoch [399/400], Train Loss: 1.4439, Test Loss: 19.0481\n",
      "Epoch [400/400], Train Loss: 1.3246, Test Loss: 18.8644\n",
      "Epoch [1/400], Train Loss: 2860.2342, Test Loss: 2492.8828\n",
      "Epoch [2/400], Train Loss: 2258.2687, Test Loss: 2086.9504\n",
      "Epoch [3/400], Train Loss: 1907.0769, Test Loss: 1772.0512\n",
      "Epoch [4/400], Train Loss: 1609.2308, Test Loss: 1508.3115\n",
      "Epoch [5/400], Train Loss: 1365.7519, Test Loss: 1291.4033\n",
      "Epoch [6/400], Train Loss: 1167.7551, Test Loss: 1111.7599\n",
      "Epoch [7/400], Train Loss: 1003.7561, Test Loss: 962.8512\n",
      "Epoch [8/400], Train Loss: 863.6181, Test Loss: 842.1271\n",
      "Epoch [9/400], Train Loss: 755.7519, Test Loss: 745.0761\n",
      "Epoch [10/400], Train Loss: 668.5515, Test Loss: 668.8116\n",
      "Epoch [11/400], Train Loss: 597.0125, Test Loss: 606.7942\n",
      "Epoch [12/400], Train Loss: 542.1483, Test Loss: 560.8769\n",
      "Epoch [13/400], Train Loss: 497.2616, Test Loss: 525.7643\n",
      "Epoch [14/400], Train Loss: 466.3939, Test Loss: 499.2957\n",
      "Epoch [15/400], Train Loss: 445.7181, Test Loss: 480.4740\n",
      "Epoch [16/400], Train Loss: 425.6208, Test Loss: 465.7253\n",
      "Epoch [17/400], Train Loss: 412.4867, Test Loss: 456.1693\n",
      "Epoch [18/400], Train Loss: 407.1027, Test Loss: 449.8285\n",
      "Epoch [19/400], Train Loss: 398.0204, Test Loss: 444.9431\n",
      "Epoch [20/400], Train Loss: 394.0169, Test Loss: 442.1393\n",
      "Epoch [21/400], Train Loss: 395.0684, Test Loss: 440.3802\n",
      "Epoch [22/400], Train Loss: 390.9373, Test Loss: 438.9779\n",
      "Epoch [23/400], Train Loss: 388.9602, Test Loss: 438.5413\n",
      "Epoch [24/400], Train Loss: 388.6483, Test Loss: 438.2171\n",
      "Epoch [25/400], Train Loss: 390.2969, Test Loss: 437.9592\n",
      "Epoch [26/400], Train Loss: 387.9720, Test Loss: 437.8599\n",
      "Epoch [27/400], Train Loss: 386.8542, Test Loss: 437.8383\n",
      "Epoch [28/400], Train Loss: 387.5878, Test Loss: 437.8447\n",
      "Epoch [29/400], Train Loss: 387.2281, Test Loss: 437.8572\n",
      "Epoch [30/400], Train Loss: 386.9971, Test Loss: 437.8982\n",
      "Epoch [31/400], Train Loss: 387.3248, Test Loss: 437.8793\n",
      "Epoch [32/400], Train Loss: 387.4304, Test Loss: 437.9095\n",
      "Epoch [33/400], Train Loss: 387.0872, Test Loss: 437.9042\n",
      "Epoch [34/400], Train Loss: 386.8866, Test Loss: 437.9432\n",
      "Epoch [35/400], Train Loss: 387.6102, Test Loss: 437.9316\n",
      "Epoch [36/400], Train Loss: 387.2927, Test Loss: 437.9255\n",
      "Epoch [37/400], Train Loss: 386.2593, Test Loss: 437.9839\n",
      "Epoch [38/400], Train Loss: 387.0439, Test Loss: 437.9340\n",
      "Epoch [39/400], Train Loss: 386.8653, Test Loss: 437.9899\n",
      "Epoch [40/400], Train Loss: 388.7257, Test Loss: 437.9363\n",
      "Epoch [41/400], Train Loss: 387.5618, Test Loss: 437.9750\n",
      "Epoch [42/400], Train Loss: 386.5845, Test Loss: 437.9658\n",
      "Epoch [43/400], Train Loss: 387.7133, Test Loss: 437.9039\n",
      "Epoch [44/400], Train Loss: 388.1395, Test Loss: 437.9418\n",
      "Epoch [45/400], Train Loss: 388.7494, Test Loss: 437.9132\n",
      "Epoch [46/400], Train Loss: 388.0229, Test Loss: 437.9505\n",
      "Epoch [47/400], Train Loss: 388.3262, Test Loss: 437.9015\n",
      "Epoch [48/400], Train Loss: 389.3406, Test Loss: 437.7061\n",
      "Epoch [49/400], Train Loss: 388.1154, Test Loss: 438.2560\n",
      "Epoch [50/400], Train Loss: 386.7349, Test Loss: 433.6470\n",
      "Epoch [51/400], Train Loss: 385.1107, Test Loss: 432.7214\n",
      "Epoch [52/400], Train Loss: 383.5862, Test Loss: 430.0212\n",
      "Epoch [53/400], Train Loss: 382.7562, Test Loss: 425.6570\n",
      "Epoch [54/400], Train Loss: 380.5109, Test Loss: 425.1773\n",
      "Epoch [55/400], Train Loss: 380.2829, Test Loss: 423.4842\n",
      "Epoch [56/400], Train Loss: 379.2939, Test Loss: 424.8104\n",
      "Epoch [57/400], Train Loss: 381.3982, Test Loss: 422.0921\n",
      "Epoch [58/400], Train Loss: 378.1584, Test Loss: 420.7314\n",
      "Epoch [59/400], Train Loss: 377.3919, Test Loss: 419.8116\n",
      "Epoch [60/400], Train Loss: 374.7157, Test Loss: 416.9047\n",
      "Epoch [61/400], Train Loss: 376.4108, Test Loss: 418.0253\n",
      "Epoch [62/400], Train Loss: 375.1651, Test Loss: 417.8606\n",
      "Epoch [63/400], Train Loss: 373.0557, Test Loss: 418.5495\n",
      "Epoch [64/400], Train Loss: 373.1141, Test Loss: 416.6105\n",
      "Epoch [65/400], Train Loss: 372.9621, Test Loss: 415.0384\n",
      "Epoch [66/400], Train Loss: 369.9146, Test Loss: 411.9550\n",
      "Epoch [67/400], Train Loss: 368.8351, Test Loss: 418.6237\n",
      "Epoch [68/400], Train Loss: 372.3279, Test Loss: 415.2024\n",
      "Epoch [69/400], Train Loss: 369.0491, Test Loss: 414.4726\n",
      "Epoch [70/400], Train Loss: 365.6316, Test Loss: 412.3541\n",
      "Epoch [71/400], Train Loss: 363.7841, Test Loss: 411.3637\n",
      "Epoch [72/400], Train Loss: 369.5117, Test Loss: 419.9551\n",
      "Epoch [73/400], Train Loss: 367.4803, Test Loss: 412.6810\n",
      "Epoch [74/400], Train Loss: 361.6002, Test Loss: 409.3711\n",
      "Epoch [75/400], Train Loss: 358.1628, Test Loss: 404.8909\n",
      "Epoch [76/400], Train Loss: 357.5673, Test Loss: 404.0237\n",
      "Epoch [77/400], Train Loss: 351.5898, Test Loss: 399.5512\n",
      "Epoch [78/400], Train Loss: 349.9983, Test Loss: 421.1374\n",
      "Epoch [79/400], Train Loss: 347.6631, Test Loss: 397.0698\n",
      "Epoch [80/400], Train Loss: 347.9233, Test Loss: 392.9844\n",
      "Epoch [81/400], Train Loss: 346.3090, Test Loss: 387.6862\n",
      "Epoch [82/400], Train Loss: 335.9195, Test Loss: 382.7992\n",
      "Epoch [83/400], Train Loss: 336.2730, Test Loss: 382.8812\n",
      "Epoch [84/400], Train Loss: 333.0087, Test Loss: 374.8517\n",
      "Epoch [85/400], Train Loss: 329.1251, Test Loss: 376.0358\n",
      "Epoch [86/400], Train Loss: 334.9011, Test Loss: 370.7088\n",
      "Epoch [87/400], Train Loss: 332.3783, Test Loss: 383.1089\n",
      "Epoch [88/400], Train Loss: 327.9864, Test Loss: 375.9814\n",
      "Epoch [89/400], Train Loss: 323.1818, Test Loss: 373.1939\n",
      "Epoch [90/400], Train Loss: 318.1978, Test Loss: 372.0827\n",
      "Epoch [91/400], Train Loss: 318.3538, Test Loss: 367.5117\n",
      "Epoch [92/400], Train Loss: 326.2524, Test Loss: 367.0487\n",
      "Epoch [93/400], Train Loss: 317.9953, Test Loss: 374.4182\n",
      "Epoch [94/400], Train Loss: 319.9520, Test Loss: 398.2903\n",
      "Epoch [95/400], Train Loss: 313.2092, Test Loss: 378.5737\n",
      "Epoch [96/400], Train Loss: 315.4453, Test Loss: 364.6337\n",
      "Epoch [97/400], Train Loss: 311.1449, Test Loss: 362.1504\n",
      "Epoch [98/400], Train Loss: 309.0758, Test Loss: 371.7840\n",
      "Epoch [99/400], Train Loss: 313.0414, Test Loss: 354.0012\n",
      "Epoch [100/400], Train Loss: 304.9207, Test Loss: 352.9359\n",
      "Epoch [101/400], Train Loss: 300.9306, Test Loss: 358.0362\n",
      "Epoch [102/400], Train Loss: 299.5811, Test Loss: 360.1066\n",
      "Epoch [103/400], Train Loss: 300.3348, Test Loss: 355.1140\n",
      "Epoch [104/400], Train Loss: 302.6588, Test Loss: 360.9427\n",
      "Epoch [105/400], Train Loss: 295.3378, Test Loss: 358.2347\n",
      "Epoch [106/400], Train Loss: 301.8921, Test Loss: 362.1004\n",
      "Epoch [107/400], Train Loss: 295.5504, Test Loss: 359.7045\n",
      "Epoch [108/400], Train Loss: 299.9758, Test Loss: 352.3436\n",
      "Epoch [109/400], Train Loss: 285.8414, Test Loss: 348.0587\n",
      "Epoch [110/400], Train Loss: 287.3171, Test Loss: 353.9855\n",
      "Epoch [111/400], Train Loss: 280.0116, Test Loss: 356.1059\n",
      "Epoch [112/400], Train Loss: 293.1363, Test Loss: 350.6921\n",
      "Epoch [113/400], Train Loss: 281.6510, Test Loss: 370.6690\n",
      "Epoch [114/400], Train Loss: 283.9365, Test Loss: 354.1113\n",
      "Epoch [115/400], Train Loss: 275.4149, Test Loss: 366.5176\n",
      "Epoch [116/400], Train Loss: 271.9386, Test Loss: 353.1316\n",
      "Epoch [117/400], Train Loss: 282.6991, Test Loss: 346.0792\n",
      "Epoch [118/400], Train Loss: 280.7269, Test Loss: 346.7301\n",
      "Epoch [119/400], Train Loss: 276.4423, Test Loss: 350.7604\n",
      "Epoch [120/400], Train Loss: 267.1971, Test Loss: 345.7644\n",
      "Epoch [121/400], Train Loss: 275.7622, Test Loss: 352.0892\n",
      "Epoch [122/400], Train Loss: 269.5165, Test Loss: 344.0680\n",
      "Epoch [123/400], Train Loss: 269.6731, Test Loss: 359.2165\n",
      "Epoch [124/400], Train Loss: 263.5583, Test Loss: 346.5550\n",
      "Epoch [125/400], Train Loss: 260.6710, Test Loss: 336.0299\n",
      "Epoch [126/400], Train Loss: 260.0751, Test Loss: 330.0018\n",
      "Epoch [127/400], Train Loss: 265.8537, Test Loss: 339.6325\n",
      "Epoch [128/400], Train Loss: 258.5995, Test Loss: 340.4716\n",
      "Epoch [129/400], Train Loss: 258.6234, Test Loss: 350.7014\n",
      "Epoch [130/400], Train Loss: 252.8456, Test Loss: 332.1726\n",
      "Epoch [131/400], Train Loss: 248.1460, Test Loss: 340.2081\n",
      "Epoch [132/400], Train Loss: 251.3620, Test Loss: 335.8724\n",
      "Epoch [133/400], Train Loss: 247.6684, Test Loss: 328.6893\n",
      "Epoch [134/400], Train Loss: 248.7313, Test Loss: 353.8019\n",
      "Epoch [135/400], Train Loss: 246.6080, Test Loss: 328.4957\n",
      "Epoch [136/400], Train Loss: 244.8257, Test Loss: 368.8932\n",
      "Epoch [137/400], Train Loss: 251.2662, Test Loss: 339.6711\n",
      "Epoch [138/400], Train Loss: 252.2080, Test Loss: 325.0165\n",
      "Epoch [139/400], Train Loss: 244.9176, Test Loss: 337.0920\n",
      "Epoch [140/400], Train Loss: 251.8173, Test Loss: 336.3646\n",
      "Epoch [141/400], Train Loss: 241.8440, Test Loss: 362.0168\n",
      "Epoch [142/400], Train Loss: 233.9469, Test Loss: 360.9331\n",
      "Epoch [143/400], Train Loss: 235.3964, Test Loss: 351.2808\n",
      "Epoch [144/400], Train Loss: 231.7595, Test Loss: 338.1510\n",
      "Epoch [145/400], Train Loss: 235.2681, Test Loss: 354.4123\n",
      "Epoch [146/400], Train Loss: 240.0211, Test Loss: 350.6478\n",
      "Epoch [147/400], Train Loss: 228.7004, Test Loss: 335.1582\n",
      "Epoch [148/400], Train Loss: 230.7180, Test Loss: 352.6101\n",
      "Epoch [149/400], Train Loss: 229.7086, Test Loss: 362.5879\n",
      "Epoch [150/400], Train Loss: 230.2310, Test Loss: 341.7923\n",
      "Epoch [151/400], Train Loss: 229.4255, Test Loss: 337.5340\n",
      "Epoch [152/400], Train Loss: 220.8065, Test Loss: 362.3397\n",
      "Epoch [153/400], Train Loss: 228.7883, Test Loss: 334.8374\n",
      "Epoch [154/400], Train Loss: 218.1848, Test Loss: 336.0814\n",
      "Epoch [155/400], Train Loss: 226.3335, Test Loss: 333.3269\n",
      "Epoch [156/400], Train Loss: 219.5256, Test Loss: 330.8166\n",
      "Epoch [157/400], Train Loss: 218.6688, Test Loss: 335.6125\n",
      "Epoch [158/400], Train Loss: 212.9264, Test Loss: 326.1083\n",
      "Epoch [159/400], Train Loss: 218.0719, Test Loss: 336.7308\n",
      "Epoch [160/400], Train Loss: 218.7259, Test Loss: 351.0911\n",
      "Epoch [161/400], Train Loss: 219.7166, Test Loss: 350.2174\n",
      "Epoch [162/400], Train Loss: 225.7392, Test Loss: 338.3903\n",
      "Epoch [163/400], Train Loss: 212.0225, Test Loss: 347.9806\n",
      "Epoch [164/400], Train Loss: 219.3508, Test Loss: 338.1305\n",
      "Epoch [165/400], Train Loss: 206.3748, Test Loss: 335.8559\n",
      "Epoch [166/400], Train Loss: 211.1817, Test Loss: 343.9291\n",
      "Epoch [167/400], Train Loss: 206.9114, Test Loss: 328.5342\n",
      "Epoch [168/400], Train Loss: 209.3337, Test Loss: 338.3409\n",
      "Epoch [169/400], Train Loss: 202.3975, Test Loss: 332.0130\n",
      "Epoch [170/400], Train Loss: 203.0115, Test Loss: 350.9428\n",
      "Epoch [171/400], Train Loss: 204.0586, Test Loss: 335.4029\n",
      "Epoch [172/400], Train Loss: 197.7709, Test Loss: 334.0095\n",
      "Epoch [173/400], Train Loss: 201.3125, Test Loss: 336.6235\n",
      "Epoch [174/400], Train Loss: 195.8435, Test Loss: 341.4207\n",
      "Epoch [175/400], Train Loss: 196.5372, Test Loss: 334.9798\n",
      "Epoch [176/400], Train Loss: 189.4598, Test Loss: 336.3629\n",
      "Epoch [177/400], Train Loss: 195.8340, Test Loss: 335.8568\n",
      "Epoch [178/400], Train Loss: 185.3864, Test Loss: 330.2920\n",
      "Epoch [179/400], Train Loss: 186.4391, Test Loss: 315.4053\n",
      "Epoch [180/400], Train Loss: 186.5050, Test Loss: 317.3781\n",
      "Epoch [181/400], Train Loss: 187.1653, Test Loss: 327.0534\n",
      "Epoch [182/400], Train Loss: 186.2433, Test Loss: 328.7900\n",
      "Epoch [183/400], Train Loss: 184.1630, Test Loss: 322.9470\n",
      "Epoch [184/400], Train Loss: 187.2288, Test Loss: 327.0705\n",
      "Epoch [185/400], Train Loss: 183.8229, Test Loss: 322.9914\n",
      "Epoch [186/400], Train Loss: 181.4987, Test Loss: 326.4958\n",
      "Epoch [187/400], Train Loss: 180.4814, Test Loss: 324.7726\n",
      "Epoch [188/400], Train Loss: 182.5619, Test Loss: 346.3837\n",
      "Epoch [189/400], Train Loss: 175.4588, Test Loss: 313.6306\n",
      "Epoch [190/400], Train Loss: 178.3921, Test Loss: 321.2958\n",
      "Epoch [191/400], Train Loss: 174.9125, Test Loss: 314.6057\n",
      "Epoch [192/400], Train Loss: 182.8228, Test Loss: 319.3263\n",
      "Epoch [193/400], Train Loss: 171.4339, Test Loss: 317.5035\n",
      "Epoch [194/400], Train Loss: 167.7633, Test Loss: 318.0858\n",
      "Epoch [195/400], Train Loss: 171.2142, Test Loss: 347.0788\n",
      "Epoch [196/400], Train Loss: 166.8126, Test Loss: 319.6924\n",
      "Epoch [197/400], Train Loss: 169.2026, Test Loss: 338.9211\n",
      "Epoch [198/400], Train Loss: 168.3069, Test Loss: 314.8989\n",
      "Epoch [199/400], Train Loss: 167.6990, Test Loss: 335.4568\n",
      "Epoch [200/400], Train Loss: 174.1906, Test Loss: 318.3354\n",
      "Epoch [201/400], Train Loss: 165.6297, Test Loss: 332.6009\n",
      "Epoch [202/400], Train Loss: 156.8854, Test Loss: 332.4880\n",
      "Epoch [203/400], Train Loss: 162.7765, Test Loss: 339.1730\n",
      "Epoch [204/400], Train Loss: 164.6525, Test Loss: 318.6687\n",
      "Epoch [205/400], Train Loss: 161.4736, Test Loss: 323.2233\n",
      "Epoch [206/400], Train Loss: 159.3719, Test Loss: 309.0423\n",
      "Epoch [207/400], Train Loss: 158.2061, Test Loss: 317.5981\n",
      "Epoch [208/400], Train Loss: 157.0171, Test Loss: 329.0607\n",
      "Epoch [209/400], Train Loss: 155.9695, Test Loss: 320.4303\n",
      "Epoch [210/400], Train Loss: 157.9509, Test Loss: 330.7996\n",
      "Epoch [211/400], Train Loss: 156.3484, Test Loss: 322.9611\n",
      "Epoch [212/400], Train Loss: 152.2745, Test Loss: 311.9850\n",
      "Epoch [213/400], Train Loss: 151.0120, Test Loss: 322.3993\n",
      "Epoch [214/400], Train Loss: 155.9034, Test Loss: 320.0793\n",
      "Epoch [215/400], Train Loss: 150.8009, Test Loss: 331.5678\n",
      "Epoch [216/400], Train Loss: 146.1613, Test Loss: 320.3967\n",
      "Epoch [217/400], Train Loss: 227.2937, Test Loss: 351.5118\n",
      "Epoch [218/400], Train Loss: 190.2845, Test Loss: 320.5309\n",
      "Epoch [219/400], Train Loss: 164.8467, Test Loss: 317.9094\n",
      "Epoch [220/400], Train Loss: 160.3425, Test Loss: 321.3323\n",
      "Epoch [221/400], Train Loss: 160.6062, Test Loss: 343.6062\n",
      "Epoch [222/400], Train Loss: 157.3677, Test Loss: 320.9820\n",
      "Epoch [223/400], Train Loss: 155.7885, Test Loss: 315.7259\n",
      "Epoch [224/400], Train Loss: 148.7201, Test Loss: 325.2215\n",
      "Epoch [225/400], Train Loss: 149.5630, Test Loss: 320.3957\n",
      "Epoch [226/400], Train Loss: 146.7843, Test Loss: 312.0223\n",
      "Epoch [227/400], Train Loss: 145.7691, Test Loss: 324.0363\n",
      "Epoch [228/400], Train Loss: 143.2165, Test Loss: 312.0673\n",
      "Epoch [229/400], Train Loss: 143.7994, Test Loss: 329.0554\n",
      "Epoch [230/400], Train Loss: 143.7831, Test Loss: 322.5987\n",
      "Epoch [231/400], Train Loss: 141.8415, Test Loss: 327.8665\n",
      "Epoch [232/400], Train Loss: 140.6968, Test Loss: 332.4961\n",
      "Epoch [233/400], Train Loss: 142.6385, Test Loss: 310.7131\n",
      "Epoch [234/400], Train Loss: 134.4893, Test Loss: 300.6494\n",
      "Epoch [235/400], Train Loss: 134.3137, Test Loss: 327.9367\n",
      "Epoch [236/400], Train Loss: 143.7926, Test Loss: 307.4131\n",
      "Epoch [237/400], Train Loss: 134.0069, Test Loss: 304.4622\n",
      "Epoch [238/400], Train Loss: 133.2011, Test Loss: 330.3665\n",
      "Epoch [239/400], Train Loss: 136.1550, Test Loss: 314.7952\n",
      "Epoch [240/400], Train Loss: 135.0374, Test Loss: 323.6631\n",
      "Epoch [241/400], Train Loss: 132.3245, Test Loss: 336.1914\n",
      "Epoch [242/400], Train Loss: 130.1380, Test Loss: 317.9993\n",
      "Epoch [243/400], Train Loss: 130.7869, Test Loss: 325.4812\n",
      "Epoch [244/400], Train Loss: 131.3252, Test Loss: 310.0705\n",
      "Epoch [245/400], Train Loss: 127.3950, Test Loss: 313.3146\n",
      "Epoch [246/400], Train Loss: 124.6818, Test Loss: 297.4645\n",
      "Epoch [247/400], Train Loss: 123.8862, Test Loss: 298.3325\n",
      "Epoch [248/400], Train Loss: 125.9824, Test Loss: 317.5337\n",
      "Epoch [249/400], Train Loss: 119.9752, Test Loss: 315.2957\n",
      "Epoch [250/400], Train Loss: 124.2400, Test Loss: 307.5976\n",
      "Epoch [251/400], Train Loss: 128.7240, Test Loss: 303.6471\n",
      "Epoch [252/400], Train Loss: 124.0720, Test Loss: 316.4595\n",
      "Epoch [253/400], Train Loss: 118.2949, Test Loss: 301.1752\n",
      "Epoch [254/400], Train Loss: 119.2392, Test Loss: 311.9678\n",
      "Epoch [255/400], Train Loss: 120.6245, Test Loss: 290.4920\n",
      "Epoch [256/400], Train Loss: 117.2154, Test Loss: 308.1704\n",
      "Epoch [257/400], Train Loss: 112.0479, Test Loss: 319.1345\n",
      "Epoch [258/400], Train Loss: 115.3683, Test Loss: 299.7712\n",
      "Epoch [259/400], Train Loss: 123.4897, Test Loss: 314.0214\n",
      "Epoch [260/400], Train Loss: 113.4683, Test Loss: 297.8054\n",
      "Epoch [261/400], Train Loss: 120.7117, Test Loss: 302.1285\n",
      "Epoch [262/400], Train Loss: 111.3430, Test Loss: 304.4260\n",
      "Epoch [263/400], Train Loss: 119.5408, Test Loss: 310.3729\n",
      "Epoch [264/400], Train Loss: 112.0277, Test Loss: 310.6025\n",
      "Epoch [265/400], Train Loss: 109.3993, Test Loss: 302.3152\n",
      "Epoch [266/400], Train Loss: 107.1316, Test Loss: 300.4722\n",
      "Epoch [267/400], Train Loss: 106.0990, Test Loss: 301.9238\n",
      "Epoch [268/400], Train Loss: 105.7593, Test Loss: 307.9141\n",
      "Epoch [269/400], Train Loss: 106.8957, Test Loss: 299.1230\n",
      "Epoch [270/400], Train Loss: 103.3404, Test Loss: 312.1134\n",
      "Epoch [271/400], Train Loss: 105.0666, Test Loss: 301.5435\n",
      "Epoch [272/400], Train Loss: 107.0271, Test Loss: 300.4850\n",
      "Epoch [273/400], Train Loss: 106.8028, Test Loss: 302.8761\n",
      "Epoch [274/400], Train Loss: 104.1358, Test Loss: 296.5469\n",
      "Epoch [275/400], Train Loss: 107.2466, Test Loss: 311.1582\n",
      "Epoch [276/400], Train Loss: 105.6222, Test Loss: 291.1850\n",
      "Epoch [277/400], Train Loss: 104.6461, Test Loss: 293.4579\n",
      "Epoch [278/400], Train Loss: 97.2212, Test Loss: 310.2000\n",
      "Epoch [279/400], Train Loss: 99.4535, Test Loss: 306.4691\n",
      "Epoch [280/400], Train Loss: 101.1799, Test Loss: 297.6621\n",
      "Epoch [281/400], Train Loss: 100.7383, Test Loss: 302.9407\n",
      "Epoch [282/400], Train Loss: 97.1774, Test Loss: 295.5924\n",
      "Epoch [283/400], Train Loss: 93.8434, Test Loss: 306.5435\n",
      "Epoch [284/400], Train Loss: 92.5568, Test Loss: 302.8617\n",
      "Epoch [285/400], Train Loss: 92.8162, Test Loss: 311.4321\n",
      "Epoch [286/400], Train Loss: 96.1152, Test Loss: 302.3077\n",
      "Epoch [287/400], Train Loss: 94.8682, Test Loss: 309.5525\n",
      "Epoch [288/400], Train Loss: 96.7998, Test Loss: 303.2309\n",
      "Epoch [289/400], Train Loss: 94.0642, Test Loss: 314.6316\n",
      "Epoch [290/400], Train Loss: 94.9696, Test Loss: 304.8476\n",
      "Epoch [291/400], Train Loss: 90.2679, Test Loss: 285.1280\n",
      "Epoch [292/400], Train Loss: 95.7461, Test Loss: 306.6217\n",
      "Epoch [293/400], Train Loss: 94.7022, Test Loss: 302.7432\n",
      "Epoch [294/400], Train Loss: 92.5029, Test Loss: 294.9351\n",
      "Epoch [295/400], Train Loss: 93.4660, Test Loss: 290.2901\n",
      "Epoch [296/400], Train Loss: 90.7545, Test Loss: 296.3072\n",
      "Epoch [297/400], Train Loss: 90.6484, Test Loss: 306.1824\n",
      "Epoch [298/400], Train Loss: 85.4491, Test Loss: 290.5461\n",
      "Epoch [299/400], Train Loss: 91.2230, Test Loss: 311.2870\n",
      "Epoch [300/400], Train Loss: 87.9922, Test Loss: 292.8624\n",
      "Epoch [301/400], Train Loss: 88.2654, Test Loss: 304.1444\n",
      "Epoch [302/400], Train Loss: 88.9861, Test Loss: 303.9725\n",
      "Epoch [303/400], Train Loss: 91.0557, Test Loss: 304.3326\n",
      "Epoch [304/400], Train Loss: 92.3545, Test Loss: 295.0777\n",
      "Epoch [305/400], Train Loss: 81.6068, Test Loss: 291.7790\n",
      "Epoch [306/400], Train Loss: 83.2096, Test Loss: 293.0911\n",
      "Epoch [307/400], Train Loss: 84.4018, Test Loss: 295.8001\n",
      "Epoch [308/400], Train Loss: 84.2681, Test Loss: 302.3624\n",
      "Epoch [309/400], Train Loss: 81.1654, Test Loss: 306.3962\n",
      "Epoch [310/400], Train Loss: 84.4335, Test Loss: 307.5339\n",
      "Epoch [311/400], Train Loss: 87.0155, Test Loss: 294.9884\n",
      "Epoch [312/400], Train Loss: 80.4813, Test Loss: 301.1694\n",
      "Epoch [313/400], Train Loss: 79.3281, Test Loss: 295.5255\n",
      "Epoch [314/400], Train Loss: 81.8075, Test Loss: 294.1881\n",
      "Epoch [315/400], Train Loss: 76.9656, Test Loss: 296.0582\n",
      "Epoch [316/400], Train Loss: 77.4935, Test Loss: 298.4223\n",
      "Epoch [317/400], Train Loss: 75.3820, Test Loss: 289.8239\n",
      "Epoch [318/400], Train Loss: 73.0225, Test Loss: 292.6307\n",
      "Epoch [319/400], Train Loss: 73.9697, Test Loss: 289.2161\n",
      "Epoch [320/400], Train Loss: 74.7125, Test Loss: 294.2936\n",
      "Epoch [321/400], Train Loss: 76.2484, Test Loss: 302.9128\n",
      "Epoch [322/400], Train Loss: 72.8781, Test Loss: 297.4336\n",
      "Epoch [323/400], Train Loss: 73.4892, Test Loss: 297.9327\n",
      "Epoch [324/400], Train Loss: 72.5048, Test Loss: 281.5030\n",
      "Epoch [325/400], Train Loss: 70.5506, Test Loss: 293.2515\n",
      "Epoch [326/400], Train Loss: 72.8693, Test Loss: 294.1279\n",
      "Epoch [327/400], Train Loss: 67.7537, Test Loss: 283.9728\n",
      "Epoch [328/400], Train Loss: 65.9225, Test Loss: 295.7773\n",
      "Epoch [329/400], Train Loss: 70.8035, Test Loss: 299.3705\n",
      "Epoch [330/400], Train Loss: 71.1588, Test Loss: 297.8618\n",
      "Epoch [331/400], Train Loss: 69.5667, Test Loss: 297.6945\n",
      "Epoch [332/400], Train Loss: 68.0896, Test Loss: 300.8068\n",
      "Epoch [333/400], Train Loss: 69.7098, Test Loss: 306.6847\n",
      "Epoch [334/400], Train Loss: 70.9631, Test Loss: 300.9780\n",
      "Epoch [335/400], Train Loss: 70.9247, Test Loss: 300.4437\n",
      "Epoch [336/400], Train Loss: 67.6287, Test Loss: 286.5709\n",
      "Epoch [337/400], Train Loss: 65.3948, Test Loss: 297.8439\n",
      "Epoch [338/400], Train Loss: 61.0848, Test Loss: 299.7080\n",
      "Epoch [339/400], Train Loss: 64.5288, Test Loss: 299.4305\n",
      "Epoch [340/400], Train Loss: 65.7552, Test Loss: 298.4138\n",
      "Epoch [341/400], Train Loss: 61.0194, Test Loss: 285.8157\n",
      "Epoch [342/400], Train Loss: 65.8271, Test Loss: 289.1166\n",
      "Epoch [343/400], Train Loss: 62.9872, Test Loss: 296.6550\n",
      "Epoch [344/400], Train Loss: 59.9066, Test Loss: 296.9370\n",
      "Epoch [345/400], Train Loss: 62.1717, Test Loss: 296.1902\n",
      "Epoch [346/400], Train Loss: 63.9705, Test Loss: 288.4074\n",
      "Epoch [347/400], Train Loss: 63.6919, Test Loss: 297.9440\n",
      "Epoch [348/400], Train Loss: 60.2923, Test Loss: 293.2701\n",
      "Epoch [349/400], Train Loss: 58.9061, Test Loss: 293.0404\n",
      "Epoch [350/400], Train Loss: 66.4410, Test Loss: 301.8241\n",
      "Epoch [351/400], Train Loss: 58.9934, Test Loss: 294.3632\n",
      "Epoch [352/400], Train Loss: 57.4094, Test Loss: 310.1690\n",
      "Epoch [353/400], Train Loss: 54.3151, Test Loss: 303.6597\n",
      "Epoch [354/400], Train Loss: 53.5446, Test Loss: 303.2921\n",
      "Epoch [355/400], Train Loss: 56.4609, Test Loss: 304.4628\n",
      "Epoch [356/400], Train Loss: 59.8768, Test Loss: 299.2879\n",
      "Epoch [357/400], Train Loss: 59.2821, Test Loss: 296.9325\n",
      "Epoch [358/400], Train Loss: 53.0828, Test Loss: 302.8210\n",
      "Epoch [359/400], Train Loss: 51.2482, Test Loss: 294.4749\n",
      "Epoch [360/400], Train Loss: 51.7409, Test Loss: 291.7849\n",
      "Epoch [361/400], Train Loss: 54.0948, Test Loss: 296.7461\n",
      "Epoch [362/400], Train Loss: 52.6218, Test Loss: 291.3179\n",
      "Epoch [363/400], Train Loss: 53.9267, Test Loss: 296.2320\n",
      "Epoch [364/400], Train Loss: 53.0944, Test Loss: 289.4589\n",
      "Epoch [365/400], Train Loss: 53.4122, Test Loss: 304.5897\n",
      "Epoch [366/400], Train Loss: 52.2722, Test Loss: 295.5984\n",
      "Epoch [367/400], Train Loss: 48.3271, Test Loss: 293.9266\n",
      "Epoch [368/400], Train Loss: 48.3632, Test Loss: 298.0856\n",
      "Epoch [369/400], Train Loss: 55.6036, Test Loss: 311.7475\n",
      "Epoch [370/400], Train Loss: 50.1301, Test Loss: 300.2020\n",
      "Epoch [371/400], Train Loss: 53.4848, Test Loss: 298.4233\n",
      "Epoch [372/400], Train Loss: 48.5954, Test Loss: 304.7229\n",
      "Epoch [373/400], Train Loss: 45.2776, Test Loss: 293.4060\n",
      "Epoch [374/400], Train Loss: 46.2697, Test Loss: 322.7364\n",
      "Epoch [375/400], Train Loss: 48.1332, Test Loss: 293.9290\n",
      "Epoch [376/400], Train Loss: 48.2225, Test Loss: 298.7160\n",
      "Epoch [377/400], Train Loss: 47.1338, Test Loss: 294.8456\n",
      "Epoch [378/400], Train Loss: 42.7436, Test Loss: 310.9438\n",
      "Epoch [379/400], Train Loss: 46.5064, Test Loss: 307.0877\n",
      "Epoch [380/400], Train Loss: 42.2510, Test Loss: 298.4125\n",
      "Epoch [381/400], Train Loss: 45.7293, Test Loss: 304.9082\n",
      "Epoch [382/400], Train Loss: 42.6381, Test Loss: 298.6599\n",
      "Epoch [383/400], Train Loss: 43.1786, Test Loss: 307.7972\n",
      "Epoch [384/400], Train Loss: 42.8902, Test Loss: 305.3994\n",
      "Epoch [385/400], Train Loss: 41.1089, Test Loss: 303.0125\n",
      "Epoch [386/400], Train Loss: 40.2364, Test Loss: 306.2295\n",
      "Epoch [387/400], Train Loss: 42.2873, Test Loss: 312.2682\n",
      "Epoch [388/400], Train Loss: 39.9631, Test Loss: 308.3976\n",
      "Epoch [389/400], Train Loss: 51.8507, Test Loss: 305.2594\n",
      "Epoch [390/400], Train Loss: 48.0910, Test Loss: 302.8536\n",
      "Epoch [391/400], Train Loss: 40.7550, Test Loss: 296.0463\n",
      "Epoch [392/400], Train Loss: 40.8824, Test Loss: 305.1114\n",
      "Epoch [393/400], Train Loss: 37.2911, Test Loss: 305.8731\n",
      "Epoch [394/400], Train Loss: 36.4569, Test Loss: 303.7516\n",
      "Epoch [395/400], Train Loss: 37.2146, Test Loss: 303.2400\n",
      "Epoch [396/400], Train Loss: 37.7202, Test Loss: 313.3278\n",
      "Epoch [397/400], Train Loss: 36.4185, Test Loss: 317.3535\n",
      "Epoch [398/400], Train Loss: 37.2997, Test Loss: 312.1038\n",
      "Epoch [399/400], Train Loss: 40.2500, Test Loss: 317.0023\n",
      "Epoch [400/400], Train Loss: 40.6593, Test Loss: 328.9042\n",
      "Epoch [1/400], Train Loss: 50983.3201, Test Loss: 48675.7502\n",
      "Epoch [2/400], Train Loss: 48260.9622, Test Loss: 46641.2881\n",
      "Epoch [3/400], Train Loss: 46318.8644, Test Loss: 44824.3545\n",
      "Epoch [4/400], Train Loss: 44555.2558, Test Loss: 43118.3485\n",
      "Epoch [5/400], Train Loss: 42931.2430, Test Loss: 41484.3093\n",
      "Epoch [6/400], Train Loss: 41350.2762, Test Loss: 39919.6021\n",
      "Epoch [7/400], Train Loss: 39694.1682, Test Loss: 38411.9276\n",
      "Epoch [8/400], Train Loss: 38340.9452, Test Loss: 36976.1877\n",
      "Epoch [9/400], Train Loss: 36805.9709, Test Loss: 35564.4852\n",
      "Epoch [10/400], Train Loss: 35450.0306, Test Loss: 34219.7455\n",
      "Epoch [11/400], Train Loss: 34137.8164, Test Loss: 32910.2424\n",
      "Epoch [12/400], Train Loss: 32830.0510, Test Loss: 31647.3802\n",
      "Epoch [13/400], Train Loss: 31552.3093, Test Loss: 30435.9099\n",
      "Epoch [14/400], Train Loss: 30383.7198, Test Loss: 29257.2412\n",
      "Epoch [15/400], Train Loss: 29146.9056, Test Loss: 28118.8008\n",
      "Epoch [16/400], Train Loss: 28130.0492, Test Loss: 27029.0419\n",
      "Epoch [17/400], Train Loss: 26999.4671, Test Loss: 25960.1121\n",
      "Epoch [18/400], Train Loss: 26042.0521, Test Loss: 24946.9752\n",
      "Epoch [19/400], Train Loss: 24966.1164, Test Loss: 23969.3214\n",
      "Epoch [20/400], Train Loss: 24043.7804, Test Loss: 23017.5059\n",
      "Epoch [21/400], Train Loss: 23099.4676, Test Loss: 22102.1666\n",
      "Epoch [22/400], Train Loss: 22155.8554, Test Loss: 21212.2697\n",
      "Epoch [23/400], Train Loss: 21245.3128, Test Loss: 20367.4135\n",
      "Epoch [24/400], Train Loss: 20456.4041, Test Loss: 19552.1352\n",
      "Epoch [25/400], Train Loss: 19670.0491, Test Loss: 18775.1162\n",
      "Epoch [26/400], Train Loss: 18880.8904, Test Loss: 18017.0018\n",
      "Epoch [27/400], Train Loss: 18091.0591, Test Loss: 17287.5803\n",
      "Epoch [28/400], Train Loss: 17396.3287, Test Loss: 16596.7681\n",
      "Epoch [29/400], Train Loss: 16700.1603, Test Loss: 15925.3444\n",
      "Epoch [30/400], Train Loss: 16031.7483, Test Loss: 15289.0518\n",
      "Epoch [31/400], Train Loss: 15422.4134, Test Loss: 14674.2971\n",
      "Epoch [32/400], Train Loss: 14827.1800, Test Loss: 14085.5999\n",
      "Epoch [33/400], Train Loss: 14258.8713, Test Loss: 13526.0853\n",
      "Epoch [34/400], Train Loss: 13703.1226, Test Loss: 12990.9025\n",
      "Epoch [35/400], Train Loss: 13206.3428, Test Loss: 12484.5592\n",
      "Epoch [36/400], Train Loss: 12637.8843, Test Loss: 11983.5133\n",
      "Epoch [37/400], Train Loss: 12188.8859, Test Loss: 11524.4287\n",
      "Epoch [38/400], Train Loss: 11748.1543, Test Loss: 11077.0748\n",
      "Epoch [39/400], Train Loss: 11290.2548, Test Loss: 10654.8936\n",
      "Epoch [40/400], Train Loss: 10875.7721, Test Loss: 10252.5097\n",
      "Epoch [41/400], Train Loss: 10465.1115, Test Loss: 9874.0288\n",
      "Epoch [42/400], Train Loss: 10110.7761, Test Loss: 9513.7446\n",
      "Epoch [43/400], Train Loss: 9767.7317, Test Loss: 9170.6133\n",
      "Epoch [44/400], Train Loss: 9388.7549, Test Loss: 8851.8105\n",
      "Epoch [45/400], Train Loss: 9086.5952, Test Loss: 8547.1979\n",
      "Epoch [46/400], Train Loss: 8784.3657, Test Loss: 8260.4730\n",
      "Epoch [47/400], Train Loss: 8500.6511, Test Loss: 7989.3171\n",
      "Epoch [48/400], Train Loss: 8246.5573, Test Loss: 7739.2673\n",
      "Epoch [49/400], Train Loss: 7997.4693, Test Loss: 7500.6356\n",
      "Epoch [50/400], Train Loss: 7799.4316, Test Loss: 7277.2149\n",
      "Epoch [51/400], Train Loss: 7549.5324, Test Loss: 7072.6256\n",
      "Epoch [52/400], Train Loss: 7355.4418, Test Loss: 6876.3038\n",
      "Epoch [53/400], Train Loss: 7163.3684, Test Loss: 6696.2962\n",
      "Epoch [54/400], Train Loss: 6981.4744, Test Loss: 6529.5087\n",
      "Epoch [55/400], Train Loss: 6818.6534, Test Loss: 6372.9061\n",
      "Epoch [56/400], Train Loss: 6662.7446, Test Loss: 6230.1032\n",
      "Epoch [57/400], Train Loss: 6529.6403, Test Loss: 6094.9662\n",
      "Epoch [58/400], Train Loss: 6379.6718, Test Loss: 5971.5039\n",
      "Epoch [59/400], Train Loss: 6288.4510, Test Loss: 5861.9453\n",
      "Epoch [60/400], Train Loss: 6155.6363, Test Loss: 5758.8830\n",
      "Epoch [61/400], Train Loss: 6072.6728, Test Loss: 5665.2437\n",
      "Epoch [62/400], Train Loss: 5964.2086, Test Loss: 5579.5178\n",
      "Epoch [63/400], Train Loss: 5900.1563, Test Loss: 5501.0542\n",
      "Epoch [64/400], Train Loss: 5823.8423, Test Loss: 5430.4167\n",
      "Epoch [65/400], Train Loss: 5760.3552, Test Loss: 5368.4049\n",
      "Epoch [66/400], Train Loss: 5670.2837, Test Loss: 5312.1024\n",
      "Epoch [67/400], Train Loss: 5621.3693, Test Loss: 5261.3209\n",
      "Epoch [68/400], Train Loss: 5566.8191, Test Loss: 5217.2365\n",
      "Epoch [69/400], Train Loss: 5531.6018, Test Loss: 5176.1836\n",
      "Epoch [70/400], Train Loss: 5484.9287, Test Loss: 5143.8060\n",
      "Epoch [71/400], Train Loss: 5455.7277, Test Loss: 5111.5566\n",
      "Epoch [72/400], Train Loss: 5410.4094, Test Loss: 5082.2803\n",
      "Epoch [73/400], Train Loss: 5401.4788, Test Loss: 5058.3811\n",
      "Epoch [74/400], Train Loss: 5363.4647, Test Loss: 5037.4222\n",
      "Epoch [75/400], Train Loss: 5343.3379, Test Loss: 5019.0635\n",
      "Epoch [76/400], Train Loss: 5326.4216, Test Loss: 5004.3497\n",
      "Epoch [77/400], Train Loss: 5310.4773, Test Loss: 4990.5820\n",
      "Epoch [78/400], Train Loss: 5350.6564, Test Loss: 4979.0942\n",
      "Epoch [79/400], Train Loss: 5294.5949, Test Loss: 4970.9945\n",
      "Epoch [80/400], Train Loss: 5280.7281, Test Loss: 4963.6678\n",
      "Epoch [81/400], Train Loss: 5270.5437, Test Loss: 4955.4001\n",
      "Epoch [82/400], Train Loss: 5252.1685, Test Loss: 4951.2819\n",
      "Epoch [83/400], Train Loss: 5249.6494, Test Loss: 4947.0437\n",
      "Epoch [84/400], Train Loss: 5289.6179, Test Loss: 4943.4821\n",
      "Epoch [85/400], Train Loss: 5263.9757, Test Loss: 4940.3521\n",
      "Epoch [86/400], Train Loss: 5246.5444, Test Loss: 4938.1916\n",
      "Epoch [87/400], Train Loss: 5277.0323, Test Loss: 4936.6574\n",
      "Epoch [88/400], Train Loss: 5241.4994, Test Loss: 4935.3254\n",
      "Epoch [89/400], Train Loss: 5237.8876, Test Loss: 4933.9265\n",
      "Epoch [90/400], Train Loss: 5237.9118, Test Loss: 4933.2129\n",
      "Epoch [91/400], Train Loss: 5243.4110, Test Loss: 4932.5796\n",
      "Epoch [92/400], Train Loss: 5263.1649, Test Loss: 4932.3702\n",
      "Epoch [93/400], Train Loss: 5268.1743, Test Loss: 4931.9186\n",
      "Epoch [94/400], Train Loss: 5243.3311, Test Loss: 4931.6201\n",
      "Epoch [95/400], Train Loss: 5225.0057, Test Loss: 4931.4927\n",
      "Epoch [96/400], Train Loss: 5226.1666, Test Loss: 4931.4371\n",
      "Epoch [97/400], Train Loss: 5240.7323, Test Loss: 4931.3992\n",
      "Epoch [98/400], Train Loss: 5232.6102, Test Loss: 4931.4312\n",
      "Epoch [99/400], Train Loss: 5236.5843, Test Loss: 4931.3886\n",
      "Epoch [100/400], Train Loss: 5234.2228, Test Loss: 4931.3496\n",
      "Epoch [101/400], Train Loss: 5247.5567, Test Loss: 4914.7620\n",
      "Epoch [102/400], Train Loss: 5198.0222, Test Loss: 4911.2379\n",
      "Epoch [103/400], Train Loss: 5223.3707, Test Loss: 4902.9411\n",
      "Epoch [104/400], Train Loss: 5182.1207, Test Loss: 4890.6871\n",
      "Epoch [105/400], Train Loss: 5188.9893, Test Loss: 4880.2767\n",
      "Epoch [106/400], Train Loss: 5146.8339, Test Loss: 4876.1075\n",
      "Epoch [107/400], Train Loss: 5140.9087, Test Loss: 4894.7990\n",
      "Epoch [108/400], Train Loss: 5129.2766, Test Loss: 4846.8846\n",
      "Epoch [109/400], Train Loss: 5121.6641, Test Loss: 4833.4594\n",
      "Epoch [110/400], Train Loss: 5091.2186, Test Loss: 4863.9532\n",
      "Epoch [111/400], Train Loss: 5155.0683, Test Loss: 4880.2348\n",
      "Epoch [112/400], Train Loss: 5091.9845, Test Loss: 4811.9178\n",
      "Epoch [113/400], Train Loss: 5082.7474, Test Loss: 4809.9080\n",
      "Epoch [114/400], Train Loss: 5052.4463, Test Loss: 4797.9975\n",
      "Epoch [115/400], Train Loss: 5061.0877, Test Loss: 4790.0041\n",
      "Epoch [116/400], Train Loss: 5092.4533, Test Loss: 4890.4201\n",
      "Epoch [117/400], Train Loss: 5084.3624, Test Loss: 4801.4546\n",
      "Epoch [118/400], Train Loss: 5018.8536, Test Loss: 4787.8297\n",
      "Epoch [119/400], Train Loss: 5005.1942, Test Loss: 4736.8771\n",
      "Epoch [120/400], Train Loss: 5043.4770, Test Loss: 4725.6466\n",
      "Epoch [121/400], Train Loss: 5055.1165, Test Loss: 4782.2345\n",
      "Epoch [122/400], Train Loss: 5027.3611, Test Loss: 4750.8696\n",
      "Epoch [123/400], Train Loss: 5028.7392, Test Loss: 4742.4097\n",
      "Epoch [124/400], Train Loss: 4974.1268, Test Loss: 4777.8157\n",
      "Epoch [125/400], Train Loss: 4993.9068, Test Loss: 4781.8845\n",
      "Epoch [126/400], Train Loss: 4976.3715, Test Loss: 4766.4450\n",
      "Epoch [127/400], Train Loss: 4947.1236, Test Loss: 4748.7725\n",
      "Epoch [128/400], Train Loss: 4976.8394, Test Loss: 4740.8416\n",
      "Epoch [129/400], Train Loss: 4987.6634, Test Loss: 4750.1353\n",
      "Epoch [130/400], Train Loss: 4927.3377, Test Loss: 4819.8251\n",
      "Epoch [131/400], Train Loss: 4993.9102, Test Loss: 4750.6237\n",
      "Epoch [132/400], Train Loss: 4934.8319, Test Loss: 4733.2632\n",
      "Epoch [133/400], Train Loss: 4940.6974, Test Loss: 4729.3416\n",
      "Epoch [134/400], Train Loss: 4934.7115, Test Loss: 4781.3258\n",
      "Epoch [135/400], Train Loss: 4889.8491, Test Loss: 4768.8517\n",
      "Epoch [136/400], Train Loss: 4925.5921, Test Loss: 4697.1790\n",
      "Epoch [137/400], Train Loss: 4927.3718, Test Loss: 4747.6337\n",
      "Epoch [138/400], Train Loss: 4924.4467, Test Loss: 4723.1689\n",
      "Epoch [139/400], Train Loss: 4961.9904, Test Loss: 4714.3426\n",
      "Epoch [140/400], Train Loss: 4907.7381, Test Loss: 4693.9554\n",
      "Epoch [141/400], Train Loss: 4869.2793, Test Loss: 4730.8095\n",
      "Epoch [142/400], Train Loss: 4869.5669, Test Loss: 4706.4220\n",
      "Epoch [143/400], Train Loss: 4887.1062, Test Loss: 4706.3449\n",
      "Epoch [144/400], Train Loss: 4851.1098, Test Loss: 4971.1594\n",
      "Epoch [145/400], Train Loss: 4913.4802, Test Loss: 4711.2003\n",
      "Epoch [146/400], Train Loss: 4871.3063, Test Loss: 4871.2303\n",
      "Epoch [147/400], Train Loss: 4805.2667, Test Loss: 4694.8922\n",
      "Epoch [148/400], Train Loss: 4868.9500, Test Loss: 4728.8473\n",
      "Epoch [149/400], Train Loss: 4835.2161, Test Loss: 4835.6212\n",
      "Epoch [150/400], Train Loss: 4913.1107, Test Loss: 4683.9850\n",
      "Epoch [151/400], Train Loss: 4864.2896, Test Loss: 4733.2175\n",
      "Epoch [152/400], Train Loss: 4884.4773, Test Loss: 4731.9812\n",
      "Epoch [153/400], Train Loss: 4824.3764, Test Loss: 4675.7560\n",
      "Epoch [154/400], Train Loss: 4827.7715, Test Loss: 4731.8798\n",
      "Epoch [155/400], Train Loss: 4812.6556, Test Loss: 4715.4640\n",
      "Epoch [156/400], Train Loss: 4814.1293, Test Loss: 4682.5088\n",
      "Epoch [157/400], Train Loss: 4798.4793, Test Loss: 4716.1891\n",
      "Epoch [158/400], Train Loss: 4856.9864, Test Loss: 4674.7929\n",
      "Epoch [159/400], Train Loss: 4822.0499, Test Loss: 4811.6047\n",
      "Epoch [160/400], Train Loss: 4812.9147, Test Loss: 4756.7452\n",
      "Epoch [161/400], Train Loss: 4819.5193, Test Loss: 4750.0370\n",
      "Epoch [162/400], Train Loss: 4794.4701, Test Loss: 4728.5942\n",
      "Epoch [163/400], Train Loss: 4790.8745, Test Loss: 4839.4113\n",
      "Epoch [164/400], Train Loss: 4881.0356, Test Loss: 4795.9124\n",
      "Epoch [165/400], Train Loss: 4798.5091, Test Loss: 4739.7399\n",
      "Epoch [166/400], Train Loss: 4786.9625, Test Loss: 4826.7867\n",
      "Epoch [167/400], Train Loss: 4843.7242, Test Loss: 4755.8360\n",
      "Epoch [168/400], Train Loss: 4796.8525, Test Loss: 4759.9264\n",
      "Epoch [169/400], Train Loss: 4868.5684, Test Loss: 4792.9165\n",
      "Epoch [170/400], Train Loss: 4761.3242, Test Loss: 4811.5695\n",
      "Epoch [171/400], Train Loss: 4755.8128, Test Loss: 4815.2696\n",
      "Epoch [172/400], Train Loss: 4770.8293, Test Loss: 4750.2482\n",
      "Epoch [173/400], Train Loss: 4754.2240, Test Loss: 4784.3560\n",
      "Epoch [174/400], Train Loss: 4723.4517, Test Loss: 4753.8349\n",
      "Epoch [175/400], Train Loss: 4694.9018, Test Loss: 4740.1123\n",
      "Epoch [176/400], Train Loss: 4743.3555, Test Loss: 4789.9992\n",
      "Epoch [177/400], Train Loss: 4740.0962, Test Loss: 4732.7494\n",
      "Epoch [178/400], Train Loss: 4774.4800, Test Loss: 4742.3163\n",
      "Epoch [179/400], Train Loss: 4699.3359, Test Loss: 4740.1154\n",
      "Epoch [180/400], Train Loss: 4715.6003, Test Loss: 4760.1885\n",
      "Epoch [181/400], Train Loss: 4761.5807, Test Loss: 4718.3218\n",
      "Epoch [182/400], Train Loss: 4732.5561, Test Loss: 4747.1799\n",
      "Epoch [183/400], Train Loss: 4703.7636, Test Loss: 4815.5091\n",
      "Epoch [184/400], Train Loss: 4694.4430, Test Loss: 4741.9916\n",
      "Epoch [185/400], Train Loss: 4700.0570, Test Loss: 4775.1041\n",
      "Epoch [186/400], Train Loss: 4710.1706, Test Loss: 4809.6681\n",
      "Epoch [187/400], Train Loss: 4676.5943, Test Loss: 4795.7999\n",
      "Epoch [188/400], Train Loss: 4628.0328, Test Loss: 4805.7995\n",
      "Epoch [189/400], Train Loss: 4683.6499, Test Loss: 4797.9484\n",
      "Epoch [190/400], Train Loss: 4673.3841, Test Loss: 4794.3370\n",
      "Epoch [191/400], Train Loss: 4667.5429, Test Loss: 4870.4223\n",
      "Epoch [192/400], Train Loss: 4624.2844, Test Loss: 4898.2325\n",
      "Epoch [193/400], Train Loss: 4643.2619, Test Loss: 4758.5840\n",
      "Epoch [194/400], Train Loss: 4617.6197, Test Loss: 4774.6846\n",
      "Epoch [195/400], Train Loss: 4616.3211, Test Loss: 4761.1032\n",
      "Epoch [196/400], Train Loss: 4608.8011, Test Loss: 4842.8444\n",
      "Epoch [197/400], Train Loss: 4579.2680, Test Loss: 4778.6474\n",
      "Epoch [198/400], Train Loss: 4585.0953, Test Loss: 4778.2062\n",
      "Epoch [199/400], Train Loss: 4555.7900, Test Loss: 4805.2491\n",
      "Epoch [200/400], Train Loss: 4585.3355, Test Loss: 4736.7724\n",
      "Epoch [201/400], Train Loss: 4561.6657, Test Loss: 4760.4445\n",
      "Epoch [202/400], Train Loss: 4559.3539, Test Loss: 4829.2294\n",
      "Epoch [203/400], Train Loss: 4613.5742, Test Loss: 4798.7610\n",
      "Epoch [204/400], Train Loss: 4594.6435, Test Loss: 4772.1580\n",
      "Epoch [205/400], Train Loss: 4550.4779, Test Loss: 4676.2105\n",
      "Epoch [206/400], Train Loss: 4624.6704, Test Loss: 4764.7316\n",
      "Epoch [207/400], Train Loss: 4566.6161, Test Loss: 4808.5886\n",
      "Epoch [208/400], Train Loss: 4564.5683, Test Loss: 4777.8243\n",
      "Epoch [209/400], Train Loss: 4501.3068, Test Loss: 4771.2232\n",
      "Epoch [210/400], Train Loss: 4521.6403, Test Loss: 4805.4946\n",
      "Epoch [211/400], Train Loss: 4581.4826, Test Loss: 4757.6057\n",
      "Epoch [212/400], Train Loss: 4594.1558, Test Loss: 4679.9019\n",
      "Epoch [213/400], Train Loss: 4597.8998, Test Loss: 4727.7535\n",
      "Epoch [214/400], Train Loss: 4583.1112, Test Loss: 4725.6731\n",
      "Epoch [215/400], Train Loss: 4568.4724, Test Loss: 4827.8507\n",
      "Epoch [216/400], Train Loss: 4562.4943, Test Loss: 4822.0432\n",
      "Epoch [217/400], Train Loss: 4523.2901, Test Loss: 4875.5988\n",
      "Epoch [218/400], Train Loss: 4618.0210, Test Loss: 5031.4002\n",
      "Epoch [219/400], Train Loss: 4725.6277, Test Loss: 5041.9483\n",
      "Epoch [220/400], Train Loss: 4766.1983, Test Loss: 4994.2778\n",
      "Epoch [221/400], Train Loss: 4648.7617, Test Loss: 5086.4778\n",
      "Epoch [222/400], Train Loss: 4738.8320, Test Loss: 4988.4965\n",
      "Epoch [223/400], Train Loss: 4706.8660, Test Loss: 5082.1380\n",
      "Epoch [224/400], Train Loss: 4671.7221, Test Loss: 5255.6629\n",
      "Epoch [225/400], Train Loss: 4684.1819, Test Loss: 5142.5916\n",
      "Epoch [226/400], Train Loss: 4659.5782, Test Loss: 4989.0702\n",
      "Epoch [227/400], Train Loss: 4563.2096, Test Loss: 4972.2984\n",
      "Epoch [228/400], Train Loss: 4648.2131, Test Loss: 5097.1738\n",
      "Epoch [229/400], Train Loss: 4658.4852, Test Loss: 5149.7569\n",
      "Epoch [230/400], Train Loss: 4652.8440, Test Loss: 5090.4859\n",
      "Epoch [231/400], Train Loss: 4609.8406, Test Loss: 5210.9316\n",
      "Epoch [232/400], Train Loss: 4598.2270, Test Loss: 5044.9423\n",
      "Epoch [233/400], Train Loss: 4589.7973, Test Loss: 4928.9064\n",
      "Epoch [234/400], Train Loss: 4634.8147, Test Loss: 5142.4322\n",
      "Epoch [235/400], Train Loss: 4589.1421, Test Loss: 5069.7164\n",
      "Epoch [236/400], Train Loss: 4534.1942, Test Loss: 4970.9571\n",
      "Epoch [237/400], Train Loss: 4555.5634, Test Loss: 5032.8915\n",
      "Epoch [238/400], Train Loss: 4579.5218, Test Loss: 5047.2298\n",
      "Epoch [239/400], Train Loss: 4601.5039, Test Loss: 5119.5738\n",
      "Epoch [240/400], Train Loss: 4591.9857, Test Loss: 5247.1302\n",
      "Epoch [241/400], Train Loss: 4541.5513, Test Loss: 5032.4886\n",
      "Epoch [242/400], Train Loss: 4528.1128, Test Loss: 5104.2742\n",
      "Epoch [243/400], Train Loss: 4553.8370, Test Loss: 5251.3274\n",
      "Epoch [244/400], Train Loss: 4539.1313, Test Loss: 5255.8849\n",
      "Epoch [245/400], Train Loss: 4515.0862, Test Loss: 5075.6821\n",
      "Epoch [246/400], Train Loss: 4543.5142, Test Loss: 5036.0761\n",
      "Epoch [247/400], Train Loss: 4542.2634, Test Loss: 5056.7405\n",
      "Epoch [248/400], Train Loss: 4487.8664, Test Loss: 5141.0884\n",
      "Epoch [249/400], Train Loss: 4504.4121, Test Loss: 5190.4586\n",
      "Epoch [250/400], Train Loss: 4552.2353, Test Loss: 5296.3844\n",
      "Epoch [251/400], Train Loss: 4573.6914, Test Loss: 5089.3533\n",
      "Epoch [252/400], Train Loss: 4554.6838, Test Loss: 5097.6010\n",
      "Epoch [253/400], Train Loss: 4482.6492, Test Loss: 5108.1958\n",
      "Epoch [254/400], Train Loss: 4526.8572, Test Loss: 5116.3665\n",
      "Epoch [255/400], Train Loss: 4516.0606, Test Loss: 5160.0930\n",
      "Epoch [256/400], Train Loss: 4509.7482, Test Loss: 5125.1270\n",
      "Epoch [257/400], Train Loss: 4462.2241, Test Loss: 5211.3934\n",
      "Epoch [258/400], Train Loss: 4453.4212, Test Loss: 5091.0946\n",
      "Epoch [259/400], Train Loss: 4428.9383, Test Loss: 5448.2974\n",
      "Epoch [260/400], Train Loss: 4467.9896, Test Loss: 5218.7490\n",
      "Epoch [261/400], Train Loss: 4491.2374, Test Loss: 5179.3819\n",
      "Epoch [262/400], Train Loss: 4464.5770, Test Loss: 5033.4156\n",
      "Epoch [263/400], Train Loss: 4410.1768, Test Loss: 5247.8163\n",
      "Epoch [264/400], Train Loss: 4414.2778, Test Loss: 5130.3808\n",
      "Epoch [265/400], Train Loss: 4361.8179, Test Loss: 5499.1996\n",
      "Epoch [266/400], Train Loss: 4406.1625, Test Loss: 5058.9093\n",
      "Epoch [267/400], Train Loss: 4401.8235, Test Loss: 5174.2846\n",
      "Epoch [268/400], Train Loss: 4325.5165, Test Loss: 5129.9147\n",
      "Epoch [269/400], Train Loss: 4320.1486, Test Loss: 5301.6896\n",
      "Epoch [270/400], Train Loss: 4367.2644, Test Loss: 5392.0689\n",
      "Epoch [271/400], Train Loss: 4348.1561, Test Loss: 5285.6109\n",
      "Epoch [272/400], Train Loss: 4261.6452, Test Loss: 5381.4378\n",
      "Epoch [273/400], Train Loss: 4261.7869, Test Loss: 5459.5570\n",
      "Epoch [274/400], Train Loss: 4281.0555, Test Loss: 5281.5555\n",
      "Epoch [275/400], Train Loss: 4317.1269, Test Loss: 5514.3238\n",
      "Epoch [276/400], Train Loss: 4318.4652, Test Loss: 5240.0278\n",
      "Epoch [277/400], Train Loss: 4258.8813, Test Loss: 5210.5065\n",
      "Epoch [278/400], Train Loss: 4276.2724, Test Loss: 5161.2115\n",
      "Epoch [279/400], Train Loss: 4267.3374, Test Loss: 5306.0327\n",
      "Epoch [280/400], Train Loss: 4299.1746, Test Loss: 5017.1374\n",
      "Epoch [281/400], Train Loss: 4338.7195, Test Loss: 5104.7488\n",
      "Epoch [282/400], Train Loss: 4280.9656, Test Loss: 5090.6681\n",
      "Epoch [283/400], Train Loss: 4259.1088, Test Loss: 5450.3191\n",
      "Epoch [284/400], Train Loss: 4253.5091, Test Loss: 5419.0652\n",
      "Epoch [285/400], Train Loss: 4169.2766, Test Loss: 5373.1492\n",
      "Epoch [286/400], Train Loss: 4168.3801, Test Loss: 5322.4764\n",
      "Epoch [287/400], Train Loss: 4193.5481, Test Loss: 5325.2525\n",
      "Epoch [288/400], Train Loss: 4135.6271, Test Loss: 5491.6021\n",
      "Epoch [289/400], Train Loss: 4113.9582, Test Loss: 5584.4877\n",
      "Epoch [290/400], Train Loss: 4155.4761, Test Loss: 5306.9190\n",
      "Epoch [291/400], Train Loss: 4165.0298, Test Loss: 5463.1279\n",
      "Epoch [292/400], Train Loss: 4108.6183, Test Loss: 5515.9642\n",
      "Epoch [293/400], Train Loss: 4120.3316, Test Loss: 5543.6557\n",
      "Epoch [294/400], Train Loss: 4068.5785, Test Loss: 5306.2063\n",
      "Epoch [295/400], Train Loss: 4082.7452, Test Loss: 5474.4042\n",
      "Epoch [296/400], Train Loss: 4110.2537, Test Loss: 5367.6280\n",
      "Epoch [297/400], Train Loss: 4165.7488, Test Loss: 5397.8103\n",
      "Epoch [298/400], Train Loss: 4043.2550, Test Loss: 5500.5366\n",
      "Epoch [299/400], Train Loss: 4041.4050, Test Loss: 5765.0427\n",
      "Epoch [300/400], Train Loss: 4056.8845, Test Loss: 5428.5571\n",
      "Epoch [301/400], Train Loss: 3961.5401, Test Loss: 5556.9144\n",
      "Epoch [302/400], Train Loss: 4027.6399, Test Loss: 5803.3637\n",
      "Epoch [303/400], Train Loss: 4054.3302, Test Loss: 5678.0823\n",
      "Epoch [304/400], Train Loss: 4026.7149, Test Loss: 5707.9772\n",
      "Epoch [305/400], Train Loss: 3985.7562, Test Loss: 5540.7421\n",
      "Epoch [306/400], Train Loss: 4013.0828, Test Loss: 5626.1477\n",
      "Epoch [307/400], Train Loss: 3971.4519, Test Loss: 5554.5580\n",
      "Epoch [308/400], Train Loss: 3928.7334, Test Loss: 5799.8667\n",
      "Epoch [309/400], Train Loss: 4016.5777, Test Loss: 5640.8608\n",
      "Epoch [310/400], Train Loss: 3923.5304, Test Loss: 5751.0997\n",
      "Epoch [311/400], Train Loss: 3913.3863, Test Loss: 5572.7654\n",
      "Epoch [312/400], Train Loss: 3946.1596, Test Loss: 5698.7552\n",
      "Epoch [313/400], Train Loss: 4067.9410, Test Loss: 5319.4308\n",
      "Epoch [314/400], Train Loss: 4024.7154, Test Loss: 5744.8704\n",
      "Epoch [315/400], Train Loss: 4045.8836, Test Loss: 5396.7851\n",
      "Epoch [316/400], Train Loss: 3915.7017, Test Loss: 5502.6128\n",
      "Epoch [317/400], Train Loss: 3910.8438, Test Loss: 5309.2593\n",
      "Epoch [318/400], Train Loss: 3939.4490, Test Loss: 5353.1990\n",
      "Epoch [319/400], Train Loss: 3844.9837, Test Loss: 5507.9480\n",
      "Epoch [320/400], Train Loss: 3920.4063, Test Loss: 5462.4772\n",
      "Epoch [321/400], Train Loss: 3867.8924, Test Loss: 5451.1416\n",
      "Epoch [322/400], Train Loss: 3829.3215, Test Loss: 5468.9719\n",
      "Epoch [323/400], Train Loss: 3846.0205, Test Loss: 5528.0994\n",
      "Epoch [324/400], Train Loss: 3810.2425, Test Loss: 5608.9124\n",
      "Epoch [325/400], Train Loss: 3866.3790, Test Loss: 5681.5933\n",
      "Epoch [326/400], Train Loss: 3802.1738, Test Loss: 5435.2831\n",
      "Epoch [327/400], Train Loss: 3926.7278, Test Loss: 5580.4670\n",
      "Epoch [328/400], Train Loss: 3920.7079, Test Loss: 5448.4384\n",
      "Epoch [329/400], Train Loss: 3866.5578, Test Loss: 5427.3694\n",
      "Epoch [330/400], Train Loss: 3711.8332, Test Loss: 5596.6866\n",
      "Epoch [331/400], Train Loss: 3720.8905, Test Loss: 5704.8835\n",
      "Epoch [332/400], Train Loss: 3790.2303, Test Loss: 5657.3033\n",
      "Epoch [333/400], Train Loss: 3707.9679, Test Loss: 5427.2446\n",
      "Epoch [334/400], Train Loss: 3783.7254, Test Loss: 5588.5542\n",
      "Epoch [335/400], Train Loss: 3774.3047, Test Loss: 5534.5776\n",
      "Epoch [336/400], Train Loss: 3773.9302, Test Loss: 5452.0846\n",
      "Epoch [337/400], Train Loss: 3756.3973, Test Loss: 5575.2146\n",
      "Epoch [338/400], Train Loss: 3761.8514, Test Loss: 5487.6144\n",
      "Epoch [339/400], Train Loss: 3795.6980, Test Loss: 5527.8799\n",
      "Epoch [340/400], Train Loss: 3602.3336, Test Loss: 5287.5916\n",
      "Epoch [341/400], Train Loss: 3661.8747, Test Loss: 5693.8895\n",
      "Epoch [342/400], Train Loss: 3689.4759, Test Loss: 5632.0016\n",
      "Epoch [343/400], Train Loss: 3784.3279, Test Loss: 5558.3970\n",
      "Epoch [344/400], Train Loss: 3673.3907, Test Loss: 5756.4400\n",
      "Epoch [345/400], Train Loss: 3811.3592, Test Loss: 5282.4736\n",
      "Epoch [346/400], Train Loss: 3736.6436, Test Loss: 5359.8207\n",
      "Epoch [347/400], Train Loss: 3646.9662, Test Loss: 5703.2437\n",
      "Epoch [348/400], Train Loss: 3692.5493, Test Loss: 5461.9659\n",
      "Epoch [349/400], Train Loss: 3611.0124, Test Loss: 5759.8649\n",
      "Epoch [350/400], Train Loss: 3830.3825, Test Loss: 5645.8539\n",
      "Epoch [351/400], Train Loss: 3728.7578, Test Loss: 5651.0829\n",
      "Epoch [352/400], Train Loss: 3655.9035, Test Loss: 5386.5218\n",
      "Epoch [353/400], Train Loss: 3559.5920, Test Loss: 5730.3163\n",
      "Epoch [354/400], Train Loss: 3666.5407, Test Loss: 5849.3175\n",
      "Epoch [355/400], Train Loss: 3704.7891, Test Loss: 6026.3004\n",
      "Epoch [356/400], Train Loss: 3616.6743, Test Loss: 5857.2046\n",
      "Epoch [357/400], Train Loss: 3656.2106, Test Loss: 5574.6081\n",
      "Epoch [358/400], Train Loss: 3619.5497, Test Loss: 5798.5422\n",
      "Epoch [359/400], Train Loss: 3515.7130, Test Loss: 5637.3052\n",
      "Epoch [360/400], Train Loss: 3614.3377, Test Loss: 5795.1069\n",
      "Epoch [361/400], Train Loss: 3546.6998, Test Loss: 5771.7486\n",
      "Epoch [362/400], Train Loss: 3543.9157, Test Loss: 6017.1222\n",
      "Epoch [363/400], Train Loss: 3544.7854, Test Loss: 5808.0192\n",
      "Epoch [364/400], Train Loss: 3661.4432, Test Loss: 5849.3076\n",
      "Epoch [365/400], Train Loss: 3560.8008, Test Loss: 5751.5938\n",
      "Epoch [366/400], Train Loss: 3492.9490, Test Loss: 5807.6499\n",
      "Epoch [367/400], Train Loss: 3547.9198, Test Loss: 5734.4422\n",
      "Epoch [368/400], Train Loss: 3450.2591, Test Loss: 5755.0657\n",
      "Epoch [369/400], Train Loss: 3391.9440, Test Loss: 5880.0372\n",
      "Epoch [370/400], Train Loss: 3482.2237, Test Loss: 5994.8374\n",
      "Epoch [371/400], Train Loss: 3466.8219, Test Loss: 5700.2729\n",
      "Epoch [372/400], Train Loss: 3467.9600, Test Loss: 5851.6057\n",
      "Epoch [373/400], Train Loss: 3563.8205, Test Loss: 5522.3431\n",
      "Epoch [374/400], Train Loss: 3474.0592, Test Loss: 5523.3411\n",
      "Epoch [375/400], Train Loss: 3391.0749, Test Loss: 5319.0639\n",
      "Epoch [376/400], Train Loss: 3333.4267, Test Loss: 5511.0303\n",
      "Epoch [377/400], Train Loss: 3322.4120, Test Loss: 6043.4166\n",
      "Epoch [378/400], Train Loss: 3433.9227, Test Loss: 5909.8259\n",
      "Epoch [379/400], Train Loss: 3484.1918, Test Loss: 5927.0954\n",
      "Epoch [380/400], Train Loss: 3346.1283, Test Loss: 6378.7504\n",
      "Epoch [381/400], Train Loss: 3354.0727, Test Loss: 5687.9770\n",
      "Epoch [382/400], Train Loss: 3301.2022, Test Loss: 5957.1410\n",
      "Epoch [383/400], Train Loss: 3356.7834, Test Loss: 6150.7240\n",
      "Epoch [384/400], Train Loss: 3427.3586, Test Loss: 5873.9008\n",
      "Epoch [385/400], Train Loss: 3287.2596, Test Loss: 5954.4049\n",
      "Epoch [386/400], Train Loss: 3228.9749, Test Loss: 5826.2788\n",
      "Epoch [387/400], Train Loss: 3253.0424, Test Loss: 5764.4524\n",
      "Epoch [388/400], Train Loss: 3326.3909, Test Loss: 5690.1481\n",
      "Epoch [389/400], Train Loss: 3283.3014, Test Loss: 5884.6608\n",
      "Epoch [390/400], Train Loss: 3238.2813, Test Loss: 5845.6487\n",
      "Epoch [391/400], Train Loss: 3245.6865, Test Loss: 6095.0437\n",
      "Epoch [392/400], Train Loss: 3365.6394, Test Loss: 5722.6643\n",
      "Epoch [393/400], Train Loss: 3401.3017, Test Loss: 5966.8097\n",
      "Epoch [394/400], Train Loss: 3293.4540, Test Loss: 5892.7285\n",
      "Epoch [395/400], Train Loss: 3225.3307, Test Loss: 5901.4598\n",
      "Epoch [396/400], Train Loss: 3219.4341, Test Loss: 6440.4966\n",
      "Epoch [397/400], Train Loss: 3294.5691, Test Loss: 5766.2092\n",
      "Epoch [398/400], Train Loss: 3198.2258, Test Loss: 6032.0886\n",
      "Epoch [399/400], Train Loss: 3192.7379, Test Loss: 5900.1692\n",
      "Epoch [400/400], Train Loss: 3167.8006, Test Loss: 6239.8434\n",
      "Epoch [1/400], Train Loss: 1.4419, Test Loss: 1.2578\n",
      "Epoch [2/400], Train Loss: 1.1613, Test Loss: 1.2224\n",
      "Epoch [3/400], Train Loss: 1.1206, Test Loss: 1.2575\n",
      "Epoch [4/400], Train Loss: 1.1068, Test Loss: 1.1954\n",
      "Epoch [5/400], Train Loss: 1.1118, Test Loss: 1.1493\n",
      "Epoch [6/400], Train Loss: 1.1199, Test Loss: 1.1837\n",
      "Epoch [7/400], Train Loss: 1.0907, Test Loss: 1.1312\n",
      "Epoch [8/400], Train Loss: 1.1010, Test Loss: 1.2207\n",
      "Epoch [9/400], Train Loss: 1.0670, Test Loss: 1.1195\n",
      "Epoch [10/400], Train Loss: 1.0498, Test Loss: 1.1492\n",
      "Epoch [11/400], Train Loss: 1.0076, Test Loss: 1.1617\n",
      "Epoch [12/400], Train Loss: 0.9994, Test Loss: 1.0969\n",
      "Epoch [13/400], Train Loss: 1.0127, Test Loss: 1.0762\n",
      "Epoch [14/400], Train Loss: 0.9866, Test Loss: 1.1106\n",
      "Epoch [15/400], Train Loss: 0.9616, Test Loss: 1.1366\n",
      "Epoch [16/400], Train Loss: 0.9879, Test Loss: 1.0561\n",
      "Epoch [17/400], Train Loss: 0.9706, Test Loss: 1.0594\n",
      "Epoch [18/400], Train Loss: 0.9258, Test Loss: 1.1099\n",
      "Epoch [19/400], Train Loss: 0.9291, Test Loss: 1.1312\n",
      "Epoch [20/400], Train Loss: 0.9674, Test Loss: 1.1194\n",
      "Epoch [21/400], Train Loss: 0.9423, Test Loss: 1.0717\n",
      "Epoch [22/400], Train Loss: 0.9359, Test Loss: 1.0962\n",
      "Epoch [23/400], Train Loss: 0.8984, Test Loss: 1.1170\n",
      "Epoch [24/400], Train Loss: 0.9201, Test Loss: 1.1082\n",
      "Epoch [25/400], Train Loss: 0.8791, Test Loss: 1.1159\n",
      "Epoch [26/400], Train Loss: 0.8617, Test Loss: 1.0743\n",
      "Epoch [27/400], Train Loss: 0.8394, Test Loss: 1.1067\n",
      "Epoch [28/400], Train Loss: 0.8207, Test Loss: 1.1035\n",
      "Epoch [29/400], Train Loss: 0.8146, Test Loss: 1.1392\n",
      "Epoch [30/400], Train Loss: 0.8143, Test Loss: 1.2589\n",
      "Epoch [31/400], Train Loss: 0.8126, Test Loss: 1.1631\n",
      "Epoch [32/400], Train Loss: 0.8041, Test Loss: 1.1437\n",
      "Epoch [33/400], Train Loss: 0.7660, Test Loss: 1.1353\n",
      "Epoch [34/400], Train Loss: 0.7490, Test Loss: 1.1204\n",
      "Epoch [35/400], Train Loss: 0.7292, Test Loss: 1.0942\n",
      "Epoch [36/400], Train Loss: 0.7100, Test Loss: 1.1862\n",
      "Epoch [37/400], Train Loss: 0.6896, Test Loss: 1.2729\n",
      "Epoch [38/400], Train Loss: 0.6829, Test Loss: 1.1950\n",
      "Epoch [39/400], Train Loss: 0.6759, Test Loss: 1.1731\n",
      "Epoch [40/400], Train Loss: 0.6344, Test Loss: 1.2286\n",
      "Epoch [41/400], Train Loss: 0.5983, Test Loss: 1.2889\n",
      "Epoch [42/400], Train Loss: 0.5849, Test Loss: 1.2598\n",
      "Epoch [43/400], Train Loss: 0.5790, Test Loss: 1.2305\n",
      "Epoch [44/400], Train Loss: 0.5466, Test Loss: 1.3022\n",
      "Epoch [45/400], Train Loss: 0.5360, Test Loss: 1.3156\n",
      "Epoch [46/400], Train Loss: 0.5085, Test Loss: 1.3673\n",
      "Epoch [47/400], Train Loss: 0.5199, Test Loss: 1.3265\n",
      "Epoch [48/400], Train Loss: 0.5090, Test Loss: 1.3327\n",
      "Epoch [49/400], Train Loss: 0.4709, Test Loss: 1.2696\n",
      "Epoch [50/400], Train Loss: 0.4321, Test Loss: 1.4138\n",
      "Epoch [51/400], Train Loss: 0.4149, Test Loss: 1.3192\n",
      "Epoch [52/400], Train Loss: 0.4052, Test Loss: 1.3389\n",
      "Epoch [53/400], Train Loss: 0.3900, Test Loss: 1.3209\n",
      "Epoch [54/400], Train Loss: 0.3734, Test Loss: 1.2682\n",
      "Epoch [55/400], Train Loss: 0.3587, Test Loss: 1.3162\n",
      "Epoch [56/400], Train Loss: 0.3425, Test Loss: 1.4006\n",
      "Epoch [57/400], Train Loss: 0.3258, Test Loss: 1.4309\n",
      "Epoch [58/400], Train Loss: 0.3118, Test Loss: 1.4653\n",
      "Epoch [59/400], Train Loss: 0.3108, Test Loss: 1.3657\n",
      "Epoch [60/400], Train Loss: 0.3044, Test Loss: 1.4311\n",
      "Epoch [61/400], Train Loss: 0.2899, Test Loss: 1.4784\n",
      "Epoch [62/400], Train Loss: 0.2665, Test Loss: 1.4232\n",
      "Epoch [63/400], Train Loss: 0.2642, Test Loss: 1.3603\n",
      "Epoch [64/400], Train Loss: 0.2465, Test Loss: 1.4306\n",
      "Epoch [65/400], Train Loss: 0.2316, Test Loss: 1.4736\n",
      "Epoch [66/400], Train Loss: 0.2268, Test Loss: 1.5379\n",
      "Epoch [67/400], Train Loss: 0.2198, Test Loss: 1.4867\n",
      "Epoch [68/400], Train Loss: 0.2032, Test Loss: 1.4645\n",
      "Epoch [69/400], Train Loss: 0.1951, Test Loss: 1.4367\n",
      "Epoch [70/400], Train Loss: 0.1745, Test Loss: 1.4933\n",
      "Epoch [71/400], Train Loss: 0.1699, Test Loss: 1.4835\n",
      "Epoch [72/400], Train Loss: 0.1628, Test Loss: 1.4176\n",
      "Epoch [73/400], Train Loss: 0.1462, Test Loss: 1.5110\n",
      "Epoch [74/400], Train Loss: 0.1476, Test Loss: 1.5250\n",
      "Epoch [75/400], Train Loss: 0.1390, Test Loss: 1.4904\n",
      "Epoch [76/400], Train Loss: 0.1414, Test Loss: 1.5147\n",
      "Epoch [77/400], Train Loss: 0.1416, Test Loss: 1.4948\n",
      "Epoch [78/400], Train Loss: 0.1253, Test Loss: 1.4909\n",
      "Epoch [79/400], Train Loss: 0.1187, Test Loss: 1.4752\n",
      "Epoch [80/400], Train Loss: 0.1240, Test Loss: 1.4829\n",
      "Epoch [81/400], Train Loss: 0.1216, Test Loss: 1.4842\n",
      "Epoch [82/400], Train Loss: 0.1029, Test Loss: 1.5650\n",
      "Epoch [83/400], Train Loss: 0.1023, Test Loss: 1.4687\n",
      "Epoch [84/400], Train Loss: 0.0905, Test Loss: 1.5419\n",
      "Epoch [85/400], Train Loss: 0.0869, Test Loss: 1.4868\n",
      "Epoch [86/400], Train Loss: 0.0886, Test Loss: 1.5318\n",
      "Epoch [87/400], Train Loss: 0.0833, Test Loss: 1.5412\n",
      "Epoch [88/400], Train Loss: 0.0685, Test Loss: 1.5034\n",
      "Epoch [89/400], Train Loss: 0.0775, Test Loss: 1.4494\n",
      "Epoch [90/400], Train Loss: 0.0788, Test Loss: 1.5589\n",
      "Epoch [91/400], Train Loss: 0.0860, Test Loss: 1.5477\n",
      "Epoch [92/400], Train Loss: 0.0824, Test Loss: 1.5020\n",
      "Epoch [93/400], Train Loss: 0.0855, Test Loss: 1.6098\n",
      "Epoch [94/400], Train Loss: 0.0742, Test Loss: 1.6488\n",
      "Epoch [95/400], Train Loss: 0.0792, Test Loss: 1.5130\n",
      "Epoch [96/400], Train Loss: 0.0644, Test Loss: 1.5298\n",
      "Epoch [97/400], Train Loss: 0.0547, Test Loss: 1.5227\n",
      "Epoch [98/400], Train Loss: 0.0480, Test Loss: 1.5115\n",
      "Epoch [99/400], Train Loss: 0.0552, Test Loss: 1.5281\n",
      "Epoch [100/400], Train Loss: 0.0562, Test Loss: 1.4987\n",
      "Epoch [101/400], Train Loss: 0.0660, Test Loss: 1.5245\n",
      "Epoch [102/400], Train Loss: 0.0505, Test Loss: 1.5377\n",
      "Epoch [103/400], Train Loss: 0.0515, Test Loss: 1.5232\n",
      "Epoch [104/400], Train Loss: 0.0566, Test Loss: 1.5197\n",
      "Epoch [105/400], Train Loss: 0.0503, Test Loss: 1.5541\n",
      "Epoch [106/400], Train Loss: 0.0420, Test Loss: 1.5641\n",
      "Epoch [107/400], Train Loss: 0.0517, Test Loss: 1.6205\n",
      "Epoch [108/400], Train Loss: 0.0557, Test Loss: 1.6496\n",
      "Epoch [109/400], Train Loss: 0.0519, Test Loss: 1.5602\n",
      "Epoch [110/400], Train Loss: 0.0414, Test Loss: 1.4916\n",
      "Epoch [111/400], Train Loss: 0.0389, Test Loss: 1.6099\n",
      "Epoch [112/400], Train Loss: 0.0345, Test Loss: 1.6133\n",
      "Epoch [113/400], Train Loss: 0.0370, Test Loss: 1.5870\n",
      "Epoch [114/400], Train Loss: 0.0429, Test Loss: 1.6079\n",
      "Epoch [115/400], Train Loss: 0.0392, Test Loss: 1.6033\n",
      "Epoch [116/400], Train Loss: 0.0339, Test Loss: 1.5948\n",
      "Epoch [117/400], Train Loss: 0.0278, Test Loss: 1.6272\n",
      "Epoch [118/400], Train Loss: 0.0274, Test Loss: 1.5909\n",
      "Epoch [119/400], Train Loss: 0.0327, Test Loss: 1.6014\n",
      "Epoch [120/400], Train Loss: 0.0270, Test Loss: 1.6015\n",
      "Epoch [121/400], Train Loss: 0.0271, Test Loss: 1.5921\n",
      "Epoch [122/400], Train Loss: 0.0274, Test Loss: 1.5775\n",
      "Epoch [123/400], Train Loss: 0.0251, Test Loss: 1.6436\n",
      "Epoch [124/400], Train Loss: 0.0282, Test Loss: 1.5966\n",
      "Epoch [125/400], Train Loss: 0.0258, Test Loss: 1.6484\n",
      "Epoch [126/400], Train Loss: 0.0282, Test Loss: 1.5497\n",
      "Epoch [127/400], Train Loss: 0.0291, Test Loss: 1.6163\n",
      "Epoch [128/400], Train Loss: 0.0311, Test Loss: 1.5956\n",
      "Epoch [129/400], Train Loss: 0.0359, Test Loss: 1.5395\n",
      "Epoch [130/400], Train Loss: 0.0434, Test Loss: 1.5288\n",
      "Epoch [131/400], Train Loss: 0.0328, Test Loss: 1.6271\n",
      "Epoch [132/400], Train Loss: 0.0278, Test Loss: 1.5918\n",
      "Epoch [133/400], Train Loss: 0.0263, Test Loss: 1.5568\n",
      "Epoch [134/400], Train Loss: 0.0227, Test Loss: 1.6161\n",
      "Epoch [135/400], Train Loss: 0.0255, Test Loss: 1.5934\n",
      "Epoch [136/400], Train Loss: 0.0243, Test Loss: 1.5948\n",
      "Epoch [137/400], Train Loss: 0.0205, Test Loss: 1.6482\n",
      "Epoch [138/400], Train Loss: 0.0204, Test Loss: 1.5754\n",
      "Epoch [139/400], Train Loss: 0.0401, Test Loss: 1.6538\n",
      "Epoch [140/400], Train Loss: 0.0678, Test Loss: 1.5922\n",
      "Epoch [141/400], Train Loss: 0.0999, Test Loss: 1.5802\n",
      "Epoch [142/400], Train Loss: 0.3832, Test Loss: 1.3781\n",
      "Epoch [143/400], Train Loss: 0.4263, Test Loss: 1.4238\n",
      "Epoch [144/400], Train Loss: 0.2943, Test Loss: 1.4998\n",
      "Epoch [145/400], Train Loss: 0.1718, Test Loss: 1.5042\n",
      "Epoch [146/400], Train Loss: 0.1300, Test Loss: 1.5442\n",
      "Epoch [147/400], Train Loss: 0.0722, Test Loss: 1.5009\n",
      "Epoch [148/400], Train Loss: 0.0514, Test Loss: 1.5396\n",
      "Epoch [149/400], Train Loss: 0.0379, Test Loss: 1.5891\n",
      "Epoch [150/400], Train Loss: 0.0301, Test Loss: 1.5586\n",
      "Epoch [151/400], Train Loss: 0.0241, Test Loss: 1.5607\n",
      "Epoch [152/400], Train Loss: 0.0208, Test Loss: 1.5465\n",
      "Epoch [153/400], Train Loss: 0.0199, Test Loss: 1.5391\n",
      "Epoch [154/400], Train Loss: 0.0158, Test Loss: 1.5602\n",
      "Epoch [155/400], Train Loss: 0.0154, Test Loss: 1.5670\n",
      "Epoch [156/400], Train Loss: 0.0141, Test Loss: 1.5788\n",
      "Epoch [157/400], Train Loss: 0.0153, Test Loss: 1.5674\n",
      "Epoch [158/400], Train Loss: 0.0126, Test Loss: 1.5752\n",
      "Epoch [159/400], Train Loss: 0.0117, Test Loss: 1.5743\n",
      "Epoch [160/400], Train Loss: 0.0107, Test Loss: 1.6030\n",
      "Epoch [161/400], Train Loss: 0.0107, Test Loss: 1.5666\n",
      "Epoch [162/400], Train Loss: 0.0092, Test Loss: 1.5868\n",
      "Epoch [163/400], Train Loss: 0.0086, Test Loss: 1.5814\n",
      "Epoch [164/400], Train Loss: 0.0096, Test Loss: 1.5785\n",
      "Epoch [165/400], Train Loss: 0.0107, Test Loss: 1.5735\n",
      "Epoch [166/400], Train Loss: 0.0097, Test Loss: 1.5878\n",
      "Epoch [167/400], Train Loss: 0.0088, Test Loss: 1.5673\n",
      "Epoch [168/400], Train Loss: 0.0074, Test Loss: 1.5651\n",
      "Epoch [169/400], Train Loss: 0.0083, Test Loss: 1.5895\n",
      "Epoch [170/400], Train Loss: 0.0109, Test Loss: 1.5913\n",
      "Epoch [171/400], Train Loss: 0.0127, Test Loss: 1.5874\n",
      "Epoch [172/400], Train Loss: 0.0157, Test Loss: 1.5943\n",
      "Epoch [173/400], Train Loss: 0.0232, Test Loss: 1.5610\n",
      "Epoch [174/400], Train Loss: 0.0319, Test Loss: 1.5883\n",
      "Epoch [175/400], Train Loss: 0.0280, Test Loss: 1.5520\n",
      "Epoch [176/400], Train Loss: 0.0194, Test Loss: 1.5767\n",
      "Epoch [177/400], Train Loss: 0.0172, Test Loss: 1.5369\n",
      "Epoch [178/400], Train Loss: 0.0144, Test Loss: 1.5334\n",
      "Epoch [179/400], Train Loss: 0.0124, Test Loss: 1.5427\n",
      "Epoch [180/400], Train Loss: 0.0147, Test Loss: 1.5492\n",
      "Epoch [181/400], Train Loss: 0.0149, Test Loss: 1.5324\n",
      "Epoch [182/400], Train Loss: 0.0316, Test Loss: 1.5355\n",
      "Epoch [183/400], Train Loss: 0.0260, Test Loss: 1.5640\n",
      "Epoch [184/400], Train Loss: 0.0227, Test Loss: 1.5530\n",
      "Epoch [185/400], Train Loss: 0.0220, Test Loss: 1.5447\n",
      "Epoch [186/400], Train Loss: 0.0184, Test Loss: 1.5515\n",
      "Epoch [187/400], Train Loss: 0.0149, Test Loss: 1.5526\n",
      "Epoch [188/400], Train Loss: 0.0137, Test Loss: 1.5138\n",
      "Epoch [189/400], Train Loss: 0.0279, Test Loss: 1.5722\n",
      "Epoch [190/400], Train Loss: 0.0263, Test Loss: 1.5724\n",
      "Epoch [191/400], Train Loss: 0.0207, Test Loss: 1.5290\n",
      "Epoch [192/400], Train Loss: 0.0198, Test Loss: 1.5182\n",
      "Epoch [193/400], Train Loss: 0.0179, Test Loss: 1.5602\n",
      "Epoch [194/400], Train Loss: 0.0179, Test Loss: 1.5549\n",
      "Epoch [195/400], Train Loss: 0.0168, Test Loss: 1.5337\n",
      "Epoch [196/400], Train Loss: 0.0161, Test Loss: 1.5090\n",
      "Epoch [197/400], Train Loss: 0.0154, Test Loss: 1.5229\n",
      "Epoch [198/400], Train Loss: 0.0140, Test Loss: 1.5524\n",
      "Epoch [199/400], Train Loss: 0.0116, Test Loss: 1.5110\n",
      "Epoch [200/400], Train Loss: 0.0089, Test Loss: 1.5377\n",
      "Epoch [201/400], Train Loss: 0.0096, Test Loss: 1.5163\n",
      "Epoch [202/400], Train Loss: 0.0148, Test Loss: 1.5627\n",
      "Epoch [203/400], Train Loss: 0.0163, Test Loss: 1.5147\n",
      "Epoch [204/400], Train Loss: 0.0197, Test Loss: 1.5411\n",
      "Epoch [205/400], Train Loss: 0.0146, Test Loss: 1.4885\n",
      "Epoch [206/400], Train Loss: 0.0120, Test Loss: 1.5183\n",
      "Epoch [207/400], Train Loss: 0.0110, Test Loss: 1.5246\n",
      "Epoch [208/400], Train Loss: 0.0110, Test Loss: 1.5095\n",
      "Epoch [209/400], Train Loss: 0.0128, Test Loss: 1.5340\n",
      "Epoch [210/400], Train Loss: 0.0120, Test Loss: 1.5351\n",
      "Epoch [211/400], Train Loss: 0.0154, Test Loss: 1.5246\n",
      "Epoch [212/400], Train Loss: 0.0145, Test Loss: 1.5324\n",
      "Epoch [213/400], Train Loss: 0.0141, Test Loss: 1.4888\n",
      "Epoch [214/400], Train Loss: 0.0231, Test Loss: 1.5239\n",
      "Epoch [215/400], Train Loss: 0.0252, Test Loss: 1.6012\n",
      "Epoch [216/400], Train Loss: 0.0289, Test Loss: 1.4735\n",
      "Epoch [217/400], Train Loss: 0.0555, Test Loss: 1.5721\n",
      "Epoch [218/400], Train Loss: 0.0859, Test Loss: 1.5106\n",
      "Epoch [219/400], Train Loss: 0.2474, Test Loss: 1.4665\n",
      "Epoch [220/400], Train Loss: 0.3446, Test Loss: 1.4822\n",
      "Epoch [221/400], Train Loss: 0.2499, Test Loss: 1.4868\n",
      "Epoch [222/400], Train Loss: 0.0744, Test Loss: 1.4269\n",
      "Epoch [223/400], Train Loss: 0.0323, Test Loss: 1.4181\n",
      "Epoch [224/400], Train Loss: 0.0199, Test Loss: 1.4400\n",
      "Epoch [225/400], Train Loss: 0.0133, Test Loss: 1.4194\n",
      "Epoch [226/400], Train Loss: 0.0092, Test Loss: 1.4269\n",
      "Epoch [227/400], Train Loss: 0.0072, Test Loss: 1.4304\n",
      "Epoch [228/400], Train Loss: 0.0058, Test Loss: 1.4326\n",
      "Epoch [229/400], Train Loss: 0.0046, Test Loss: 1.4203\n",
      "Epoch [230/400], Train Loss: 0.0040, Test Loss: 1.4318\n",
      "Epoch [231/400], Train Loss: 0.0037, Test Loss: 1.4417\n",
      "Epoch [232/400], Train Loss: 0.0030, Test Loss: 1.4328\n",
      "Epoch [233/400], Train Loss: 0.0027, Test Loss: 1.4338\n",
      "Epoch [234/400], Train Loss: 0.0021, Test Loss: 1.4403\n",
      "Epoch [235/400], Train Loss: 0.0020, Test Loss: 1.4388\n",
      "Epoch [236/400], Train Loss: 0.0018, Test Loss: 1.4367\n",
      "Epoch [237/400], Train Loss: 0.0016, Test Loss: 1.4435\n",
      "Epoch [238/400], Train Loss: 0.0019, Test Loss: 1.4404\n",
      "Epoch [239/400], Train Loss: 0.0020, Test Loss: 1.4521\n",
      "Epoch [240/400], Train Loss: 0.0020, Test Loss: 1.4548\n",
      "Epoch [241/400], Train Loss: 0.0021, Test Loss: 1.4505\n",
      "Epoch [242/400], Train Loss: 0.0025, Test Loss: 1.4433\n",
      "Epoch [243/400], Train Loss: 0.0032, Test Loss: 1.4648\n",
      "Epoch [244/400], Train Loss: 0.0031, Test Loss: 1.4452\n",
      "Epoch [245/400], Train Loss: 0.0029, Test Loss: 1.4599\n",
      "Epoch [246/400], Train Loss: 0.0019, Test Loss: 1.4565\n",
      "Epoch [247/400], Train Loss: 0.0021, Test Loss: 1.4597\n",
      "Epoch [248/400], Train Loss: 0.0023, Test Loss: 1.4638\n",
      "Epoch [249/400], Train Loss: 0.0028, Test Loss: 1.4578\n",
      "Epoch [250/400], Train Loss: 0.0029, Test Loss: 1.4422\n",
      "Epoch [251/400], Train Loss: 0.0032, Test Loss: 1.4688\n",
      "Epoch [252/400], Train Loss: 0.0046, Test Loss: 1.4344\n",
      "Epoch [253/400], Train Loss: 0.0055, Test Loss: 1.4614\n",
      "Epoch [254/400], Train Loss: 0.0072, Test Loss: 1.4572\n",
      "Epoch [255/400], Train Loss: 0.0085, Test Loss: 1.4573\n",
      "Epoch [256/400], Train Loss: 0.0124, Test Loss: 1.4409\n",
      "Epoch [257/400], Train Loss: 0.0151, Test Loss: 1.4742\n",
      "Epoch [258/400], Train Loss: 0.0198, Test Loss: 1.4288\n",
      "Epoch [259/400], Train Loss: 0.0224, Test Loss: 1.4415\n",
      "Epoch [260/400], Train Loss: 0.0194, Test Loss: 1.4775\n",
      "Epoch [261/400], Train Loss: 0.0174, Test Loss: 1.4494\n",
      "Epoch [262/400], Train Loss: 0.0144, Test Loss: 1.4883\n",
      "Epoch [263/400], Train Loss: 0.0105, Test Loss: 1.4194\n",
      "Epoch [264/400], Train Loss: 0.0088, Test Loss: 1.4569\n",
      "Epoch [265/400], Train Loss: 0.0067, Test Loss: 1.4195\n",
      "Epoch [266/400], Train Loss: 0.0062, Test Loss: 1.4590\n",
      "Epoch [267/400], Train Loss: 0.0058, Test Loss: 1.4451\n",
      "Epoch [268/400], Train Loss: 0.0068, Test Loss: 1.4517\n",
      "Epoch [269/400], Train Loss: 0.0058, Test Loss: 1.4540\n",
      "Epoch [270/400], Train Loss: 0.0067, Test Loss: 1.4711\n",
      "Epoch [271/400], Train Loss: 0.0074, Test Loss: 1.4471\n",
      "Epoch [272/400], Train Loss: 0.0088, Test Loss: 1.4484\n",
      "Epoch [273/400], Train Loss: 0.0109, Test Loss: 1.4719\n",
      "Epoch [274/400], Train Loss: 0.0111, Test Loss: 1.4083\n",
      "Epoch [275/400], Train Loss: 0.0110, Test Loss: 1.4621\n",
      "Epoch [276/400], Train Loss: 0.0112, Test Loss: 1.4269\n",
      "Epoch [277/400], Train Loss: 0.0132, Test Loss: 1.3997\n",
      "Epoch [278/400], Train Loss: 0.0134, Test Loss: 1.4539\n",
      "Epoch [279/400], Train Loss: 0.0161, Test Loss: 1.4611\n",
      "Epoch [280/400], Train Loss: 0.0204, Test Loss: 1.4731\n",
      "Epoch [281/400], Train Loss: 0.0168, Test Loss: 1.4417\n",
      "Epoch [282/400], Train Loss: 0.0179, Test Loss: 1.4904\n",
      "Epoch [283/400], Train Loss: 0.0246, Test Loss: 1.4692\n",
      "Epoch [284/400], Train Loss: 0.0333, Test Loss: 1.4756\n",
      "Epoch [285/400], Train Loss: 0.0364, Test Loss: 1.4882\n",
      "Epoch [286/400], Train Loss: 0.0295, Test Loss: 1.4717\n",
      "Epoch [287/400], Train Loss: 0.0188, Test Loss: 1.4525\n",
      "Epoch [288/400], Train Loss: 0.0131, Test Loss: 1.4587\n",
      "Epoch [289/400], Train Loss: 0.0078, Test Loss: 1.4516\n",
      "Epoch [290/400], Train Loss: 0.0047, Test Loss: 1.4358\n",
      "Epoch [291/400], Train Loss: 0.0034, Test Loss: 1.4463\n",
      "Epoch [292/400], Train Loss: 0.0027, Test Loss: 1.4343\n",
      "Epoch [293/400], Train Loss: 0.0019, Test Loss: 1.4256\n",
      "Epoch [294/400], Train Loss: 0.0015, Test Loss: 1.4272\n",
      "Epoch [295/400], Train Loss: 0.0015, Test Loss: 1.4432\n",
      "Epoch [296/400], Train Loss: 0.0013, Test Loss: 1.4289\n",
      "Epoch [297/400], Train Loss: 0.0014, Test Loss: 1.4401\n",
      "Epoch [298/400], Train Loss: 0.0013, Test Loss: 1.4363\n",
      "Epoch [299/400], Train Loss: 0.0013, Test Loss: 1.4258\n",
      "Epoch [300/400], Train Loss: 0.0014, Test Loss: 1.4308\n",
      "Epoch [301/400], Train Loss: 0.0013, Test Loss: 1.4289\n",
      "Epoch [302/400], Train Loss: 0.0016, Test Loss: 1.4296\n",
      "Epoch [303/400], Train Loss: 0.0022, Test Loss: 1.4281\n",
      "Epoch [304/400], Train Loss: 0.0029, Test Loss: 1.4690\n",
      "Epoch [305/400], Train Loss: 0.0050, Test Loss: 1.4433\n",
      "Epoch [306/400], Train Loss: 0.0088, Test Loss: 1.4338\n",
      "Epoch [307/400], Train Loss: 0.0135, Test Loss: 1.4340\n",
      "Epoch [308/400], Train Loss: 0.0492, Test Loss: 1.4853\n",
      "Epoch [309/400], Train Loss: 0.3244, Test Loss: 1.5741\n",
      "Epoch [310/400], Train Loss: 0.6268, Test Loss: 1.4712\n",
      "Epoch [311/400], Train Loss: 0.3758, Test Loss: 1.5611\n",
      "Epoch [312/400], Train Loss: 0.1383, Test Loss: 1.5080\n",
      "Epoch [313/400], Train Loss: 0.0559, Test Loss: 1.4914\n",
      "Epoch [314/400], Train Loss: 0.0308, Test Loss: 1.4913\n",
      "Epoch [315/400], Train Loss: 0.0207, Test Loss: 1.4715\n",
      "Epoch [316/400], Train Loss: 0.0141, Test Loss: 1.4916\n",
      "Epoch [317/400], Train Loss: 0.0119, Test Loss: 1.4949\n",
      "Epoch [318/400], Train Loss: 0.0098, Test Loss: 1.4877\n",
      "Epoch [319/400], Train Loss: 0.0075, Test Loss: 1.4986\n",
      "Epoch [320/400], Train Loss: 0.0058, Test Loss: 1.5028\n",
      "Epoch [321/400], Train Loss: 0.0050, Test Loss: 1.5075\n",
      "Epoch [322/400], Train Loss: 0.0042, Test Loss: 1.5012\n",
      "Epoch [323/400], Train Loss: 0.0036, Test Loss: 1.5064\n",
      "Epoch [324/400], Train Loss: 0.0030, Test Loss: 1.5039\n",
      "Epoch [325/400], Train Loss: 0.0025, Test Loss: 1.5032\n",
      "Epoch [326/400], Train Loss: 0.0023, Test Loss: 1.5010\n",
      "Epoch [327/400], Train Loss: 0.0021, Test Loss: 1.5067\n",
      "Epoch [328/400], Train Loss: 0.0017, Test Loss: 1.5065\n",
      "Epoch [329/400], Train Loss: 0.0017, Test Loss: 1.5018\n",
      "Epoch [330/400], Train Loss: 0.0014, Test Loss: 1.5067\n",
      "Epoch [331/400], Train Loss: 0.0012, Test Loss: 1.5066\n",
      "Epoch [332/400], Train Loss: 0.0011, Test Loss: 1.5055\n",
      "Epoch [333/400], Train Loss: 0.0010, Test Loss: 1.5096\n",
      "Epoch [334/400], Train Loss: 0.0010, Test Loss: 1.5036\n",
      "Epoch [335/400], Train Loss: 0.0009, Test Loss: 1.5017\n",
      "Epoch [336/400], Train Loss: 0.0008, Test Loss: 1.5073\n",
      "Epoch [337/400], Train Loss: 0.0008, Test Loss: 1.5017\n",
      "Epoch [338/400], Train Loss: 0.0009, Test Loss: 1.5042\n",
      "Epoch [339/400], Train Loss: 0.0012, Test Loss: 1.4962\n",
      "Epoch [340/400], Train Loss: 0.0017, Test Loss: 1.5085\n",
      "Epoch [341/400], Train Loss: 0.0019, Test Loss: 1.5069\n",
      "Epoch [342/400], Train Loss: 0.0024, Test Loss: 1.5055\n",
      "Epoch [343/400], Train Loss: 0.0029, Test Loss: 1.5136\n",
      "Epoch [344/400], Train Loss: 0.0032, Test Loss: 1.4980\n",
      "Epoch [345/400], Train Loss: 0.0037, Test Loss: 1.5052\n",
      "Epoch [346/400], Train Loss: 0.0044, Test Loss: 1.4872\n",
      "Epoch [347/400], Train Loss: 0.0067, Test Loss: 1.4956\n",
      "Epoch [348/400], Train Loss: 0.0080, Test Loss: 1.4868\n",
      "Epoch [349/400], Train Loss: 0.0117, Test Loss: 1.4968\n",
      "Epoch [350/400], Train Loss: 0.0117, Test Loss: 1.4906\n",
      "Epoch [351/400], Train Loss: 0.0116, Test Loss: 1.4751\n",
      "Epoch [352/400], Train Loss: 0.0108, Test Loss: 1.4984\n",
      "Epoch [353/400], Train Loss: 0.0105, Test Loss: 1.5099\n",
      "Epoch [354/400], Train Loss: 0.0083, Test Loss: 1.4774\n",
      "Epoch [355/400], Train Loss: 0.0093, Test Loss: 1.5045\n",
      "Epoch [356/400], Train Loss: 0.0089, Test Loss: 1.4780\n",
      "Epoch [357/400], Train Loss: 0.0080, Test Loss: 1.4836\n",
      "Epoch [358/400], Train Loss: 0.0294, Test Loss: 1.5243\n",
      "Epoch [359/400], Train Loss: 0.0425, Test Loss: 1.5429\n",
      "Epoch [360/400], Train Loss: 0.0313, Test Loss: 1.5208\n",
      "Epoch [361/400], Train Loss: 0.0237, Test Loss: 1.5389\n",
      "Epoch [362/400], Train Loss: 0.0149, Test Loss: 1.4863\n",
      "Epoch [363/400], Train Loss: 0.0110, Test Loss: 1.5565\n",
      "Epoch [364/400], Train Loss: 0.0090, Test Loss: 1.5031\n",
      "Epoch [365/400], Train Loss: 0.0066, Test Loss: 1.5191\n",
      "Epoch [366/400], Train Loss: 0.0045, Test Loss: 1.4977\n",
      "Epoch [367/400], Train Loss: 0.0034, Test Loss: 1.5168\n",
      "Epoch [368/400], Train Loss: 0.0025, Test Loss: 1.5119\n",
      "Epoch [369/400], Train Loss: 0.0021, Test Loss: 1.5096\n",
      "Epoch [370/400], Train Loss: 0.0015, Test Loss: 1.5169\n",
      "Epoch [371/400], Train Loss: 0.0013, Test Loss: 1.5147\n",
      "Epoch [372/400], Train Loss: 0.0014, Test Loss: 1.5096\n",
      "Epoch [373/400], Train Loss: 0.0014, Test Loss: 1.5090\n",
      "Epoch [374/400], Train Loss: 0.0016, Test Loss: 1.5188\n",
      "Epoch [375/400], Train Loss: 0.0017, Test Loss: 1.5105\n",
      "Epoch [376/400], Train Loss: 0.0016, Test Loss: 1.5085\n",
      "Epoch [377/400], Train Loss: 0.0015, Test Loss: 1.5119\n",
      "Epoch [378/400], Train Loss: 0.0015, Test Loss: 1.5109\n",
      "Epoch [379/400], Train Loss: 0.0015, Test Loss: 1.5152\n",
      "Epoch [380/400], Train Loss: 0.0021, Test Loss: 1.5189\n",
      "Epoch [381/400], Train Loss: 0.0032, Test Loss: 1.5088\n",
      "Epoch [382/400], Train Loss: 0.0049, Test Loss: 1.4925\n",
      "Epoch [383/400], Train Loss: 0.0082, Test Loss: 1.4940\n",
      "Epoch [384/400], Train Loss: 0.0123, Test Loss: 1.5008\n",
      "Epoch [385/400], Train Loss: 0.0250, Test Loss: 1.4789\n",
      "Epoch [386/400], Train Loss: 0.0530, Test Loss: 1.5429\n",
      "Epoch [387/400], Train Loss: 0.1208, Test Loss: 1.4584\n",
      "Epoch [388/400], Train Loss: 0.1935, Test Loss: 1.5147\n",
      "Epoch [389/400], Train Loss: 0.0964, Test Loss: 1.4576\n",
      "Epoch [390/400], Train Loss: 0.0641, Test Loss: 1.5336\n",
      "Epoch [391/400], Train Loss: 0.0264, Test Loss: 1.4673\n",
      "Epoch [392/400], Train Loss: 0.0139, Test Loss: 1.4753\n",
      "Epoch [393/400], Train Loss: 0.0085, Test Loss: 1.4535\n",
      "Epoch [394/400], Train Loss: 0.0059, Test Loss: 1.4584\n",
      "Epoch [395/400], Train Loss: 0.0043, Test Loss: 1.4439\n",
      "Epoch [396/400], Train Loss: 0.0031, Test Loss: 1.4589\n",
      "Epoch [397/400], Train Loss: 0.0023, Test Loss: 1.4594\n",
      "Epoch [398/400], Train Loss: 0.0019, Test Loss: 1.4614\n",
      "Epoch [399/400], Train Loss: 0.0017, Test Loss: 1.4596\n",
      "Epoch [400/400], Train Loss: 0.0015, Test Loss: 1.4602\n",
      "Epoch [1/400], Train Loss: 38.0487, Test Loss: 67.5921\n",
      "Epoch [2/400], Train Loss: 37.6615, Test Loss: 67.8209\n",
      "Epoch [3/400], Train Loss: 37.6759, Test Loss: 67.0157\n",
      "Epoch [4/400], Train Loss: 38.7984, Test Loss: 67.3788\n",
      "Epoch [5/400], Train Loss: 38.0798, Test Loss: 67.3421\n",
      "Epoch [6/400], Train Loss: 37.5409, Test Loss: 67.0456\n",
      "Epoch [7/400], Train Loss: 37.4523, Test Loss: 69.3979\n",
      "Epoch [8/400], Train Loss: 37.4652, Test Loss: 66.8117\n",
      "Epoch [9/400], Train Loss: 37.3121, Test Loss: 67.4190\n",
      "Epoch [10/400], Train Loss: 37.2824, Test Loss: 66.2861\n",
      "Epoch [11/400], Train Loss: 37.4125, Test Loss: 66.2531\n",
      "Epoch [12/400], Train Loss: 37.3112, Test Loss: 66.9792\n",
      "Epoch [13/400], Train Loss: 37.4121, Test Loss: 66.8874\n",
      "Epoch [14/400], Train Loss: 39.3443, Test Loss: 66.3891\n",
      "Epoch [15/400], Train Loss: 36.9350, Test Loss: 67.6980\n",
      "Epoch [16/400], Train Loss: 36.7370, Test Loss: 65.8420\n",
      "Epoch [17/400], Train Loss: 36.6586, Test Loss: 66.3085\n",
      "Epoch [18/400], Train Loss: 36.8109, Test Loss: 66.5575\n",
      "Epoch [19/400], Train Loss: 36.0121, Test Loss: 65.6479\n",
      "Epoch [20/400], Train Loss: 36.2729, Test Loss: 65.6988\n",
      "Epoch [21/400], Train Loss: 35.9145, Test Loss: 67.8850\n",
      "Epoch [22/400], Train Loss: 35.9238, Test Loss: 65.9152\n",
      "Epoch [23/400], Train Loss: 35.9057, Test Loss: 68.3114\n",
      "Epoch [24/400], Train Loss: 36.9328, Test Loss: 65.9224\n",
      "Epoch [25/400], Train Loss: 37.3862, Test Loss: 65.9228\n",
      "Epoch [26/400], Train Loss: 35.3051, Test Loss: 66.3402\n",
      "Epoch [27/400], Train Loss: 34.6955, Test Loss: 65.8977\n",
      "Epoch [28/400], Train Loss: 35.8074, Test Loss: 65.2678\n",
      "Epoch [29/400], Train Loss: 34.6064, Test Loss: 64.1003\n",
      "Epoch [30/400], Train Loss: 33.4688, Test Loss: 66.0878\n",
      "Epoch [31/400], Train Loss: 34.3246, Test Loss: 67.5824\n",
      "Epoch [32/400], Train Loss: 34.7402, Test Loss: 65.5965\n",
      "Epoch [33/400], Train Loss: 33.3683, Test Loss: 65.8180\n",
      "Epoch [34/400], Train Loss: 34.7877, Test Loss: 66.3865\n",
      "Epoch [35/400], Train Loss: 33.0377, Test Loss: 65.2265\n",
      "Epoch [36/400], Train Loss: 32.7572, Test Loss: 65.7862\n",
      "Epoch [37/400], Train Loss: 31.2077, Test Loss: 63.7375\n",
      "Epoch [38/400], Train Loss: 31.3230, Test Loss: 66.8098\n",
      "Epoch [39/400], Train Loss: 30.5415, Test Loss: 66.4663\n",
      "Epoch [40/400], Train Loss: 31.0615, Test Loss: 62.7836\n",
      "Epoch [41/400], Train Loss: 31.6260, Test Loss: 67.2946\n",
      "Epoch [42/400], Train Loss: 31.0978, Test Loss: 66.5005\n",
      "Epoch [43/400], Train Loss: 30.9529, Test Loss: 64.7288\n",
      "Epoch [44/400], Train Loss: 28.5582, Test Loss: 65.3898\n",
      "Epoch [45/400], Train Loss: 27.9897, Test Loss: 66.9222\n",
      "Epoch [46/400], Train Loss: 28.5916, Test Loss: 64.5827\n",
      "Epoch [47/400], Train Loss: 28.3811, Test Loss: 65.7752\n",
      "Epoch [48/400], Train Loss: 27.8528, Test Loss: 64.3133\n",
      "Epoch [49/400], Train Loss: 31.3155, Test Loss: 64.9673\n",
      "Epoch [50/400], Train Loss: 28.7780, Test Loss: 68.4153\n",
      "Epoch [51/400], Train Loss: 27.8323, Test Loss: 69.4296\n",
      "Epoch [52/400], Train Loss: 25.8374, Test Loss: 68.2961\n",
      "Epoch [53/400], Train Loss: 25.8975, Test Loss: 68.2076\n",
      "Epoch [54/400], Train Loss: 23.6365, Test Loss: 70.7879\n",
      "Epoch [55/400], Train Loss: 25.9082, Test Loss: 65.9514\n",
      "Epoch [56/400], Train Loss: 23.0787, Test Loss: 68.0325\n",
      "Epoch [57/400], Train Loss: 22.9298, Test Loss: 67.2996\n",
      "Epoch [58/400], Train Loss: 22.1027, Test Loss: 68.2785\n",
      "Epoch [59/400], Train Loss: 22.3519, Test Loss: 69.1415\n",
      "Epoch [60/400], Train Loss: 21.6611, Test Loss: 69.8842\n",
      "Epoch [61/400], Train Loss: 21.2721, Test Loss: 70.0911\n",
      "Epoch [62/400], Train Loss: 20.3147, Test Loss: 71.8133\n",
      "Epoch [63/400], Train Loss: 21.0724, Test Loss: 68.5821\n",
      "Epoch [64/400], Train Loss: 19.5794, Test Loss: 69.9356\n",
      "Epoch [65/400], Train Loss: 18.6951, Test Loss: 67.4006\n",
      "Epoch [66/400], Train Loss: 17.8155, Test Loss: 70.0665\n",
      "Epoch [67/400], Train Loss: 23.3713, Test Loss: 70.0862\n",
      "Epoch [68/400], Train Loss: 19.7041, Test Loss: 71.0541\n",
      "Epoch [69/400], Train Loss: 17.5991, Test Loss: 69.0785\n",
      "Epoch [70/400], Train Loss: 17.6525, Test Loss: 70.0719\n",
      "Epoch [71/400], Train Loss: 16.5808, Test Loss: 69.0310\n",
      "Epoch [72/400], Train Loss: 14.8472, Test Loss: 69.9572\n",
      "Epoch [73/400], Train Loss: 13.6290, Test Loss: 73.7773\n",
      "Epoch [74/400], Train Loss: 30.1330, Test Loss: 69.1426\n",
      "Epoch [75/400], Train Loss: 23.8945, Test Loss: 69.9890\n",
      "Epoch [76/400], Train Loss: 25.8104, Test Loss: 71.1919\n",
      "Epoch [77/400], Train Loss: 22.0894, Test Loss: 69.5520\n",
      "Epoch [78/400], Train Loss: 18.6535, Test Loss: 69.2573\n",
      "Epoch [79/400], Train Loss: 17.6180, Test Loss: 71.3749\n",
      "Epoch [80/400], Train Loss: 16.6365, Test Loss: 70.6984\n",
      "Epoch [81/400], Train Loss: 15.1080, Test Loss: 71.6765\n",
      "Epoch [82/400], Train Loss: 15.5992, Test Loss: 71.1530\n",
      "Epoch [83/400], Train Loss: 16.5080, Test Loss: 73.6983\n",
      "Epoch [84/400], Train Loss: 13.8552, Test Loss: 71.4228\n",
      "Epoch [85/400], Train Loss: 14.6119, Test Loss: 71.9208\n",
      "Epoch [86/400], Train Loss: 13.0145, Test Loss: 71.8369\n",
      "Epoch [87/400], Train Loss: 13.0542, Test Loss: 71.8828\n",
      "Epoch [88/400], Train Loss: 13.3149, Test Loss: 70.9929\n",
      "Epoch [89/400], Train Loss: 12.1735, Test Loss: 68.1447\n",
      "Epoch [90/400], Train Loss: 12.3005, Test Loss: 71.2920\n",
      "Epoch [91/400], Train Loss: 20.2116, Test Loss: 70.1355\n",
      "Epoch [92/400], Train Loss: 14.9847, Test Loss: 77.3616\n",
      "Epoch [93/400], Train Loss: 13.1272, Test Loss: 70.8830\n",
      "Epoch [94/400], Train Loss: 11.2611, Test Loss: 70.2129\n",
      "Epoch [95/400], Train Loss: 10.1768, Test Loss: 70.9415\n",
      "Epoch [96/400], Train Loss: 11.5101, Test Loss: 70.3827\n",
      "Epoch [97/400], Train Loss: 29.2767, Test Loss: 64.1355\n",
      "Epoch [98/400], Train Loss: 25.8553, Test Loss: 68.5552\n",
      "Epoch [99/400], Train Loss: 22.2332, Test Loss: 66.0562\n",
      "Epoch [100/400], Train Loss: 21.1278, Test Loss: 69.0708\n",
      "Epoch [101/400], Train Loss: 32.3108, Test Loss: 67.1612\n",
      "Epoch [102/400], Train Loss: 26.9475, Test Loss: 72.1156\n",
      "Epoch [103/400], Train Loss: 21.2951, Test Loss: 70.7845\n",
      "Epoch [104/400], Train Loss: 22.1005, Test Loss: 77.6713\n",
      "Epoch [105/400], Train Loss: 15.6031, Test Loss: 81.6718\n",
      "Epoch [106/400], Train Loss: 13.6560, Test Loss: 73.6548\n",
      "Epoch [107/400], Train Loss: 11.6247, Test Loss: 73.7535\n",
      "Epoch [108/400], Train Loss: 11.5706, Test Loss: 72.1499\n",
      "Epoch [109/400], Train Loss: 11.9384, Test Loss: 71.1685\n",
      "Epoch [110/400], Train Loss: 9.1979, Test Loss: 72.4057\n",
      "Epoch [111/400], Train Loss: 9.1852, Test Loss: 71.4332\n",
      "Epoch [112/400], Train Loss: 8.3651, Test Loss: 70.6309\n",
      "Epoch [113/400], Train Loss: 10.1779, Test Loss: 68.5970\n",
      "Epoch [114/400], Train Loss: 12.7071, Test Loss: 71.7283\n",
      "Epoch [115/400], Train Loss: 9.6247, Test Loss: 73.8720\n",
      "Epoch [116/400], Train Loss: 16.8889, Test Loss: 70.6458\n",
      "Epoch [117/400], Train Loss: 19.4297, Test Loss: 66.1508\n",
      "Epoch [118/400], Train Loss: 26.9540, Test Loss: 64.3322\n",
      "Epoch [119/400], Train Loss: 24.6726, Test Loss: 63.1447\n",
      "Epoch [120/400], Train Loss: 21.5330, Test Loss: 64.0462\n",
      "Epoch [121/400], Train Loss: 17.5211, Test Loss: 67.3692\n",
      "Epoch [122/400], Train Loss: 15.1929, Test Loss: 68.9470\n",
      "Epoch [123/400], Train Loss: 12.9583, Test Loss: 68.9352\n",
      "Epoch [124/400], Train Loss: 11.8494, Test Loss: 76.3456\n",
      "Epoch [125/400], Train Loss: 14.2293, Test Loss: 72.3504\n",
      "Epoch [126/400], Train Loss: 13.4015, Test Loss: 72.4381\n",
      "Epoch [127/400], Train Loss: 9.3642, Test Loss: 68.6095\n",
      "Epoch [128/400], Train Loss: 9.4675, Test Loss: 71.2683\n",
      "Epoch [129/400], Train Loss: 7.3628, Test Loss: 68.3639\n",
      "Epoch [130/400], Train Loss: 9.1356, Test Loss: 69.8577\n",
      "Epoch [131/400], Train Loss: 10.6670, Test Loss: 67.1045\n",
      "Epoch [132/400], Train Loss: 9.2101, Test Loss: 68.1933\n",
      "Epoch [133/400], Train Loss: 7.7214, Test Loss: 73.2538\n",
      "Epoch [134/400], Train Loss: 8.5309, Test Loss: 67.9159\n",
      "Epoch [135/400], Train Loss: 9.7264, Test Loss: 66.7436\n",
      "Epoch [136/400], Train Loss: 8.0420, Test Loss: 68.8618\n",
      "Epoch [137/400], Train Loss: 8.4558, Test Loss: 74.1714\n",
      "Epoch [138/400], Train Loss: 17.6342, Test Loss: 68.2746\n",
      "Epoch [139/400], Train Loss: 8.1634, Test Loss: 68.6086\n",
      "Epoch [140/400], Train Loss: 7.2937, Test Loss: 68.1077\n",
      "Epoch [141/400], Train Loss: 6.0762, Test Loss: 69.3121\n",
      "Epoch [142/400], Train Loss: 8.0034, Test Loss: 70.5214\n",
      "Epoch [143/400], Train Loss: 8.8875, Test Loss: 67.0973\n",
      "Epoch [144/400], Train Loss: 8.3485, Test Loss: 68.6991\n",
      "Epoch [145/400], Train Loss: 6.3187, Test Loss: 69.0537\n",
      "Epoch [146/400], Train Loss: 6.3481, Test Loss: 68.6381\n",
      "Epoch [147/400], Train Loss: 5.5595, Test Loss: 68.9546\n",
      "Epoch [148/400], Train Loss: 5.9807, Test Loss: 68.1609\n",
      "Epoch [149/400], Train Loss: 5.5732, Test Loss: 69.6241\n",
      "Epoch [150/400], Train Loss: 5.3238, Test Loss: 69.2735\n",
      "Epoch [151/400], Train Loss: 4.6547, Test Loss: 69.0516\n",
      "Epoch [152/400], Train Loss: 4.5107, Test Loss: 68.3649\n",
      "Epoch [153/400], Train Loss: 4.4181, Test Loss: 69.6214\n",
      "Epoch [154/400], Train Loss: 4.4563, Test Loss: 69.9243\n",
      "Epoch [155/400], Train Loss: 4.5602, Test Loss: 67.8898\n",
      "Epoch [156/400], Train Loss: 4.5431, Test Loss: 71.2412\n",
      "Epoch [157/400], Train Loss: 4.4668, Test Loss: 69.4598\n",
      "Epoch [158/400], Train Loss: 4.8560, Test Loss: 69.3159\n",
      "Epoch [159/400], Train Loss: 4.7138, Test Loss: 70.3262\n",
      "Epoch [160/400], Train Loss: 4.2117, Test Loss: 71.8988\n",
      "Epoch [161/400], Train Loss: 4.1585, Test Loss: 69.1142\n",
      "Epoch [162/400], Train Loss: 4.5439, Test Loss: 69.5377\n",
      "Epoch [163/400], Train Loss: 4.3744, Test Loss: 69.3514\n",
      "Epoch [164/400], Train Loss: 4.3542, Test Loss: 69.8769\n",
      "Epoch [165/400], Train Loss: 4.8129, Test Loss: 70.7930\n",
      "Epoch [166/400], Train Loss: 4.3008, Test Loss: 70.1679\n",
      "Epoch [167/400], Train Loss: 4.7601, Test Loss: 71.1696\n",
      "Epoch [168/400], Train Loss: 4.3019, Test Loss: 68.8198\n",
      "Epoch [169/400], Train Loss: 5.0839, Test Loss: 69.6283\n",
      "Epoch [170/400], Train Loss: 4.2055, Test Loss: 68.7922\n",
      "Epoch [171/400], Train Loss: 4.2826, Test Loss: 66.7203\n",
      "Epoch [172/400], Train Loss: 3.7029, Test Loss: 68.1417\n",
      "Epoch [173/400], Train Loss: 3.5661, Test Loss: 67.9274\n",
      "Epoch [174/400], Train Loss: 3.7556, Test Loss: 66.5216\n",
      "Epoch [175/400], Train Loss: 4.6569, Test Loss: 68.8498\n",
      "Epoch [176/400], Train Loss: 25.9709, Test Loss: 68.1345\n",
      "Epoch [177/400], Train Loss: 32.4585, Test Loss: 75.7069\n",
      "Epoch [178/400], Train Loss: 23.9974, Test Loss: 64.2488\n",
      "Epoch [179/400], Train Loss: 36.8542, Test Loss: 67.0380\n",
      "Epoch [180/400], Train Loss: 35.1781, Test Loss: 67.5870\n",
      "Epoch [181/400], Train Loss: 34.0011, Test Loss: 69.0979\n",
      "Epoch [182/400], Train Loss: 33.1133, Test Loss: 67.3216\n",
      "Epoch [183/400], Train Loss: 32.3154, Test Loss: 66.9631\n",
      "Epoch [184/400], Train Loss: 31.4553, Test Loss: 67.8703\n",
      "Epoch [185/400], Train Loss: 30.8094, Test Loss: 68.6114\n",
      "Epoch [186/400], Train Loss: 30.4319, Test Loss: 66.8587\n",
      "Epoch [187/400], Train Loss: 30.3389, Test Loss: 67.4057\n",
      "Epoch [188/400], Train Loss: 28.0453, Test Loss: 70.0371\n",
      "Epoch [189/400], Train Loss: 26.5860, Test Loss: 69.7943\n",
      "Epoch [190/400], Train Loss: 27.4686, Test Loss: 68.1382\n",
      "Epoch [191/400], Train Loss: 26.5613, Test Loss: 65.9390\n",
      "Epoch [192/400], Train Loss: 22.3082, Test Loss: 69.9087\n",
      "Epoch [193/400], Train Loss: 22.9580, Test Loss: 69.9347\n",
      "Epoch [194/400], Train Loss: 21.0415, Test Loss: 65.5714\n",
      "Epoch [195/400], Train Loss: 19.0808, Test Loss: 67.0294\n",
      "Epoch [196/400], Train Loss: 20.1675, Test Loss: 67.5589\n",
      "Epoch [197/400], Train Loss: 17.5914, Test Loss: 67.4648\n",
      "Epoch [198/400], Train Loss: 17.1942, Test Loss: 69.2171\n",
      "Epoch [199/400], Train Loss: 16.1404, Test Loss: 70.5199\n",
      "Epoch [200/400], Train Loss: 15.5044, Test Loss: 69.2994\n",
      "Epoch [201/400], Train Loss: 21.0240, Test Loss: 71.4340\n",
      "Epoch [202/400], Train Loss: 15.7948, Test Loss: 66.6234\n",
      "Epoch [203/400], Train Loss: 14.4347, Test Loss: 68.5146\n",
      "Epoch [204/400], Train Loss: 13.9138, Test Loss: 68.3816\n",
      "Epoch [205/400], Train Loss: 13.5934, Test Loss: 67.8843\n",
      "Epoch [206/400], Train Loss: 13.3885, Test Loss: 67.5027\n",
      "Epoch [207/400], Train Loss: 12.7555, Test Loss: 67.9891\n",
      "Epoch [208/400], Train Loss: 12.8258, Test Loss: 68.7750\n",
      "Epoch [209/400], Train Loss: 13.2531, Test Loss: 71.2029\n",
      "Epoch [210/400], Train Loss: 13.2076, Test Loss: 66.6186\n",
      "Epoch [211/400], Train Loss: 12.4815, Test Loss: 68.3410\n",
      "Epoch [212/400], Train Loss: 12.8355, Test Loss: 67.8339\n",
      "Epoch [213/400], Train Loss: 13.1458, Test Loss: 68.7568\n",
      "Epoch [214/400], Train Loss: 12.0996, Test Loss: 67.3054\n",
      "Epoch [215/400], Train Loss: 12.3092, Test Loss: 68.3971\n",
      "Epoch [216/400], Train Loss: 11.8931, Test Loss: 67.7092\n",
      "Epoch [217/400], Train Loss: 16.5547, Test Loss: 71.8128\n",
      "Epoch [218/400], Train Loss: 18.4011, Test Loss: 69.4467\n",
      "Epoch [219/400], Train Loss: 24.4847, Test Loss: 75.8919\n",
      "Epoch [220/400], Train Loss: 29.2736, Test Loss: 68.7268\n",
      "Epoch [221/400], Train Loss: 25.8598, Test Loss: 68.7499\n",
      "Epoch [222/400], Train Loss: 21.3860, Test Loss: 69.4090\n",
      "Epoch [223/400], Train Loss: 17.5332, Test Loss: 66.2024\n",
      "Epoch [224/400], Train Loss: 14.4805, Test Loss: 65.9590\n",
      "Epoch [225/400], Train Loss: 12.9913, Test Loss: 65.9053\n",
      "Epoch [226/400], Train Loss: 12.9622, Test Loss: 67.2723\n",
      "Epoch [227/400], Train Loss: 11.9995, Test Loss: 68.4229\n",
      "Epoch [228/400], Train Loss: 12.2524, Test Loss: 66.7270\n",
      "Epoch [229/400], Train Loss: 12.1770, Test Loss: 69.9020\n",
      "Epoch [230/400], Train Loss: 12.4807, Test Loss: 66.8638\n",
      "Epoch [231/400], Train Loss: 11.0136, Test Loss: 69.2506\n",
      "Epoch [232/400], Train Loss: 11.8940, Test Loss: 67.2870\n",
      "Epoch [233/400], Train Loss: 10.4393, Test Loss: 68.4781\n",
      "Epoch [234/400], Train Loss: 11.0075, Test Loss: 72.6291\n",
      "Epoch [235/400], Train Loss: 9.8122, Test Loss: 67.9145\n",
      "Epoch [236/400], Train Loss: 8.9617, Test Loss: 68.8500\n",
      "Epoch [237/400], Train Loss: 9.1437, Test Loss: 68.8455\n",
      "Epoch [238/400], Train Loss: 9.3536, Test Loss: 69.9215\n",
      "Epoch [239/400], Train Loss: 11.0335, Test Loss: 68.1664\n",
      "Epoch [240/400], Train Loss: 19.1063, Test Loss: 69.8687\n",
      "Epoch [241/400], Train Loss: 16.1613, Test Loss: 68.1824\n",
      "Epoch [242/400], Train Loss: 11.1493, Test Loss: 69.9134\n",
      "Epoch [243/400], Train Loss: 9.8969, Test Loss: 70.7809\n",
      "Epoch [244/400], Train Loss: 9.6724, Test Loss: 67.8126\n",
      "Epoch [245/400], Train Loss: 8.7146, Test Loss: 72.3521\n",
      "Epoch [246/400], Train Loss: 9.4592, Test Loss: 71.4612\n",
      "Epoch [247/400], Train Loss: 7.8141, Test Loss: 74.0534\n",
      "Epoch [248/400], Train Loss: 7.6173, Test Loss: 72.4687\n",
      "Epoch [249/400], Train Loss: 7.1820, Test Loss: 75.5566\n",
      "Epoch [250/400], Train Loss: 7.0007, Test Loss: 70.3615\n",
      "Epoch [251/400], Train Loss: 7.9142, Test Loss: 72.9544\n",
      "Epoch [252/400], Train Loss: 8.5116, Test Loss: 73.6891\n",
      "Epoch [253/400], Train Loss: 7.2450, Test Loss: 73.0354\n",
      "Epoch [254/400], Train Loss: 6.1527, Test Loss: 71.1784\n",
      "Epoch [255/400], Train Loss: 7.2431, Test Loss: 74.1769\n",
      "Epoch [256/400], Train Loss: 5.8286, Test Loss: 72.0288\n",
      "Epoch [257/400], Train Loss: 5.3378, Test Loss: 70.1970\n",
      "Epoch [258/400], Train Loss: 8.0495, Test Loss: 76.2603\n",
      "Epoch [259/400], Train Loss: 7.8502, Test Loss: 75.7457\n",
      "Epoch [260/400], Train Loss: 13.7330, Test Loss: 71.9332\n",
      "Epoch [261/400], Train Loss: 12.7905, Test Loss: 72.3924\n",
      "Epoch [262/400], Train Loss: 10.1354, Test Loss: 73.8176\n",
      "Epoch [263/400], Train Loss: 13.1016, Test Loss: 69.3044\n",
      "Epoch [264/400], Train Loss: 8.1473, Test Loss: 72.2073\n",
      "Epoch [265/400], Train Loss: 6.8031, Test Loss: 72.3153\n",
      "Epoch [266/400], Train Loss: 8.3251, Test Loss: 71.7238\n",
      "Epoch [267/400], Train Loss: 9.3434, Test Loss: 68.4478\n",
      "Epoch [268/400], Train Loss: 7.4939, Test Loss: 71.6985\n",
      "Epoch [269/400], Train Loss: 7.5860, Test Loss: 68.8010\n",
      "Epoch [270/400], Train Loss: 18.3648, Test Loss: 71.6184\n",
      "Epoch [271/400], Train Loss: 13.5557, Test Loss: 68.2948\n",
      "Epoch [272/400], Train Loss: 20.6227, Test Loss: 69.6799\n",
      "Epoch [273/400], Train Loss: 13.9499, Test Loss: 68.8557\n",
      "Epoch [274/400], Train Loss: 10.5225, Test Loss: 68.6124\n",
      "Epoch [275/400], Train Loss: 8.7969, Test Loss: 70.1249\n",
      "Epoch [276/400], Train Loss: 7.6232, Test Loss: 70.7043\n",
      "Epoch [277/400], Train Loss: 7.1981, Test Loss: 71.8083\n",
      "Epoch [278/400], Train Loss: 7.3745, Test Loss: 72.1480\n",
      "Epoch [279/400], Train Loss: 8.0475, Test Loss: 74.8913\n",
      "Epoch [280/400], Train Loss: 20.6805, Test Loss: 73.5180\n",
      "Epoch [281/400], Train Loss: 12.3941, Test Loss: 72.3163\n",
      "Epoch [282/400], Train Loss: 9.5068, Test Loss: 69.1664\n",
      "Epoch [283/400], Train Loss: 8.8081, Test Loss: 72.0687\n",
      "Epoch [284/400], Train Loss: 7.5481, Test Loss: 70.6832\n",
      "Epoch [285/400], Train Loss: 6.1515, Test Loss: 71.6386\n",
      "Epoch [286/400], Train Loss: 5.6916, Test Loss: 70.2127\n",
      "Epoch [287/400], Train Loss: 4.8757, Test Loss: 72.4671\n",
      "Epoch [288/400], Train Loss: 4.6259, Test Loss: 69.7155\n",
      "Epoch [289/400], Train Loss: 4.9554, Test Loss: 70.1003\n",
      "Epoch [290/400], Train Loss: 3.6579, Test Loss: 73.2772\n",
      "Epoch [291/400], Train Loss: 4.0979, Test Loss: 70.5589\n",
      "Epoch [292/400], Train Loss: 4.2751, Test Loss: 70.6051\n",
      "Epoch [293/400], Train Loss: 3.4546, Test Loss: 71.7860\n",
      "Epoch [294/400], Train Loss: 3.8690, Test Loss: 71.5834\n",
      "Epoch [295/400], Train Loss: 3.5160, Test Loss: 72.2099\n",
      "Epoch [296/400], Train Loss: 8.8070, Test Loss: 69.1963\n",
      "Epoch [297/400], Train Loss: 10.6442, Test Loss: 71.7436\n",
      "Epoch [298/400], Train Loss: 8.4069, Test Loss: 67.8438\n",
      "Epoch [299/400], Train Loss: 4.5734, Test Loss: 67.9749\n",
      "Epoch [300/400], Train Loss: 3.8962, Test Loss: 66.1489\n",
      "Epoch [301/400], Train Loss: 3.7713, Test Loss: 67.3750\n",
      "Epoch [302/400], Train Loss: 3.2788, Test Loss: 69.7360\n",
      "Epoch [303/400], Train Loss: 3.2038, Test Loss: 67.9147\n",
      "Epoch [304/400], Train Loss: 2.9482, Test Loss: 66.8731\n",
      "Epoch [305/400], Train Loss: 2.8529, Test Loss: 68.6134\n",
      "Epoch [306/400], Train Loss: 2.7871, Test Loss: 67.4322\n",
      "Epoch [307/400], Train Loss: 2.7257, Test Loss: 68.5100\n",
      "Epoch [308/400], Train Loss: 2.7480, Test Loss: 68.1996\n",
      "Epoch [309/400], Train Loss: 2.5522, Test Loss: 66.0657\n",
      "Epoch [310/400], Train Loss: 2.6181, Test Loss: 69.2376\n",
      "Epoch [311/400], Train Loss: 2.6384, Test Loss: 69.1506\n",
      "Epoch [312/400], Train Loss: 2.4420, Test Loss: 67.8710\n",
      "Epoch [313/400], Train Loss: 2.2359, Test Loss: 68.8696\n",
      "Epoch [314/400], Train Loss: 2.1775, Test Loss: 68.1567\n",
      "Epoch [315/400], Train Loss: 2.6032, Test Loss: 69.3160\n",
      "Epoch [316/400], Train Loss: 3.8234, Test Loss: 70.0297\n",
      "Epoch [317/400], Train Loss: 2.8878, Test Loss: 70.2057\n",
      "Epoch [318/400], Train Loss: 3.0758, Test Loss: 75.0219\n",
      "Epoch [319/400], Train Loss: 7.0061, Test Loss: 72.9626\n",
      "Epoch [320/400], Train Loss: 6.9136, Test Loss: 75.9272\n",
      "Epoch [321/400], Train Loss: 5.8450, Test Loss: 70.1631\n",
      "Epoch [322/400], Train Loss: 5.4866, Test Loss: 70.2751\n",
      "Epoch [323/400], Train Loss: 3.5672, Test Loss: 70.1287\n",
      "Epoch [324/400], Train Loss: 3.4975, Test Loss: 72.0622\n",
      "Epoch [325/400], Train Loss: 4.0831, Test Loss: 70.4120\n",
      "Epoch [326/400], Train Loss: 3.7763, Test Loss: 70.9392\n",
      "Epoch [327/400], Train Loss: 2.7055, Test Loss: 69.4290\n",
      "Epoch [328/400], Train Loss: 2.2643, Test Loss: 70.4410\n",
      "Epoch [329/400], Train Loss: 1.9983, Test Loss: 69.5559\n",
      "Epoch [330/400], Train Loss: 1.8632, Test Loss: 69.0661\n",
      "Epoch [331/400], Train Loss: 1.8669, Test Loss: 69.3756\n",
      "Epoch [332/400], Train Loss: 1.7051, Test Loss: 71.0624\n",
      "Epoch [333/400], Train Loss: 1.7581, Test Loss: 69.6880\n",
      "Epoch [334/400], Train Loss: 1.7912, Test Loss: 69.4921\n",
      "Epoch [335/400], Train Loss: 1.9558, Test Loss: 67.8493\n",
      "Epoch [336/400], Train Loss: 2.0779, Test Loss: 69.0241\n",
      "Epoch [337/400], Train Loss: 1.6676, Test Loss: 68.5811\n",
      "Epoch [338/400], Train Loss: 1.7356, Test Loss: 68.4934\n",
      "Epoch [339/400], Train Loss: 6.0617, Test Loss: 78.9884\n",
      "Epoch [340/400], Train Loss: 13.1045, Test Loss: 71.3585\n",
      "Epoch [341/400], Train Loss: 11.7414, Test Loss: 74.0627\n",
      "Epoch [342/400], Train Loss: 6.8105, Test Loss: 75.2243\n",
      "Epoch [343/400], Train Loss: 6.9369, Test Loss: 72.6681\n",
      "Epoch [344/400], Train Loss: 4.8556, Test Loss: 71.1417\n",
      "Epoch [345/400], Train Loss: 4.7585, Test Loss: 71.3239\n",
      "Epoch [346/400], Train Loss: 3.1640, Test Loss: 72.5030\n",
      "Epoch [347/400], Train Loss: 2.6742, Test Loss: 72.0235\n",
      "Epoch [348/400], Train Loss: 2.7677, Test Loss: 71.3835\n",
      "Epoch [349/400], Train Loss: 2.7149, Test Loss: 71.8180\n",
      "Epoch [350/400], Train Loss: 2.3278, Test Loss: 71.0235\n",
      "Epoch [351/400], Train Loss: 2.0746, Test Loss: 71.4165\n",
      "Epoch [352/400], Train Loss: 1.9708, Test Loss: 72.0711\n",
      "Epoch [353/400], Train Loss: 1.8552, Test Loss: 71.0397\n",
      "Epoch [354/400], Train Loss: 1.7530, Test Loss: 71.8015\n",
      "Epoch [355/400], Train Loss: 1.6500, Test Loss: 71.6213\n",
      "Epoch [356/400], Train Loss: 1.5709, Test Loss: 71.8830\n",
      "Epoch [357/400], Train Loss: 1.5488, Test Loss: 72.3806\n",
      "Epoch [358/400], Train Loss: 1.6770, Test Loss: 73.4565\n",
      "Epoch [359/400], Train Loss: 1.6464, Test Loss: 73.1173\n",
      "Epoch [360/400], Train Loss: 1.5867, Test Loss: 72.2799\n",
      "Epoch [361/400], Train Loss: 1.4941, Test Loss: 71.3964\n",
      "Epoch [362/400], Train Loss: 1.4580, Test Loss: 71.1544\n",
      "Epoch [363/400], Train Loss: 1.4586, Test Loss: 71.1300\n",
      "Epoch [364/400], Train Loss: 1.4563, Test Loss: 71.5411\n",
      "Epoch [365/400], Train Loss: 1.6097, Test Loss: 71.4871\n",
      "Epoch [366/400], Train Loss: 1.6172, Test Loss: 71.6965\n",
      "Epoch [367/400], Train Loss: 1.6912, Test Loss: 68.7354\n",
      "Epoch [368/400], Train Loss: 1.7490, Test Loss: 70.3885\n",
      "Epoch [369/400], Train Loss: 3.7793, Test Loss: 71.8256\n",
      "Epoch [370/400], Train Loss: 8.0747, Test Loss: 76.4873\n",
      "Epoch [371/400], Train Loss: 20.7684, Test Loss: 68.7581\n",
      "Epoch [372/400], Train Loss: 19.9427, Test Loss: 72.6161\n",
      "Epoch [373/400], Train Loss: 9.5729, Test Loss: 77.4829\n",
      "Epoch [374/400], Train Loss: 5.2811, Test Loss: 73.4021\n",
      "Epoch [375/400], Train Loss: 3.9415, Test Loss: 71.6570\n",
      "Epoch [376/400], Train Loss: 2.9821, Test Loss: 69.0816\n",
      "Epoch [377/400], Train Loss: 2.5509, Test Loss: 70.8996\n",
      "Epoch [378/400], Train Loss: 2.1930, Test Loss: 70.3803\n",
      "Epoch [379/400], Train Loss: 1.9238, Test Loss: 71.3157\n",
      "Epoch [380/400], Train Loss: 1.8559, Test Loss: 70.2571\n",
      "Epoch [381/400], Train Loss: 1.8523, Test Loss: 71.9226\n",
      "Epoch [382/400], Train Loss: 1.7470, Test Loss: 71.5193\n",
      "Epoch [383/400], Train Loss: 1.6769, Test Loss: 71.4799\n",
      "Epoch [384/400], Train Loss: 1.5853, Test Loss: 71.7910\n",
      "Epoch [385/400], Train Loss: 1.5622, Test Loss: 72.2434\n",
      "Epoch [386/400], Train Loss: 1.4428, Test Loss: 71.8332\n",
      "Epoch [387/400], Train Loss: 1.4168, Test Loss: 72.3839\n",
      "Epoch [388/400], Train Loss: 1.3692, Test Loss: 71.8260\n",
      "Epoch [389/400], Train Loss: 1.3364, Test Loss: 72.1060\n",
      "Epoch [390/400], Train Loss: 1.3153, Test Loss: 72.7608\n",
      "Epoch [391/400], Train Loss: 1.3807, Test Loss: 71.6297\n",
      "Epoch [392/400], Train Loss: 1.3411, Test Loss: 72.1963\n",
      "Epoch [393/400], Train Loss: 1.2197, Test Loss: 71.0783\n",
      "Epoch [394/400], Train Loss: 1.2124, Test Loss: 71.6878\n",
      "Epoch [395/400], Train Loss: 1.2285, Test Loss: 71.5863\n",
      "Epoch [396/400], Train Loss: 1.3029, Test Loss: 69.5446\n",
      "Epoch [397/400], Train Loss: 1.4212, Test Loss: 71.5544\n",
      "Epoch [398/400], Train Loss: 2.5913, Test Loss: 73.6634\n",
      "Epoch [399/400], Train Loss: 15.1719, Test Loss: 70.2154\n",
      "Epoch [400/400], Train Loss: 11.2015, Test Loss: 71.2937\n",
      "Epoch [1/400], Train Loss: 58618.3882, Test Loss: 56350.9790\n",
      "Epoch [2/400], Train Loss: 55842.7800, Test Loss: 54399.1736\n",
      "Epoch [3/400], Train Loss: 54010.1620, Test Loss: 52673.8429\n",
      "Epoch [4/400], Train Loss: 52170.8846, Test Loss: 51067.6475\n",
      "Epoch [5/400], Train Loss: 50592.8292, Test Loss: 49536.0022\n",
      "Epoch [6/400], Train Loss: 49179.9024, Test Loss: 48080.7318\n",
      "Epoch [7/400], Train Loss: 47594.1730, Test Loss: 46669.9196\n",
      "Epoch [8/400], Train Loss: 46271.6093, Test Loss: 45327.1212\n",
      "Epoch [9/400], Train Loss: 44782.1813, Test Loss: 44015.9080\n",
      "Epoch [10/400], Train Loss: 43530.1677, Test Loss: 42773.1881\n",
      "Epoch [11/400], Train Loss: 42187.8541, Test Loss: 41555.7182\n",
      "Epoch [12/400], Train Loss: 40974.1655, Test Loss: 40397.2259\n",
      "Epoch [13/400], Train Loss: 39858.1366, Test Loss: 39284.9552\n",
      "Epoch [14/400], Train Loss: 38657.2121, Test Loss: 38192.3936\n",
      "Epoch [15/400], Train Loss: 37443.5677, Test Loss: 37140.5834\n",
      "Epoch [16/400], Train Loss: 36545.8011, Test Loss: 36151.7497\n",
      "Epoch [17/400], Train Loss: 35436.0868, Test Loss: 35181.1512\n",
      "Epoch [18/400], Train Loss: 34420.7526, Test Loss: 34245.2492\n",
      "Epoch [19/400], Train Loss: 33533.5359, Test Loss: 33365.2597\n",
      "Epoch [20/400], Train Loss: 32603.4889, Test Loss: 32499.9683\n",
      "Epoch [21/400], Train Loss: 31596.8805, Test Loss: 31663.6997\n",
      "Epoch [22/400], Train Loss: 30824.5637, Test Loss: 30873.2750\n",
      "Epoch [23/400], Train Loss: 29964.5585, Test Loss: 30104.5989\n",
      "Epoch [24/400], Train Loss: 29171.4532, Test Loss: 29368.0507\n",
      "Epoch [25/400], Train Loss: 28444.8919, Test Loss: 28663.7410\n",
      "Epoch [26/400], Train Loss: 27729.1778, Test Loss: 27996.0517\n",
      "Epoch [27/400], Train Loss: 27053.4849, Test Loss: 27340.5366\n",
      "Epoch [28/400], Train Loss: 26291.3314, Test Loss: 26722.0875\n",
      "Epoch [29/400], Train Loss: 25641.9791, Test Loss: 26133.2901\n",
      "Epoch [30/400], Train Loss: 25057.9405, Test Loss: 25566.5036\n",
      "Epoch [31/400], Train Loss: 24414.6960, Test Loss: 25033.8061\n",
      "Epoch [32/400], Train Loss: 23931.6108, Test Loss: 24517.3781\n",
      "Epoch [33/400], Train Loss: 23355.0629, Test Loss: 24026.1199\n",
      "Epoch [34/400], Train Loss: 22849.7707, Test Loss: 23562.1356\n",
      "Epoch [35/400], Train Loss: 22355.7284, Test Loss: 23112.5819\n",
      "Epoch [36/400], Train Loss: 21912.7712, Test Loss: 22701.3336\n",
      "Epoch [37/400], Train Loss: 21479.4704, Test Loss: 22292.2052\n",
      "Epoch [38/400], Train Loss: 21012.7814, Test Loss: 21915.9871\n",
      "Epoch [39/400], Train Loss: 20613.7531, Test Loss: 21547.6825\n",
      "Epoch [40/400], Train Loss: 20238.5036, Test Loss: 21206.3330\n",
      "Epoch [41/400], Train Loss: 19891.8229, Test Loss: 20893.4611\n",
      "Epoch [42/400], Train Loss: 19510.0117, Test Loss: 20586.1413\n",
      "Epoch [43/400], Train Loss: 19219.9110, Test Loss: 20306.1975\n",
      "Epoch [44/400], Train Loss: 18861.1095, Test Loss: 20031.8202\n",
      "Epoch [45/400], Train Loss: 18586.2857, Test Loss: 19788.9584\n",
      "Epoch [46/400], Train Loss: 18346.3419, Test Loss: 19557.4309\n",
      "Epoch [47/400], Train Loss: 18088.2993, Test Loss: 19336.5478\n",
      "Epoch [48/400], Train Loss: 17799.6825, Test Loss: 19136.2499\n",
      "Epoch [49/400], Train Loss: 17640.6949, Test Loss: 18940.2943\n",
      "Epoch [50/400], Train Loss: 17390.9618, Test Loss: 18765.8733\n",
      "Epoch [51/400], Train Loss: 17195.7835, Test Loss: 18602.0553\n",
      "Epoch [52/400], Train Loss: 17022.9136, Test Loss: 18452.6711\n",
      "Epoch [53/400], Train Loss: 16841.9135, Test Loss: 18306.4247\n",
      "Epoch [54/400], Train Loss: 16707.3664, Test Loss: 18185.9509\n",
      "Epoch [55/400], Train Loss: 16539.8841, Test Loss: 18070.9362\n",
      "Epoch [56/400], Train Loss: 16381.2401, Test Loss: 17957.3930\n",
      "Epoch [57/400], Train Loss: 16257.6869, Test Loss: 17859.9071\n",
      "Epoch [58/400], Train Loss: 16158.5828, Test Loss: 17773.6277\n",
      "Epoch [59/400], Train Loss: 16044.9955, Test Loss: 17687.8477\n",
      "Epoch [60/400], Train Loss: 15974.4192, Test Loss: 17615.6210\n",
      "Epoch [61/400], Train Loss: 15850.8919, Test Loss: 17549.8013\n",
      "Epoch [62/400], Train Loss: 15781.4471, Test Loss: 17492.8481\n",
      "Epoch [63/400], Train Loss: 15717.3553, Test Loss: 17438.5499\n",
      "Epoch [64/400], Train Loss: 15658.4151, Test Loss: 17395.2720\n",
      "Epoch [65/400], Train Loss: 15582.5809, Test Loss: 17355.8294\n",
      "Epoch [66/400], Train Loss: 15526.4809, Test Loss: 17322.3039\n",
      "Epoch [67/400], Train Loss: 15432.5018, Test Loss: 17289.7142\n",
      "Epoch [68/400], Train Loss: 15418.5222, Test Loss: 17263.1740\n",
      "Epoch [69/400], Train Loss: 15405.7377, Test Loss: 17238.0514\n",
      "Epoch [70/400], Train Loss: 15360.8985, Test Loss: 17218.7691\n",
      "Epoch [71/400], Train Loss: 15316.8820, Test Loss: 17205.4729\n",
      "Epoch [72/400], Train Loss: 15282.1314, Test Loss: 17192.2119\n",
      "Epoch [73/400], Train Loss: 15305.7963, Test Loss: 17180.3830\n",
      "Epoch [74/400], Train Loss: 15241.8722, Test Loss: 17172.0594\n",
      "Epoch [75/400], Train Loss: 15218.3128, Test Loss: 17165.1250\n",
      "Epoch [76/400], Train Loss: 15231.8140, Test Loss: 17159.7761\n",
      "Epoch [77/400], Train Loss: 15195.7193, Test Loss: 17155.9509\n",
      "Epoch [78/400], Train Loss: 15180.7903, Test Loss: 17153.2610\n",
      "Epoch [79/400], Train Loss: 15209.6963, Test Loss: 17151.2467\n",
      "Epoch [80/400], Train Loss: 15181.5915, Test Loss: 17150.8047\n",
      "Epoch [81/400], Train Loss: 15199.0684, Test Loss: 17150.9874\n",
      "Epoch [82/400], Train Loss: 15207.1188, Test Loss: 17151.2408\n",
      "Epoch [83/400], Train Loss: 15160.8895, Test Loss: 17152.2363\n",
      "Epoch [84/400], Train Loss: 15156.3112, Test Loss: 17153.8484\n",
      "Epoch [85/400], Train Loss: 15091.3059, Test Loss: 17155.8860\n",
      "Epoch [86/400], Train Loss: 15142.5917, Test Loss: 17157.6607\n",
      "Epoch [87/400], Train Loss: 15108.0165, Test Loss: 17159.5840\n",
      "Epoch [88/400], Train Loss: 15134.1724, Test Loss: 17160.9716\n",
      "Epoch [89/400], Train Loss: 15146.6571, Test Loss: 17163.5893\n",
      "Epoch [90/400], Train Loss: 15104.4465, Test Loss: 17165.4446\n",
      "Epoch [91/400], Train Loss: 15173.1508, Test Loss: 17167.9287\n",
      "Epoch [92/400], Train Loss: 15138.9485, Test Loss: 17169.1193\n",
      "Epoch [93/400], Train Loss: 15129.3964, Test Loss: 17171.9879\n",
      "Epoch [94/400], Train Loss: 15101.3801, Test Loss: 17174.3121\n",
      "Epoch [95/400], Train Loss: 15150.9188, Test Loss: 17176.2670\n",
      "Epoch [96/400], Train Loss: 15114.5300, Test Loss: 17177.1390\n",
      "Epoch [97/400], Train Loss: 15137.3961, Test Loss: 17177.1379\n",
      "Epoch [98/400], Train Loss: 15124.3701, Test Loss: 17180.5707\n",
      "Epoch [99/400], Train Loss: 15089.5120, Test Loss: 17181.1091\n",
      "Epoch [100/400], Train Loss: 15084.8510, Test Loss: 17182.4409\n",
      "Epoch [101/400], Train Loss: 15116.9837, Test Loss: 17183.7890\n",
      "Epoch [102/400], Train Loss: 15106.2076, Test Loss: 17185.6529\n",
      "Epoch [103/400], Train Loss: 15119.8062, Test Loss: 17185.2049\n",
      "Epoch [104/400], Train Loss: 15086.4627, Test Loss: 17186.4223\n",
      "Epoch [105/400], Train Loss: 15099.7704, Test Loss: 17188.9703\n",
      "Epoch [106/400], Train Loss: 15098.4005, Test Loss: 17188.2926\n",
      "Epoch [107/400], Train Loss: 15144.7267, Test Loss: 17188.7260\n",
      "Epoch [108/400], Train Loss: 15120.8441, Test Loss: 17186.4265\n",
      "Epoch [109/400], Train Loss: 15095.6008, Test Loss: 17187.7815\n",
      "Epoch [110/400], Train Loss: 15113.6111, Test Loss: 17190.9053\n",
      "Epoch [111/400], Train Loss: 15113.1878, Test Loss: 17189.8015\n",
      "Epoch [112/400], Train Loss: 15142.1647, Test Loss: 17191.7417\n",
      "Epoch [113/400], Train Loss: 15085.6356, Test Loss: 17191.6680\n",
      "Epoch [114/400], Train Loss: 15121.9969, Test Loss: 17192.1427\n",
      "Epoch [115/400], Train Loss: 15087.5549, Test Loss: 17190.5976\n",
      "Epoch [116/400], Train Loss: 15130.7304, Test Loss: 17191.2147\n",
      "Epoch [117/400], Train Loss: 15120.3837, Test Loss: 17189.8658\n",
      "Epoch [118/400], Train Loss: 15141.2707, Test Loss: 17192.6595\n",
      "Epoch [119/400], Train Loss: 15109.9170, Test Loss: 17183.6151\n",
      "Epoch [120/400], Train Loss: 15073.2845, Test Loss: 17173.1706\n",
      "Epoch [121/400], Train Loss: 15160.4091, Test Loss: 17177.0099\n",
      "Epoch [122/400], Train Loss: 15119.5160, Test Loss: 17121.7953\n",
      "Epoch [123/400], Train Loss: 15169.9495, Test Loss: 17134.5239\n",
      "Epoch [124/400], Train Loss: 15128.0747, Test Loss: 17146.3208\n",
      "Epoch [125/400], Train Loss: 15101.1258, Test Loss: 17135.4060\n",
      "Epoch [126/400], Train Loss: 15065.7578, Test Loss: 17119.4366\n",
      "Epoch [127/400], Train Loss: 15083.3392, Test Loss: 17153.3342\n",
      "Epoch [128/400], Train Loss: 15075.2167, Test Loss: 17088.9816\n",
      "Epoch [129/400], Train Loss: 15101.7972, Test Loss: 17118.6204\n",
      "Epoch [130/400], Train Loss: 15099.6140, Test Loss: 17108.9713\n",
      "Epoch [131/400], Train Loss: 15073.4060, Test Loss: 17097.5335\n",
      "Epoch [132/400], Train Loss: 15029.5227, Test Loss: 17065.5593\n",
      "Epoch [133/400], Train Loss: 15067.9010, Test Loss: 17091.7042\n",
      "Epoch [134/400], Train Loss: 15027.1425, Test Loss: 17002.8143\n",
      "Epoch [135/400], Train Loss: 15029.3177, Test Loss: 17115.6394\n",
      "Epoch [136/400], Train Loss: 15005.7134, Test Loss: 17078.8909\n",
      "Epoch [137/400], Train Loss: 15037.3198, Test Loss: 16966.0334\n",
      "Epoch [138/400], Train Loss: 14998.6498, Test Loss: 16995.1950\n",
      "Epoch [139/400], Train Loss: 14990.2677, Test Loss: 17007.7886\n",
      "Epoch [140/400], Train Loss: 14925.0918, Test Loss: 16950.4455\n",
      "Epoch [141/400], Train Loss: 15000.7085, Test Loss: 17031.4234\n",
      "Epoch [142/400], Train Loss: 14912.0534, Test Loss: 17084.1524\n",
      "Epoch [143/400], Train Loss: 14928.7484, Test Loss: 16998.8039\n",
      "Epoch [144/400], Train Loss: 14969.6673, Test Loss: 17096.6301\n",
      "Epoch [145/400], Train Loss: 14826.2509, Test Loss: 16973.1496\n",
      "Epoch [146/400], Train Loss: 14769.6984, Test Loss: 16951.6227\n",
      "Epoch [147/400], Train Loss: 14737.2305, Test Loss: 17058.9242\n",
      "Epoch [148/400], Train Loss: 14834.3501, Test Loss: 17045.7233\n",
      "Epoch [149/400], Train Loss: 14685.2658, Test Loss: 17032.2561\n",
      "Epoch [150/400], Train Loss: 14604.7502, Test Loss: 17128.8551\n",
      "Epoch [151/400], Train Loss: 14591.4453, Test Loss: 17159.6889\n",
      "Epoch [152/400], Train Loss: 14576.0365, Test Loss: 16951.5651\n",
      "Epoch [153/400], Train Loss: 14657.5315, Test Loss: 16982.7907\n",
      "Epoch [154/400], Train Loss: 14666.9352, Test Loss: 17036.4086\n",
      "Epoch [155/400], Train Loss: 14508.6252, Test Loss: 17094.3904\n",
      "Epoch [156/400], Train Loss: 14567.4919, Test Loss: 17156.5666\n",
      "Epoch [157/400], Train Loss: 14491.8454, Test Loss: 17109.2561\n",
      "Epoch [158/400], Train Loss: 14510.8287, Test Loss: 17105.1542\n",
      "Epoch [159/400], Train Loss: 14443.9309, Test Loss: 17342.8423\n",
      "Epoch [160/400], Train Loss: 14429.5421, Test Loss: 17198.9786\n",
      "Epoch [161/400], Train Loss: 14709.5171, Test Loss: 17143.0372\n",
      "Epoch [162/400], Train Loss: 14413.7173, Test Loss: 17129.8475\n",
      "Epoch [163/400], Train Loss: 14438.6908, Test Loss: 17055.2895\n",
      "Epoch [164/400], Train Loss: 14316.9954, Test Loss: 17014.9628\n",
      "Epoch [165/400], Train Loss: 14263.9931, Test Loss: 16944.5605\n",
      "Epoch [166/400], Train Loss: 14245.9105, Test Loss: 17141.3635\n",
      "Epoch [167/400], Train Loss: 14283.7417, Test Loss: 16985.3015\n",
      "Epoch [168/400], Train Loss: 14225.3787, Test Loss: 17300.4809\n",
      "Epoch [169/400], Train Loss: 14462.9368, Test Loss: 17133.4343\n",
      "Epoch [170/400], Train Loss: 14418.7177, Test Loss: 17324.9427\n",
      "Epoch [171/400], Train Loss: 14401.8410, Test Loss: 17078.9366\n",
      "Epoch [172/400], Train Loss: 14246.1103, Test Loss: 16994.9137\n",
      "Epoch [173/400], Train Loss: 14315.6916, Test Loss: 17032.1309\n",
      "Epoch [174/400], Train Loss: 14281.4042, Test Loss: 16969.8055\n",
      "Epoch [175/400], Train Loss: 14286.4061, Test Loss: 17149.1183\n",
      "Epoch [176/400], Train Loss: 14270.1847, Test Loss: 17182.8702\n",
      "Epoch [177/400], Train Loss: 14263.0094, Test Loss: 17114.9052\n",
      "Epoch [178/400], Train Loss: 14183.6910, Test Loss: 17066.3679\n",
      "Epoch [179/400], Train Loss: 14131.8175, Test Loss: 17228.4329\n",
      "Epoch [180/400], Train Loss: 14148.4187, Test Loss: 17215.9720\n",
      "Epoch [181/400], Train Loss: 14168.2055, Test Loss: 16982.9088\n",
      "Epoch [182/400], Train Loss: 14219.7465, Test Loss: 17084.9970\n",
      "Epoch [183/400], Train Loss: 14103.9843, Test Loss: 17098.4281\n",
      "Epoch [184/400], Train Loss: 13933.6984, Test Loss: 17352.5562\n",
      "Epoch [185/400], Train Loss: 14021.5486, Test Loss: 17325.0341\n",
      "Epoch [186/400], Train Loss: 13869.9820, Test Loss: 17374.2602\n",
      "Epoch [187/400], Train Loss: 13981.1434, Test Loss: 17277.9914\n",
      "Epoch [188/400], Train Loss: 13919.3186, Test Loss: 17160.3716\n",
      "Epoch [189/400], Train Loss: 13828.6704, Test Loss: 17288.7189\n",
      "Epoch [190/400], Train Loss: 13892.5267, Test Loss: 17210.6064\n",
      "Epoch [191/400], Train Loss: 13947.1926, Test Loss: 17143.9434\n",
      "Epoch [192/400], Train Loss: 13855.2881, Test Loss: 17226.4338\n",
      "Epoch [193/400], Train Loss: 13982.5692, Test Loss: 17740.5830\n",
      "Epoch [194/400], Train Loss: 13967.0868, Test Loss: 17364.6594\n",
      "Epoch [195/400], Train Loss: 13742.1141, Test Loss: 17406.6801\n",
      "Epoch [196/400], Train Loss: 13746.5919, Test Loss: 17374.6476\n",
      "Epoch [197/400], Train Loss: 13794.2708, Test Loss: 17346.4672\n",
      "Epoch [198/400], Train Loss: 13668.5480, Test Loss: 17342.0171\n",
      "Epoch [199/400], Train Loss: 13793.6882, Test Loss: 17272.9070\n",
      "Epoch [200/400], Train Loss: 13863.6013, Test Loss: 17479.8340\n",
      "Epoch [201/400], Train Loss: 13769.4925, Test Loss: 17552.3591\n",
      "Epoch [202/400], Train Loss: 13769.9402, Test Loss: 17288.6170\n",
      "Epoch [203/400], Train Loss: 13940.7360, Test Loss: 17646.9536\n",
      "Epoch [204/400], Train Loss: 13740.1713, Test Loss: 17445.7945\n",
      "Epoch [205/400], Train Loss: 13533.9224, Test Loss: 17577.6888\n",
      "Epoch [206/400], Train Loss: 13610.4557, Test Loss: 17641.2209\n",
      "Epoch [207/400], Train Loss: 13694.9467, Test Loss: 17512.6001\n",
      "Epoch [208/400], Train Loss: 13509.5281, Test Loss: 17494.6674\n",
      "Epoch [209/400], Train Loss: 13709.8673, Test Loss: 17551.4886\n",
      "Epoch [210/400], Train Loss: 13494.1726, Test Loss: 17443.8710\n",
      "Epoch [211/400], Train Loss: 13544.1151, Test Loss: 17663.7564\n",
      "Epoch [212/400], Train Loss: 13612.9114, Test Loss: 17260.0790\n",
      "Epoch [213/400], Train Loss: 13559.1845, Test Loss: 17350.4038\n",
      "Epoch [214/400], Train Loss: 13270.7404, Test Loss: 17415.0007\n",
      "Epoch [215/400], Train Loss: 13601.8584, Test Loss: 17679.1189\n",
      "Epoch [216/400], Train Loss: 13500.8700, Test Loss: 17367.6870\n",
      "Epoch [217/400], Train Loss: 13384.2956, Test Loss: 17726.0066\n",
      "Epoch [218/400], Train Loss: 13436.5541, Test Loss: 17646.5268\n",
      "Epoch [219/400], Train Loss: 13397.6864, Test Loss: 17322.0313\n",
      "Epoch [220/400], Train Loss: 13372.7883, Test Loss: 17364.3580\n",
      "Epoch [221/400], Train Loss: 13351.3367, Test Loss: 17240.4650\n",
      "Epoch [222/400], Train Loss: 13276.5645, Test Loss: 17616.5121\n",
      "Epoch [223/400], Train Loss: 13384.5785, Test Loss: 17411.3293\n",
      "Epoch [224/400], Train Loss: 13130.8052, Test Loss: 17249.1579\n",
      "Epoch [225/400], Train Loss: 13186.4419, Test Loss: 17487.2213\n",
      "Epoch [226/400], Train Loss: 13123.6648, Test Loss: 18103.4893\n",
      "Epoch [227/400], Train Loss: 13218.8169, Test Loss: 17500.6257\n",
      "Epoch [228/400], Train Loss: 13113.2874, Test Loss: 17717.3943\n",
      "Epoch [229/400], Train Loss: 13207.1916, Test Loss: 17377.8586\n",
      "Epoch [230/400], Train Loss: 13174.3628, Test Loss: 17392.9767\n",
      "Epoch [231/400], Train Loss: 13197.1717, Test Loss: 17376.3452\n",
      "Epoch [232/400], Train Loss: 13172.7876, Test Loss: 17652.1685\n",
      "Epoch [233/400], Train Loss: 13128.1256, Test Loss: 17171.7437\n",
      "Epoch [234/400], Train Loss: 13005.9306, Test Loss: 17452.6706\n",
      "Epoch [235/400], Train Loss: 12834.0952, Test Loss: 17739.6151\n",
      "Epoch [236/400], Train Loss: 12967.7849, Test Loss: 17592.6498\n",
      "Epoch [237/400], Train Loss: 12962.3935, Test Loss: 17358.8502\n",
      "Epoch [238/400], Train Loss: 13068.3447, Test Loss: 17118.9485\n",
      "Epoch [239/400], Train Loss: 12938.8032, Test Loss: 17602.1453\n",
      "Epoch [240/400], Train Loss: 12962.2985, Test Loss: 17590.4917\n",
      "Epoch [241/400], Train Loss: 13036.4448, Test Loss: 17569.3572\n",
      "Epoch [242/400], Train Loss: 12915.5385, Test Loss: 17632.4087\n",
      "Epoch [243/400], Train Loss: 12950.8060, Test Loss: 17293.2254\n",
      "Epoch [244/400], Train Loss: 12837.8696, Test Loss: 17555.9999\n",
      "Epoch [245/400], Train Loss: 12809.9145, Test Loss: 17428.6712\n",
      "Epoch [246/400], Train Loss: 12615.9042, Test Loss: 18375.5454\n",
      "Epoch [247/400], Train Loss: 13096.0891, Test Loss: 17619.1785\n",
      "Epoch [248/400], Train Loss: 12957.0358, Test Loss: 17539.5694\n",
      "Epoch [249/400], Train Loss: 12622.6400, Test Loss: 17465.8848\n",
      "Epoch [250/400], Train Loss: 12650.2671, Test Loss: 17595.3375\n",
      "Epoch [251/400], Train Loss: 12668.3329, Test Loss: 18153.8753\n",
      "Epoch [252/400], Train Loss: 12805.7215, Test Loss: 17589.7594\n",
      "Epoch [253/400], Train Loss: 12704.8546, Test Loss: 17377.0247\n",
      "Epoch [254/400], Train Loss: 12527.9452, Test Loss: 17499.0083\n",
      "Epoch [255/400], Train Loss: 12417.9965, Test Loss: 17525.6047\n",
      "Epoch [256/400], Train Loss: 12625.4515, Test Loss: 17454.0196\n",
      "Epoch [257/400], Train Loss: 12446.4492, Test Loss: 18068.7777\n",
      "Epoch [258/400], Train Loss: 13040.7271, Test Loss: 17530.1220\n",
      "Epoch [259/400], Train Loss: 12487.8208, Test Loss: 17339.9002\n",
      "Epoch [260/400], Train Loss: 12612.2464, Test Loss: 17268.4203\n",
      "Epoch [261/400], Train Loss: 12469.0677, Test Loss: 17634.9033\n",
      "Epoch [262/400], Train Loss: 12510.9792, Test Loss: 17459.7910\n",
      "Epoch [263/400], Train Loss: 12354.3119, Test Loss: 17634.4820\n",
      "Epoch [264/400], Train Loss: 12323.0131, Test Loss: 17662.6094\n",
      "Epoch [265/400], Train Loss: 12336.9702, Test Loss: 17402.8143\n",
      "Epoch [266/400], Train Loss: 12175.1372, Test Loss: 17615.7205\n",
      "Epoch [267/400], Train Loss: 12129.2486, Test Loss: 17802.0663\n",
      "Epoch [268/400], Train Loss: 12160.6524, Test Loss: 17462.4335\n",
      "Epoch [269/400], Train Loss: 12016.2002, Test Loss: 17871.1810\n",
      "Epoch [270/400], Train Loss: 12162.6885, Test Loss: 17979.1719\n",
      "Epoch [271/400], Train Loss: 12247.4249, Test Loss: 18026.1922\n",
      "Epoch [272/400], Train Loss: 12287.8454, Test Loss: 17807.3937\n",
      "Epoch [273/400], Train Loss: 12459.1414, Test Loss: 17788.5094\n",
      "Epoch [274/400], Train Loss: 12380.2480, Test Loss: 17648.2771\n",
      "Epoch [275/400], Train Loss: 12432.7167, Test Loss: 17920.6653\n",
      "Epoch [276/400], Train Loss: 12293.1761, Test Loss: 17777.6369\n",
      "Epoch [277/400], Train Loss: 12139.1262, Test Loss: 18025.8024\n",
      "Epoch [278/400], Train Loss: 12167.7633, Test Loss: 18047.8529\n",
      "Epoch [279/400], Train Loss: 12133.0344, Test Loss: 17829.4382\n",
      "Epoch [280/400], Train Loss: 12218.3029, Test Loss: 17747.0779\n",
      "Epoch [281/400], Train Loss: 12021.2160, Test Loss: 17740.2808\n",
      "Epoch [282/400], Train Loss: 12219.2435, Test Loss: 18165.1602\n",
      "Epoch [283/400], Train Loss: 12276.7661, Test Loss: 18756.8025\n",
      "Epoch [284/400], Train Loss: 12230.2963, Test Loss: 17636.8308\n",
      "Epoch [285/400], Train Loss: 11888.4676, Test Loss: 17547.5095\n",
      "Epoch [286/400], Train Loss: 11834.8635, Test Loss: 17855.6221\n",
      "Epoch [287/400], Train Loss: 11759.5723, Test Loss: 17914.4494\n",
      "Epoch [288/400], Train Loss: 12170.9533, Test Loss: 17870.1951\n",
      "Epoch [289/400], Train Loss: 11910.9386, Test Loss: 17650.0705\n",
      "Epoch [290/400], Train Loss: 11564.0510, Test Loss: 17705.8416\n",
      "Epoch [291/400], Train Loss: 11653.2277, Test Loss: 17707.3926\n",
      "Epoch [292/400], Train Loss: 11698.7732, Test Loss: 17858.7127\n",
      "Epoch [293/400], Train Loss: 11642.1710, Test Loss: 17893.1509\n",
      "Epoch [294/400], Train Loss: 11617.6075, Test Loss: 17913.3089\n",
      "Epoch [295/400], Train Loss: 11543.9681, Test Loss: 17824.5248\n",
      "Epoch [296/400], Train Loss: 11565.0951, Test Loss: 17886.7133\n",
      "Epoch [297/400], Train Loss: 11392.6997, Test Loss: 18025.1762\n",
      "Epoch [298/400], Train Loss: 11479.8236, Test Loss: 17579.4623\n",
      "Epoch [299/400], Train Loss: 11468.4180, Test Loss: 17620.1588\n",
      "Epoch [300/400], Train Loss: 11522.9100, Test Loss: 17844.0404\n",
      "Epoch [301/400], Train Loss: 11314.9848, Test Loss: 17937.4062\n",
      "Epoch [302/400], Train Loss: 11675.3777, Test Loss: 18056.5789\n",
      "Epoch [303/400], Train Loss: 11427.3537, Test Loss: 17719.9059\n",
      "Epoch [304/400], Train Loss: 11542.7850, Test Loss: 17829.2124\n",
      "Epoch [305/400], Train Loss: 11264.9019, Test Loss: 17716.1662\n",
      "Epoch [306/400], Train Loss: 11163.9589, Test Loss: 17574.2285\n",
      "Epoch [307/400], Train Loss: 11238.6775, Test Loss: 17971.2556\n",
      "Epoch [308/400], Train Loss: 11264.2399, Test Loss: 18340.9216\n",
      "Epoch [309/400], Train Loss: 11290.6986, Test Loss: 18227.1294\n",
      "Epoch [310/400], Train Loss: 11382.6343, Test Loss: 17646.8285\n",
      "Epoch [311/400], Train Loss: 11241.2450, Test Loss: 18216.1814\n",
      "Epoch [312/400], Train Loss: 11039.2437, Test Loss: 17932.1950\n",
      "Epoch [313/400], Train Loss: 11049.8718, Test Loss: 18262.9262\n",
      "Epoch [314/400], Train Loss: 11028.2303, Test Loss: 18169.3540\n",
      "Epoch [315/400], Train Loss: 11123.3263, Test Loss: 18307.9601\n",
      "Epoch [316/400], Train Loss: 11453.1047, Test Loss: 18413.1538\n",
      "Epoch [317/400], Train Loss: 11231.9429, Test Loss: 17876.5368\n",
      "Epoch [318/400], Train Loss: 11159.3442, Test Loss: 17811.5670\n",
      "Epoch [319/400], Train Loss: 11331.4826, Test Loss: 17632.3547\n",
      "Epoch [320/400], Train Loss: 11217.0134, Test Loss: 17946.5192\n",
      "Epoch [321/400], Train Loss: 11048.1994, Test Loss: 17820.7695\n",
      "Epoch [322/400], Train Loss: 10968.2306, Test Loss: 17720.4177\n",
      "Epoch [323/400], Train Loss: 10967.5901, Test Loss: 18058.7734\n",
      "Epoch [324/400], Train Loss: 10989.7825, Test Loss: 17765.9887\n",
      "Epoch [325/400], Train Loss: 11006.8240, Test Loss: 17823.1525\n",
      "Epoch [326/400], Train Loss: 11074.6358, Test Loss: 18152.7084\n",
      "Epoch [327/400], Train Loss: 10907.6437, Test Loss: 18246.7418\n",
      "Epoch [328/400], Train Loss: 10770.9171, Test Loss: 18337.9647\n",
      "Epoch [329/400], Train Loss: 11170.4118, Test Loss: 18284.6085\n",
      "Epoch [330/400], Train Loss: 10917.4868, Test Loss: 18011.7859\n",
      "Epoch [331/400], Train Loss: 10861.9679, Test Loss: 18405.0543\n",
      "Epoch [332/400], Train Loss: 10881.3913, Test Loss: 18509.4434\n",
      "Epoch [333/400], Train Loss: 11001.2298, Test Loss: 18256.3317\n",
      "Epoch [334/400], Train Loss: 11226.7968, Test Loss: 18721.7556\n",
      "Epoch [335/400], Train Loss: 10823.6649, Test Loss: 18565.8270\n",
      "Epoch [336/400], Train Loss: 10575.9211, Test Loss: 18033.6878\n",
      "Epoch [337/400], Train Loss: 10688.8646, Test Loss: 18384.4089\n",
      "Epoch [338/400], Train Loss: 10674.4759, Test Loss: 18202.1697\n",
      "Epoch [339/400], Train Loss: 10539.9102, Test Loss: 18214.4810\n",
      "Epoch [340/400], Train Loss: 10898.0362, Test Loss: 18773.5209\n",
      "Epoch [341/400], Train Loss: 10665.8479, Test Loss: 18083.7502\n",
      "Epoch [342/400], Train Loss: 10688.3987, Test Loss: 18307.6325\n",
      "Epoch [343/400], Train Loss: 11034.5493, Test Loss: 18525.0481\n",
      "Epoch [344/400], Train Loss: 10699.1871, Test Loss: 18268.0560\n",
      "Epoch [345/400], Train Loss: 10666.4966, Test Loss: 18171.5896\n",
      "Epoch [346/400], Train Loss: 10693.6170, Test Loss: 18113.2710\n",
      "Epoch [347/400], Train Loss: 10898.2265, Test Loss: 18208.3548\n",
      "Epoch [348/400], Train Loss: 10980.0223, Test Loss: 17942.2770\n",
      "Epoch [349/400], Train Loss: 10647.9372, Test Loss: 18024.1387\n",
      "Epoch [350/400], Train Loss: 10625.2167, Test Loss: 18220.3656\n",
      "Epoch [351/400], Train Loss: 10537.9709, Test Loss: 18301.5516\n",
      "Epoch [352/400], Train Loss: 10338.3054, Test Loss: 18315.2525\n",
      "Epoch [353/400], Train Loss: 10658.5447, Test Loss: 18207.8007\n",
      "Epoch [354/400], Train Loss: 10366.0539, Test Loss: 17829.9908\n",
      "Epoch [355/400], Train Loss: 10456.6758, Test Loss: 17835.1877\n",
      "Epoch [356/400], Train Loss: 10207.2564, Test Loss: 18292.4908\n",
      "Epoch [357/400], Train Loss: 10421.0663, Test Loss: 18337.4478\n",
      "Epoch [358/400], Train Loss: 10476.6885, Test Loss: 18463.4543\n",
      "Epoch [359/400], Train Loss: 10315.2105, Test Loss: 18765.9087\n",
      "Epoch [360/400], Train Loss: 10098.1433, Test Loss: 18490.3675\n",
      "Epoch [361/400], Train Loss: 10185.7753, Test Loss: 18418.1284\n",
      "Epoch [362/400], Train Loss: 10105.5698, Test Loss: 18707.5412\n",
      "Epoch [363/400], Train Loss: 10016.3482, Test Loss: 18764.2258\n",
      "Epoch [364/400], Train Loss: 10245.5239, Test Loss: 18411.3763\n",
      "Epoch [365/400], Train Loss: 9923.5907, Test Loss: 19400.3676\n",
      "Epoch [366/400], Train Loss: 9989.8104, Test Loss: 18212.9121\n",
      "Epoch [367/400], Train Loss: 9920.9073, Test Loss: 18688.1056\n",
      "Epoch [368/400], Train Loss: 9922.6340, Test Loss: 18904.0917\n",
      "Epoch [369/400], Train Loss: 10230.3379, Test Loss: 18227.1430\n",
      "Epoch [370/400], Train Loss: 9793.3389, Test Loss: 18779.8353\n",
      "Epoch [371/400], Train Loss: 10176.4703, Test Loss: 18715.6374\n",
      "Epoch [372/400], Train Loss: 9741.5738, Test Loss: 18941.9415\n",
      "Epoch [373/400], Train Loss: 9846.7840, Test Loss: 20120.7902\n",
      "Epoch [374/400], Train Loss: 9775.7975, Test Loss: 19263.3482\n",
      "Epoch [375/400], Train Loss: 9787.4848, Test Loss: 19049.0125\n",
      "Epoch [376/400], Train Loss: 9926.5369, Test Loss: 18827.6943\n",
      "Epoch [377/400], Train Loss: 9695.4907, Test Loss: 18843.5496\n",
      "Epoch [378/400], Train Loss: 9619.9031, Test Loss: 18469.9547\n",
      "Epoch [379/400], Train Loss: 9645.3217, Test Loss: 19390.9260\n",
      "Epoch [380/400], Train Loss: 9475.5721, Test Loss: 19498.0776\n",
      "Epoch [381/400], Train Loss: 9641.6159, Test Loss: 19795.7258\n",
      "Epoch [382/400], Train Loss: 9462.3785, Test Loss: 18801.4243\n",
      "Epoch [383/400], Train Loss: 9664.0268, Test Loss: 19226.3162\n",
      "Epoch [384/400], Train Loss: 9517.5161, Test Loss: 19235.7077\n",
      "Epoch [385/400], Train Loss: 9352.2849, Test Loss: 19180.8826\n",
      "Epoch [386/400], Train Loss: 9540.2042, Test Loss: 18851.5286\n",
      "Epoch [387/400], Train Loss: 9690.3226, Test Loss: 19444.3573\n",
      "Epoch [388/400], Train Loss: 9843.7772, Test Loss: 19013.6614\n",
      "Epoch [389/400], Train Loss: 9751.8799, Test Loss: 19504.9526\n",
      "Epoch [390/400], Train Loss: 9361.8717, Test Loss: 19151.1884\n",
      "Epoch [391/400], Train Loss: 9668.4117, Test Loss: 18520.7757\n",
      "Epoch [392/400], Train Loss: 9338.3003, Test Loss: 18695.8875\n",
      "Epoch [393/400], Train Loss: 8990.4393, Test Loss: 19594.2774\n",
      "Epoch [394/400], Train Loss: 9179.5019, Test Loss: 19527.2113\n",
      "Epoch [395/400], Train Loss: 9244.9408, Test Loss: 19733.9319\n",
      "Epoch [396/400], Train Loss: 9418.9725, Test Loss: 19820.9481\n",
      "Epoch [397/400], Train Loss: 9399.9613, Test Loss: 19219.2730\n",
      "Epoch [398/400], Train Loss: 9072.9780, Test Loss: 19392.4700\n",
      "Epoch [399/400], Train Loss: 9175.0086, Test Loss: 19809.9945\n",
      "Epoch [400/400], Train Loss: 8877.5057, Test Loss: 19587.6511\n",
      "Epoch [1/400], Train Loss: 41.8813, Test Loss: 19.5498\n",
      "Epoch [2/400], Train Loss: 16.7609, Test Loss: 17.9182\n",
      "Epoch [3/400], Train Loss: 16.3293, Test Loss: 17.9161\n",
      "Epoch [4/400], Train Loss: 16.3729, Test Loss: 17.8857\n",
      "Epoch [5/400], Train Loss: 16.2700, Test Loss: 17.8015\n",
      "Epoch [6/400], Train Loss: 16.2894, Test Loss: 17.7556\n",
      "Epoch [7/400], Train Loss: 16.0782, Test Loss: 17.5927\n",
      "Epoch [8/400], Train Loss: 15.8551, Test Loss: 17.4460\n",
      "Epoch [9/400], Train Loss: 15.4913, Test Loss: 17.2633\n",
      "Epoch [10/400], Train Loss: 15.5641, Test Loss: 17.1738\n",
      "Epoch [11/400], Train Loss: 15.1836, Test Loss: 16.5365\n",
      "Epoch [12/400], Train Loss: 14.9690, Test Loss: 16.4990\n",
      "Epoch [13/400], Train Loss: 14.8297, Test Loss: 16.7047\n",
      "Epoch [14/400], Train Loss: 14.2694, Test Loss: 17.0921\n",
      "Epoch [15/400], Train Loss: 14.5422, Test Loss: 16.5111\n",
      "Epoch [16/400], Train Loss: 13.6810, Test Loss: 15.3036\n",
      "Epoch [17/400], Train Loss: 13.9579, Test Loss: 15.6333\n",
      "Epoch [18/400], Train Loss: 14.4222, Test Loss: 15.2476\n",
      "Epoch [19/400], Train Loss: 13.2289, Test Loss: 14.9919\n",
      "Epoch [20/400], Train Loss: 13.1939, Test Loss: 15.0119\n",
      "Epoch [21/400], Train Loss: 12.7731, Test Loss: 14.3490\n",
      "Epoch [22/400], Train Loss: 12.4681, Test Loss: 14.7807\n",
      "Epoch [23/400], Train Loss: 12.2807, Test Loss: 14.3578\n",
      "Epoch [24/400], Train Loss: 12.2761, Test Loss: 15.4604\n",
      "Epoch [25/400], Train Loss: 11.9973, Test Loss: 14.0964\n",
      "Epoch [26/400], Train Loss: 11.6456, Test Loss: 14.5728\n",
      "Epoch [27/400], Train Loss: 11.3164, Test Loss: 14.0946\n",
      "Epoch [28/400], Train Loss: 11.2870, Test Loss: 15.0513\n",
      "Epoch [29/400], Train Loss: 11.3933, Test Loss: 15.7405\n",
      "Epoch [30/400], Train Loss: 11.7260, Test Loss: 15.0159\n",
      "Epoch [31/400], Train Loss: 11.4911, Test Loss: 14.4231\n",
      "Epoch [32/400], Train Loss: 11.2396, Test Loss: 14.4409\n",
      "Epoch [33/400], Train Loss: 11.1936, Test Loss: 14.8285\n",
      "Epoch [34/400], Train Loss: 10.8355, Test Loss: 15.0876\n",
      "Epoch [35/400], Train Loss: 10.7496, Test Loss: 14.4243\n",
      "Epoch [36/400], Train Loss: 10.4909, Test Loss: 16.7058\n",
      "Epoch [37/400], Train Loss: 10.7507, Test Loss: 14.7156\n",
      "Epoch [38/400], Train Loss: 10.4249, Test Loss: 14.9985\n",
      "Epoch [39/400], Train Loss: 10.7193, Test Loss: 14.4963\n",
      "Epoch [40/400], Train Loss: 10.6572, Test Loss: 15.1168\n",
      "Epoch [41/400], Train Loss: 10.6401, Test Loss: 15.0988\n",
      "Epoch [42/400], Train Loss: 10.3010, Test Loss: 15.6635\n",
      "Epoch [43/400], Train Loss: 10.3215, Test Loss: 14.5875\n",
      "Epoch [44/400], Train Loss: 10.2965, Test Loss: 14.5183\n",
      "Epoch [45/400], Train Loss: 10.1326, Test Loss: 14.4513\n",
      "Epoch [46/400], Train Loss: 9.9632, Test Loss: 14.7437\n",
      "Epoch [47/400], Train Loss: 10.3781, Test Loss: 13.9955\n",
      "Epoch [48/400], Train Loss: 9.7750, Test Loss: 14.2687\n",
      "Epoch [49/400], Train Loss: 9.9908, Test Loss: 14.6451\n",
      "Epoch [50/400], Train Loss: 9.6494, Test Loss: 14.7210\n",
      "Epoch [51/400], Train Loss: 9.7919, Test Loss: 14.7273\n",
      "Epoch [52/400], Train Loss: 9.4535, Test Loss: 14.5496\n",
      "Epoch [53/400], Train Loss: 9.2035, Test Loss: 14.5774\n",
      "Epoch [54/400], Train Loss: 9.0976, Test Loss: 15.5382\n",
      "Epoch [55/400], Train Loss: 9.4728, Test Loss: 16.3743\n",
      "Epoch [56/400], Train Loss: 8.9735, Test Loss: 15.0947\n",
      "Epoch [57/400], Train Loss: 9.1021, Test Loss: 14.7238\n",
      "Epoch [58/400], Train Loss: 8.9466, Test Loss: 14.6569\n",
      "Epoch [59/400], Train Loss: 8.7897, Test Loss: 14.5835\n",
      "Epoch [60/400], Train Loss: 8.7415, Test Loss: 14.6469\n",
      "Epoch [61/400], Train Loss: 8.8263, Test Loss: 14.4229\n",
      "Epoch [62/400], Train Loss: 8.4809, Test Loss: 14.7700\n",
      "Epoch [63/400], Train Loss: 8.8088, Test Loss: 13.9653\n",
      "Epoch [64/400], Train Loss: 8.8415, Test Loss: 13.7702\n",
      "Epoch [65/400], Train Loss: 8.5306, Test Loss: 16.6367\n",
      "Epoch [66/400], Train Loss: 8.6823, Test Loss: 15.0099\n",
      "Epoch [67/400], Train Loss: 8.8947, Test Loss: 15.3937\n",
      "Epoch [68/400], Train Loss: 8.8034, Test Loss: 13.5913\n",
      "Epoch [69/400], Train Loss: 8.3553, Test Loss: 14.0133\n",
      "Epoch [70/400], Train Loss: 8.6586, Test Loss: 15.2640\n",
      "Epoch [71/400], Train Loss: 8.9330, Test Loss: 14.0863\n",
      "Epoch [72/400], Train Loss: 8.2617, Test Loss: 14.2473\n",
      "Epoch [73/400], Train Loss: 8.2196, Test Loss: 14.1287\n",
      "Epoch [74/400], Train Loss: 8.1387, Test Loss: 14.4546\n",
      "Epoch [75/400], Train Loss: 7.8522, Test Loss: 14.2993\n",
      "Epoch [76/400], Train Loss: 7.8009, Test Loss: 13.9900\n",
      "Epoch [77/400], Train Loss: 7.7040, Test Loss: 14.0447\n",
      "Epoch [78/400], Train Loss: 7.8350, Test Loss: 15.9510\n",
      "Epoch [79/400], Train Loss: 8.3852, Test Loss: 14.4488\n",
      "Epoch [80/400], Train Loss: 7.6881, Test Loss: 14.6429\n",
      "Epoch [81/400], Train Loss: 7.7551, Test Loss: 15.3319\n",
      "Epoch [82/400], Train Loss: 7.4731, Test Loss: 15.0095\n",
      "Epoch [83/400], Train Loss: 7.5121, Test Loss: 16.2869\n",
      "Epoch [84/400], Train Loss: 7.1403, Test Loss: 14.6202\n",
      "Epoch [85/400], Train Loss: 6.9697, Test Loss: 15.1520\n",
      "Epoch [86/400], Train Loss: 6.9382, Test Loss: 15.5746\n",
      "Epoch [87/400], Train Loss: 6.8360, Test Loss: 14.4685\n",
      "Epoch [88/400], Train Loss: 7.3595, Test Loss: 14.9247\n",
      "Epoch [89/400], Train Loss: 7.4339, Test Loss: 14.7646\n",
      "Epoch [90/400], Train Loss: 7.0231, Test Loss: 14.6132\n",
      "Epoch [91/400], Train Loss: 6.9093, Test Loss: 15.2767\n",
      "Epoch [92/400], Train Loss: 6.6261, Test Loss: 14.0611\n",
      "Epoch [93/400], Train Loss: 6.6055, Test Loss: 15.1742\n",
      "Epoch [94/400], Train Loss: 6.5191, Test Loss: 14.5167\n",
      "Epoch [95/400], Train Loss: 6.2971, Test Loss: 15.6027\n",
      "Epoch [96/400], Train Loss: 6.2869, Test Loss: 15.9487\n",
      "Epoch [97/400], Train Loss: 6.1201, Test Loss: 15.1910\n",
      "Epoch [98/400], Train Loss: 6.2263, Test Loss: 13.7009\n",
      "Epoch [99/400], Train Loss: 6.0331, Test Loss: 15.4938\n",
      "Epoch [100/400], Train Loss: 6.3022, Test Loss: 13.9735\n",
      "Epoch [101/400], Train Loss: 6.4734, Test Loss: 14.8955\n",
      "Epoch [102/400], Train Loss: 6.1556, Test Loss: 14.2690\n",
      "Epoch [103/400], Train Loss: 5.8193, Test Loss: 14.6703\n",
      "Epoch [104/400], Train Loss: 6.6029, Test Loss: 14.6943\n",
      "Epoch [105/400], Train Loss: 6.0429, Test Loss: 14.5056\n",
      "Epoch [106/400], Train Loss: 5.9488, Test Loss: 14.5863\n",
      "Epoch [107/400], Train Loss: 6.0703, Test Loss: 13.8169\n",
      "Epoch [108/400], Train Loss: 5.5480, Test Loss: 14.7445\n",
      "Epoch [109/400], Train Loss: 5.6222, Test Loss: 14.6810\n",
      "Epoch [110/400], Train Loss: 5.2559, Test Loss: 15.2132\n",
      "Epoch [111/400], Train Loss: 5.6850, Test Loss: 14.3121\n",
      "Epoch [112/400], Train Loss: 5.7679, Test Loss: 14.6049\n",
      "Epoch [113/400], Train Loss: 5.2705, Test Loss: 14.7230\n",
      "Epoch [114/400], Train Loss: 5.2923, Test Loss: 13.8312\n",
      "Epoch [115/400], Train Loss: 4.9966, Test Loss: 13.6662\n",
      "Epoch [116/400], Train Loss: 4.9003, Test Loss: 14.7309\n",
      "Epoch [117/400], Train Loss: 4.8608, Test Loss: 13.5345\n",
      "Epoch [118/400], Train Loss: 4.9167, Test Loss: 13.9569\n",
      "Epoch [119/400], Train Loss: 4.8375, Test Loss: 15.2082\n",
      "Epoch [120/400], Train Loss: 4.7155, Test Loss: 14.8851\n",
      "Epoch [121/400], Train Loss: 4.6723, Test Loss: 13.6434\n",
      "Epoch [122/400], Train Loss: 4.5685, Test Loss: 13.8260\n",
      "Epoch [123/400], Train Loss: 4.3158, Test Loss: 14.0643\n",
      "Epoch [124/400], Train Loss: 4.7595, Test Loss: 14.2412\n",
      "Epoch [125/400], Train Loss: 4.2516, Test Loss: 14.4297\n",
      "Epoch [126/400], Train Loss: 4.1374, Test Loss: 14.4958\n",
      "Epoch [127/400], Train Loss: 4.1179, Test Loss: 16.4289\n",
      "Epoch [128/400], Train Loss: 4.1379, Test Loss: 14.2020\n",
      "Epoch [129/400], Train Loss: 4.1981, Test Loss: 14.3724\n",
      "Epoch [130/400], Train Loss: 3.8489, Test Loss: 15.0622\n",
      "Epoch [131/400], Train Loss: 4.1523, Test Loss: 14.8838\n",
      "Epoch [132/400], Train Loss: 3.7982, Test Loss: 14.6438\n",
      "Epoch [133/400], Train Loss: 3.7954, Test Loss: 15.4174\n",
      "Epoch [134/400], Train Loss: 3.7772, Test Loss: 14.7839\n",
      "Epoch [135/400], Train Loss: 3.6869, Test Loss: 14.5628\n",
      "Epoch [136/400], Train Loss: 3.8807, Test Loss: 14.4016\n",
      "Epoch [137/400], Train Loss: 3.5527, Test Loss: 14.7347\n",
      "Epoch [138/400], Train Loss: 3.2520, Test Loss: 15.0761\n",
      "Epoch [139/400], Train Loss: 3.2516, Test Loss: 14.7845\n",
      "Epoch [140/400], Train Loss: 3.0875, Test Loss: 14.6951\n",
      "Epoch [141/400], Train Loss: 3.1282, Test Loss: 14.4613\n",
      "Epoch [142/400], Train Loss: 3.1264, Test Loss: 14.5463\n",
      "Epoch [143/400], Train Loss: 2.9609, Test Loss: 14.9694\n",
      "Epoch [144/400], Train Loss: 2.8467, Test Loss: 14.7224\n",
      "Epoch [145/400], Train Loss: 2.8425, Test Loss: 14.7007\n",
      "Epoch [146/400], Train Loss: 2.7947, Test Loss: 15.5655\n",
      "Epoch [147/400], Train Loss: 2.7841, Test Loss: 15.2375\n",
      "Epoch [148/400], Train Loss: 2.8793, Test Loss: 15.2814\n",
      "Epoch [149/400], Train Loss: 2.5441, Test Loss: 15.6653\n",
      "Epoch [150/400], Train Loss: 2.4866, Test Loss: 15.9656\n",
      "Epoch [151/400], Train Loss: 2.4579, Test Loss: 15.7042\n",
      "Epoch [152/400], Train Loss: 2.4794, Test Loss: 16.3645\n",
      "Epoch [153/400], Train Loss: 2.5968, Test Loss: 16.0759\n",
      "Epoch [154/400], Train Loss: 2.3842, Test Loss: 15.9007\n",
      "Epoch [155/400], Train Loss: 2.2613, Test Loss: 16.5537\n",
      "Epoch [156/400], Train Loss: 2.0635, Test Loss: 15.9236\n",
      "Epoch [157/400], Train Loss: 2.1024, Test Loss: 15.9098\n",
      "Epoch [158/400], Train Loss: 2.3503, Test Loss: 16.1013\n",
      "Epoch [159/400], Train Loss: 2.0450, Test Loss: 16.5477\n",
      "Epoch [160/400], Train Loss: 1.9071, Test Loss: 16.4756\n",
      "Epoch [161/400], Train Loss: 1.8084, Test Loss: 16.1866\n",
      "Epoch [162/400], Train Loss: 2.1134, Test Loss: 16.0665\n",
      "Epoch [163/400], Train Loss: 2.2364, Test Loss: 16.9804\n",
      "Epoch [164/400], Train Loss: 2.1481, Test Loss: 16.2333\n",
      "Epoch [165/400], Train Loss: 1.9543, Test Loss: 15.9925\n",
      "Epoch [166/400], Train Loss: 1.7223, Test Loss: 16.4401\n",
      "Epoch [167/400], Train Loss: 1.7805, Test Loss: 16.3374\n",
      "Epoch [168/400], Train Loss: 1.6386, Test Loss: 16.0428\n",
      "Epoch [169/400], Train Loss: 1.5495, Test Loss: 16.5987\n",
      "Epoch [170/400], Train Loss: 1.6427, Test Loss: 16.7397\n",
      "Epoch [171/400], Train Loss: 1.4141, Test Loss: 16.6306\n",
      "Epoch [172/400], Train Loss: 1.4684, Test Loss: 17.4070\n",
      "Epoch [173/400], Train Loss: 1.5550, Test Loss: 16.5334\n",
      "Epoch [174/400], Train Loss: 1.2787, Test Loss: 16.0519\n",
      "Epoch [175/400], Train Loss: 1.0666, Test Loss: 17.0569\n",
      "Epoch [176/400], Train Loss: 1.1722, Test Loss: 16.7631\n",
      "Epoch [177/400], Train Loss: 1.1545, Test Loss: 16.7792\n",
      "Epoch [178/400], Train Loss: 1.2742, Test Loss: 16.6789\n",
      "Epoch [179/400], Train Loss: 1.5425, Test Loss: 17.1180\n",
      "Epoch [180/400], Train Loss: 1.4443, Test Loss: 17.4240\n",
      "Epoch [181/400], Train Loss: 1.1746, Test Loss: 17.3224\n",
      "Epoch [182/400], Train Loss: 1.0774, Test Loss: 17.1752\n",
      "Epoch [183/400], Train Loss: 0.9946, Test Loss: 17.2310\n",
      "Epoch [184/400], Train Loss: 0.8666, Test Loss: 17.4503\n",
      "Epoch [185/400], Train Loss: 1.0694, Test Loss: 17.2254\n",
      "Epoch [186/400], Train Loss: 0.9497, Test Loss: 17.0186\n",
      "Epoch [187/400], Train Loss: 1.0015, Test Loss: 17.3866\n",
      "Epoch [188/400], Train Loss: 0.8652, Test Loss: 18.1668\n",
      "Epoch [189/400], Train Loss: 0.8032, Test Loss: 17.2056\n",
      "Epoch [190/400], Train Loss: 0.9174, Test Loss: 17.7604\n",
      "Epoch [191/400], Train Loss: 0.7658, Test Loss: 17.1146\n",
      "Epoch [192/400], Train Loss: 0.8233, Test Loss: 17.4298\n",
      "Epoch [193/400], Train Loss: 0.9109, Test Loss: 17.6205\n",
      "Epoch [194/400], Train Loss: 0.7485, Test Loss: 17.0468\n",
      "Epoch [195/400], Train Loss: 0.7119, Test Loss: 17.5815\n",
      "Epoch [196/400], Train Loss: 0.6277, Test Loss: 17.4087\n",
      "Epoch [197/400], Train Loss: 0.6628, Test Loss: 17.6789\n",
      "Epoch [198/400], Train Loss: 0.6377, Test Loss: 17.5145\n",
      "Epoch [199/400], Train Loss: 0.5496, Test Loss: 17.8178\n",
      "Epoch [200/400], Train Loss: 0.5320, Test Loss: 17.9312\n",
      "Epoch [201/400], Train Loss: 0.5711, Test Loss: 17.9796\n",
      "Epoch [202/400], Train Loss: 0.5345, Test Loss: 17.6086\n",
      "Epoch [203/400], Train Loss: 0.6081, Test Loss: 18.1746\n",
      "Epoch [204/400], Train Loss: 0.7125, Test Loss: 18.0700\n",
      "Epoch [205/400], Train Loss: 0.6034, Test Loss: 18.1652\n",
      "Epoch [206/400], Train Loss: 0.6112, Test Loss: 18.1194\n",
      "Epoch [207/400], Train Loss: 0.6484, Test Loss: 18.2822\n",
      "Epoch [208/400], Train Loss: 0.9801, Test Loss: 18.3756\n",
      "Epoch [209/400], Train Loss: 1.0527, Test Loss: 18.0461\n",
      "Epoch [210/400], Train Loss: 1.2168, Test Loss: 17.9291\n",
      "Epoch [211/400], Train Loss: 1.1399, Test Loss: 17.1403\n",
      "Epoch [212/400], Train Loss: 1.0956, Test Loss: 19.1565\n",
      "Epoch [213/400], Train Loss: 0.6930, Test Loss: 18.0451\n",
      "Epoch [214/400], Train Loss: 0.4304, Test Loss: 18.2463\n",
      "Epoch [215/400], Train Loss: 0.4525, Test Loss: 18.1010\n",
      "Epoch [216/400], Train Loss: 0.4670, Test Loss: 17.8106\n",
      "Epoch [217/400], Train Loss: 0.4223, Test Loss: 17.7475\n",
      "Epoch [218/400], Train Loss: 0.3893, Test Loss: 18.0977\n",
      "Epoch [219/400], Train Loss: 0.3300, Test Loss: 18.8371\n",
      "Epoch [220/400], Train Loss: 0.3106, Test Loss: 18.0227\n",
      "Epoch [221/400], Train Loss: 0.3592, Test Loss: 18.4328\n",
      "Epoch [222/400], Train Loss: 0.3460, Test Loss: 18.1335\n",
      "Epoch [223/400], Train Loss: 0.3603, Test Loss: 18.3489\n",
      "Epoch [224/400], Train Loss: 0.4609, Test Loss: 18.0217\n",
      "Epoch [225/400], Train Loss: 0.4406, Test Loss: 17.6800\n",
      "Epoch [226/400], Train Loss: 0.4180, Test Loss: 18.5363\n",
      "Epoch [227/400], Train Loss: 0.4261, Test Loss: 18.1214\n",
      "Epoch [228/400], Train Loss: 0.3877, Test Loss: 18.6766\n",
      "Epoch [229/400], Train Loss: 0.3490, Test Loss: 18.2663\n",
      "Epoch [230/400], Train Loss: 0.2844, Test Loss: 18.2842\n",
      "Epoch [231/400], Train Loss: 0.2448, Test Loss: 18.8226\n",
      "Epoch [232/400], Train Loss: 0.2406, Test Loss: 17.9752\n",
      "Epoch [233/400], Train Loss: 0.2882, Test Loss: 17.9414\n",
      "Epoch [234/400], Train Loss: 0.2792, Test Loss: 18.2287\n",
      "Epoch [235/400], Train Loss: 0.2733, Test Loss: 18.3110\n",
      "Epoch [236/400], Train Loss: 0.2966, Test Loss: 18.2598\n",
      "Epoch [237/400], Train Loss: 0.5433, Test Loss: 18.3838\n",
      "Epoch [238/400], Train Loss: 0.6092, Test Loss: 18.1089\n",
      "Epoch [239/400], Train Loss: 0.5506, Test Loss: 17.7738\n",
      "Epoch [240/400], Train Loss: 0.6186, Test Loss: 17.9635\n",
      "Epoch [241/400], Train Loss: 0.9338, Test Loss: 18.3084\n",
      "Epoch [242/400], Train Loss: 0.7169, Test Loss: 17.6882\n",
      "Epoch [243/400], Train Loss: 0.5512, Test Loss: 19.2304\n",
      "Epoch [244/400], Train Loss: 0.4396, Test Loss: 18.1409\n",
      "Epoch [245/400], Train Loss: 0.3127, Test Loss: 18.1595\n",
      "Epoch [246/400], Train Loss: 0.2761, Test Loss: 17.8822\n",
      "Epoch [247/400], Train Loss: 0.1969, Test Loss: 17.9317\n",
      "Epoch [248/400], Train Loss: 0.1812, Test Loss: 18.1160\n",
      "Epoch [249/400], Train Loss: 0.1642, Test Loss: 18.1040\n",
      "Epoch [250/400], Train Loss: 0.1453, Test Loss: 18.3936\n",
      "Epoch [251/400], Train Loss: 0.1660, Test Loss: 18.0130\n",
      "Epoch [252/400], Train Loss: 0.1518, Test Loss: 17.9465\n",
      "Epoch [253/400], Train Loss: 0.1287, Test Loss: 18.2799\n",
      "Epoch [254/400], Train Loss: 0.1142, Test Loss: 17.9372\n",
      "Epoch [255/400], Train Loss: 0.1190, Test Loss: 18.1835\n",
      "Epoch [256/400], Train Loss: 0.1379, Test Loss: 18.2288\n",
      "Epoch [257/400], Train Loss: 0.1404, Test Loss: 18.1163\n",
      "Epoch [258/400], Train Loss: 0.1078, Test Loss: 17.9375\n",
      "Epoch [259/400], Train Loss: 0.1378, Test Loss: 18.3633\n",
      "Epoch [260/400], Train Loss: 0.1330, Test Loss: 18.0167\n",
      "Epoch [261/400], Train Loss: 0.2288, Test Loss: 18.3184\n",
      "Epoch [262/400], Train Loss: 0.3711, Test Loss: 18.2212\n",
      "Epoch [263/400], Train Loss: 0.4097, Test Loss: 17.9164\n",
      "Epoch [264/400], Train Loss: 0.4414, Test Loss: 17.5482\n",
      "Epoch [265/400], Train Loss: 0.5034, Test Loss: 17.8825\n",
      "Epoch [266/400], Train Loss: 0.5100, Test Loss: 17.1354\n",
      "Epoch [267/400], Train Loss: 0.4351, Test Loss: 17.6972\n",
      "Epoch [268/400], Train Loss: 0.3339, Test Loss: 17.5047\n",
      "Epoch [269/400], Train Loss: 0.3929, Test Loss: 17.4932\n",
      "Epoch [270/400], Train Loss: 0.4566, Test Loss: 18.0439\n",
      "Epoch [271/400], Train Loss: 0.3862, Test Loss: 17.6976\n",
      "Epoch [272/400], Train Loss: 0.3083, Test Loss: 17.3818\n",
      "Epoch [273/400], Train Loss: 0.3038, Test Loss: 17.8662\n",
      "Epoch [274/400], Train Loss: 0.2189, Test Loss: 17.3699\n",
      "Epoch [275/400], Train Loss: 0.1653, Test Loss: 17.6514\n",
      "Epoch [276/400], Train Loss: 0.1419, Test Loss: 17.7034\n",
      "Epoch [277/400], Train Loss: 0.0988, Test Loss: 17.8970\n",
      "Epoch [278/400], Train Loss: 0.0878, Test Loss: 18.1043\n",
      "Epoch [279/400], Train Loss: 0.0789, Test Loss: 17.9131\n",
      "Epoch [280/400], Train Loss: 0.0853, Test Loss: 17.8052\n",
      "Epoch [281/400], Train Loss: 0.0811, Test Loss: 17.7687\n",
      "Epoch [282/400], Train Loss: 0.0847, Test Loss: 17.7048\n",
      "Epoch [283/400], Train Loss: 0.0788, Test Loss: 17.9298\n",
      "Epoch [284/400], Train Loss: 0.0742, Test Loss: 17.8807\n",
      "Epoch [285/400], Train Loss: 0.0711, Test Loss: 17.8220\n",
      "Epoch [286/400], Train Loss: 0.0680, Test Loss: 17.7840\n",
      "Epoch [287/400], Train Loss: 0.0824, Test Loss: 17.8936\n",
      "Epoch [288/400], Train Loss: 0.1052, Test Loss: 18.2272\n",
      "Epoch [289/400], Train Loss: 0.1918, Test Loss: 17.7557\n",
      "Epoch [290/400], Train Loss: 0.2714, Test Loss: 17.9126\n",
      "Epoch [291/400], Train Loss: 0.5789, Test Loss: 17.7146\n",
      "Epoch [292/400], Train Loss: 2.8175, Test Loss: 20.1609\n",
      "Epoch [293/400], Train Loss: 11.3250, Test Loss: 16.3824\n",
      "Epoch [294/400], Train Loss: 9.3071, Test Loss: 16.6960\n",
      "Epoch [295/400], Train Loss: 7.8845, Test Loss: 17.0646\n",
      "Epoch [296/400], Train Loss: 5.8003, Test Loss: 16.0858\n",
      "Epoch [297/400], Train Loss: 5.3533, Test Loss: 17.5839\n",
      "Epoch [298/400], Train Loss: 3.7304, Test Loss: 17.4436\n",
      "Epoch [299/400], Train Loss: 2.9975, Test Loss: 16.9997\n",
      "Epoch [300/400], Train Loss: 2.2670, Test Loss: 18.1812\n",
      "Epoch [301/400], Train Loss: 1.7359, Test Loss: 19.4658\n",
      "Epoch [302/400], Train Loss: 1.5314, Test Loss: 17.9140\n",
      "Epoch [303/400], Train Loss: 1.1760, Test Loss: 18.0293\n",
      "Epoch [304/400], Train Loss: 0.9051, Test Loss: 18.2241\n",
      "Epoch [305/400], Train Loss: 0.9025, Test Loss: 17.9730\n",
      "Epoch [306/400], Train Loss: 0.7214, Test Loss: 17.6614\n",
      "Epoch [307/400], Train Loss: 0.6665, Test Loss: 18.4417\n",
      "Epoch [308/400], Train Loss: 0.5955, Test Loss: 18.2336\n",
      "Epoch [309/400], Train Loss: 0.4897, Test Loss: 18.4939\n",
      "Epoch [310/400], Train Loss: 0.4416, Test Loss: 18.4808\n",
      "Epoch [311/400], Train Loss: 0.4812, Test Loss: 18.2122\n",
      "Epoch [312/400], Train Loss: 0.4435, Test Loss: 18.2138\n",
      "Epoch [313/400], Train Loss: 0.3892, Test Loss: 18.6396\n",
      "Epoch [314/400], Train Loss: 0.3172, Test Loss: 18.1686\n",
      "Epoch [315/400], Train Loss: 0.3079, Test Loss: 17.9706\n",
      "Epoch [316/400], Train Loss: 0.3341, Test Loss: 18.2545\n",
      "Epoch [317/400], Train Loss: 0.3033, Test Loss: 18.5766\n",
      "Epoch [318/400], Train Loss: 0.2653, Test Loss: 18.6872\n",
      "Epoch [319/400], Train Loss: 0.2422, Test Loss: 18.9133\n",
      "Epoch [320/400], Train Loss: 0.2164, Test Loss: 18.3626\n",
      "Epoch [321/400], Train Loss: 0.2466, Test Loss: 18.4099\n",
      "Epoch [322/400], Train Loss: 0.1999, Test Loss: 18.2745\n",
      "Epoch [323/400], Train Loss: 0.1720, Test Loss: 18.4236\n",
      "Epoch [324/400], Train Loss: 0.1638, Test Loss: 18.4947\n",
      "Epoch [325/400], Train Loss: 0.2239, Test Loss: 18.6743\n",
      "Epoch [326/400], Train Loss: 0.3407, Test Loss: 18.4634\n",
      "Epoch [327/400], Train Loss: 0.3503, Test Loss: 18.3565\n",
      "Epoch [328/400], Train Loss: 0.2910, Test Loss: 18.2331\n",
      "Epoch [329/400], Train Loss: 0.3062, Test Loss: 18.7004\n",
      "Epoch [330/400], Train Loss: 0.2452, Test Loss: 18.0983\n",
      "Epoch [331/400], Train Loss: 0.1902, Test Loss: 18.8175\n",
      "Epoch [332/400], Train Loss: 0.1537, Test Loss: 18.4142\n",
      "Epoch [333/400], Train Loss: 0.1500, Test Loss: 18.4835\n",
      "Epoch [334/400], Train Loss: 0.1509, Test Loss: 18.2582\n",
      "Epoch [335/400], Train Loss: 0.1402, Test Loss: 18.4715\n",
      "Epoch [336/400], Train Loss: 0.1592, Test Loss: 18.6237\n",
      "Epoch [337/400], Train Loss: 0.1355, Test Loss: 18.5084\n",
      "Epoch [338/400], Train Loss: 0.1279, Test Loss: 18.2916\n",
      "Epoch [339/400], Train Loss: 0.1359, Test Loss: 18.6939\n",
      "Epoch [340/400], Train Loss: 0.1731, Test Loss: 18.7901\n",
      "Epoch [341/400], Train Loss: 0.1459, Test Loss: 18.2847\n",
      "Epoch [342/400], Train Loss: 0.1563, Test Loss: 18.6105\n",
      "Epoch [343/400], Train Loss: 0.2210, Test Loss: 18.9016\n",
      "Epoch [344/400], Train Loss: 0.4065, Test Loss: 18.4517\n",
      "Epoch [345/400], Train Loss: 0.3142, Test Loss: 18.3792\n",
      "Epoch [346/400], Train Loss: 0.3560, Test Loss: 18.7214\n",
      "Epoch [347/400], Train Loss: 0.2797, Test Loss: 18.8085\n",
      "Epoch [348/400], Train Loss: 0.2475, Test Loss: 18.7316\n",
      "Epoch [349/400], Train Loss: 0.3599, Test Loss: 18.3714\n",
      "Epoch [350/400], Train Loss: 0.3853, Test Loss: 18.5019\n",
      "Epoch [351/400], Train Loss: 0.3248, Test Loss: 18.6966\n",
      "Epoch [352/400], Train Loss: 0.3073, Test Loss: 18.7879\n",
      "Epoch [353/400], Train Loss: 0.3221, Test Loss: 18.3624\n",
      "Epoch [354/400], Train Loss: 0.2507, Test Loss: 18.2791\n",
      "Epoch [355/400], Train Loss: 0.2019, Test Loss: 18.5427\n",
      "Epoch [356/400], Train Loss: 0.1749, Test Loss: 18.5929\n",
      "Epoch [357/400], Train Loss: 0.2217, Test Loss: 18.6333\n",
      "Epoch [358/400], Train Loss: 0.1626, Test Loss: 18.2781\n",
      "Epoch [359/400], Train Loss: 0.1455, Test Loss: 18.1356\n",
      "Epoch [360/400], Train Loss: 0.1206, Test Loss: 18.1823\n",
      "Epoch [361/400], Train Loss: 0.1344, Test Loss: 18.3053\n",
      "Epoch [362/400], Train Loss: 0.1326, Test Loss: 18.5820\n",
      "Epoch [363/400], Train Loss: 0.1360, Test Loss: 18.0539\n",
      "Epoch [364/400], Train Loss: 0.1200, Test Loss: 18.3052\n",
      "Epoch [365/400], Train Loss: 0.1046, Test Loss: 18.4799\n",
      "Epoch [366/400], Train Loss: 0.0886, Test Loss: 18.2327\n",
      "Epoch [367/400], Train Loss: 0.0801, Test Loss: 18.3573\n",
      "Epoch [368/400], Train Loss: 0.0857, Test Loss: 18.8038\n",
      "Epoch [369/400], Train Loss: 0.0880, Test Loss: 18.4351\n",
      "Epoch [370/400], Train Loss: 0.1141, Test Loss: 18.2292\n",
      "Epoch [371/400], Train Loss: 0.1529, Test Loss: 18.7379\n",
      "Epoch [372/400], Train Loss: 0.3600, Test Loss: 18.5020\n",
      "Epoch [373/400], Train Loss: 0.3163, Test Loss: 18.1212\n",
      "Epoch [374/400], Train Loss: 0.6755, Test Loss: 18.2954\n",
      "Epoch [375/400], Train Loss: 8.3510, Test Loss: 19.7225\n",
      "Epoch [376/400], Train Loss: 7.5037, Test Loss: 18.2531\n",
      "Epoch [377/400], Train Loss: 4.4295, Test Loss: 17.1631\n",
      "Epoch [378/400], Train Loss: 3.0485, Test Loss: 17.8253\n",
      "Epoch [379/400], Train Loss: 2.0020, Test Loss: 17.9011\n",
      "Epoch [380/400], Train Loss: 1.0760, Test Loss: 17.2638\n",
      "Epoch [381/400], Train Loss: 0.7591, Test Loss: 17.4848\n",
      "Epoch [382/400], Train Loss: 0.5518, Test Loss: 17.5742\n",
      "Epoch [383/400], Train Loss: 0.4348, Test Loss: 17.5142\n",
      "Epoch [384/400], Train Loss: 0.3248, Test Loss: 17.1872\n",
      "Epoch [385/400], Train Loss: 0.2707, Test Loss: 17.1579\n",
      "Epoch [386/400], Train Loss: 0.2119, Test Loss: 17.3315\n",
      "Epoch [387/400], Train Loss: 0.1940, Test Loss: 17.6351\n",
      "Epoch [388/400], Train Loss: 0.1778, Test Loss: 17.6789\n",
      "Epoch [389/400], Train Loss: 0.1368, Test Loss: 17.2892\n",
      "Epoch [390/400], Train Loss: 0.1247, Test Loss: 17.4554\n",
      "Epoch [391/400], Train Loss: 0.1235, Test Loss: 17.4521\n",
      "Epoch [392/400], Train Loss: 0.1128, Test Loss: 17.6357\n",
      "Epoch [393/400], Train Loss: 0.1071, Test Loss: 17.5627\n",
      "Epoch [394/400], Train Loss: 0.0925, Test Loss: 17.5849\n",
      "Epoch [395/400], Train Loss: 0.0807, Test Loss: 17.6371\n",
      "Epoch [396/400], Train Loss: 0.0695, Test Loss: 17.6274\n",
      "Epoch [397/400], Train Loss: 0.0845, Test Loss: 17.8303\n",
      "Epoch [398/400], Train Loss: 0.1054, Test Loss: 17.6804\n",
      "Epoch [399/400], Train Loss: 0.0873, Test Loss: 17.7093\n",
      "Epoch [400/400], Train Loss: 0.0716, Test Loss: 17.6620\n",
      "Epoch [1/400], Train Loss: 178015.8953, Test Loss: 160322.8424\n",
      "Epoch [2/400], Train Loss: 173323.1377, Test Loss: 157273.0099\n",
      "Epoch [3/400], Train Loss: 170239.1861, Test Loss: 154565.1402\n",
      "Epoch [4/400], Train Loss: 167387.4954, Test Loss: 152003.1413\n",
      "Epoch [5/400], Train Loss: 164938.9535, Test Loss: 149510.2302\n",
      "Epoch [6/400], Train Loss: 162255.6012, Test Loss: 147099.8242\n",
      "Epoch [7/400], Train Loss: 159718.5630, Test Loss: 144744.5878\n",
      "Epoch [8/400], Train Loss: 157316.9696, Test Loss: 142472.9550\n",
      "Epoch [9/400], Train Loss: 154808.6862, Test Loss: 140234.4894\n",
      "Epoch [10/400], Train Loss: 152496.1096, Test Loss: 138095.3801\n",
      "Epoch [11/400], Train Loss: 149869.1829, Test Loss: 135941.5506\n",
      "Epoch [12/400], Train Loss: 147643.1628, Test Loss: 133851.1055\n",
      "Epoch [13/400], Train Loss: 145536.3525, Test Loss: 131810.5239\n",
      "Epoch [14/400], Train Loss: 143407.1442, Test Loss: 129845.5324\n",
      "Epoch [15/400], Train Loss: 140931.6403, Test Loss: 127871.7500\n",
      "Epoch [16/400], Train Loss: 139270.7052, Test Loss: 125988.1707\n",
      "Epoch [17/400], Train Loss: 137254.0653, Test Loss: 124100.9743\n",
      "Epoch [18/400], Train Loss: 134626.1105, Test Loss: 122268.4708\n",
      "Epoch [19/400], Train Loss: 132951.8563, Test Loss: 120499.4472\n",
      "Epoch [20/400], Train Loss: 130529.8626, Test Loss: 118732.9600\n",
      "Epoch [21/400], Train Loss: 129100.0378, Test Loss: 117052.0928\n",
      "Epoch [22/400], Train Loss: 127001.2791, Test Loss: 115383.2948\n",
      "Epoch [23/400], Train Loss: 125733.3419, Test Loss: 113761.0586\n",
      "Epoch [24/400], Train Loss: 123867.8290, Test Loss: 112156.2757\n",
      "Epoch [25/400], Train Loss: 121771.4197, Test Loss: 110604.4097\n",
      "Epoch [26/400], Train Loss: 120690.0165, Test Loss: 109069.0485\n",
      "Epoch [27/400], Train Loss: 118548.5784, Test Loss: 107577.8511\n",
      "Epoch [28/400], Train Loss: 117034.8532, Test Loss: 106128.7530\n",
      "Epoch [29/400], Train Loss: 115544.2837, Test Loss: 104712.9285\n",
      "Epoch [30/400], Train Loss: 113973.5525, Test Loss: 103324.9177\n",
      "Epoch [31/400], Train Loss: 112101.9939, Test Loss: 101956.0551\n",
      "Epoch [32/400], Train Loss: 110908.7591, Test Loss: 100641.6264\n",
      "Epoch [33/400], Train Loss: 109470.3293, Test Loss: 99336.1222\n",
      "Epoch [34/400], Train Loss: 107912.3746, Test Loss: 98077.8516\n",
      "Epoch [35/400], Train Loss: 106356.4806, Test Loss: 96833.2973\n",
      "Epoch [36/400], Train Loss: 105168.9609, Test Loss: 95628.8971\n",
      "Epoch [37/400], Train Loss: 103756.6412, Test Loss: 94457.8208\n",
      "Epoch [38/400], Train Loss: 102547.5017, Test Loss: 93328.9260\n",
      "Epoch [39/400], Train Loss: 101111.7007, Test Loss: 92197.7721\n",
      "Epoch [40/400], Train Loss: 99852.4584, Test Loss: 91121.8015\n",
      "Epoch [41/400], Train Loss: 98709.8816, Test Loss: 90050.9938\n",
      "Epoch [42/400], Train Loss: 97649.6178, Test Loss: 89051.4478\n",
      "Epoch [43/400], Train Loss: 96384.4367, Test Loss: 88017.9007\n",
      "Epoch [44/400], Train Loss: 95108.6059, Test Loss: 87065.2148\n",
      "Epoch [45/400], Train Loss: 94135.1638, Test Loss: 86122.5267\n",
      "Epoch [46/400], Train Loss: 93036.6566, Test Loss: 85172.1059\n",
      "Epoch [47/400], Train Loss: 92081.4023, Test Loss: 84299.3895\n",
      "Epoch [48/400], Train Loss: 90905.1113, Test Loss: 83415.5216\n",
      "Epoch [49/400], Train Loss: 89647.8983, Test Loss: 82560.1705\n",
      "Epoch [50/400], Train Loss: 88961.7168, Test Loss: 81767.6039\n",
      "Epoch [51/400], Train Loss: 87969.0146, Test Loss: 80967.2624\n",
      "Epoch [52/400], Train Loss: 87036.2352, Test Loss: 80199.4580\n",
      "Epoch [53/400], Train Loss: 86167.4126, Test Loss: 79451.9021\n",
      "Epoch [54/400], Train Loss: 85119.2206, Test Loss: 78742.2544\n",
      "Epoch [55/400], Train Loss: 84446.2687, Test Loss: 78053.3146\n",
      "Epoch [56/400], Train Loss: 83679.8007, Test Loss: 77376.1335\n",
      "Epoch [57/400], Train Loss: 82815.2490, Test Loss: 76712.7390\n",
      "Epoch [58/400], Train Loss: 81970.2574, Test Loss: 76092.9079\n",
      "Epoch [59/400], Train Loss: 81311.4147, Test Loss: 75499.4614\n",
      "Epoch [60/400], Train Loss: 80487.3072, Test Loss: 74892.9159\n",
      "Epoch [61/400], Train Loss: 79832.2033, Test Loss: 74328.0296\n",
      "Epoch [62/400], Train Loss: 79189.6849, Test Loss: 73793.6413\n",
      "Epoch [63/400], Train Loss: 78441.5850, Test Loss: 73277.6909\n",
      "Epoch [64/400], Train Loss: 77974.6812, Test Loss: 72773.5329\n",
      "Epoch [65/400], Train Loss: 77379.8588, Test Loss: 72287.5409\n",
      "Epoch [66/400], Train Loss: 76837.7221, Test Loss: 71830.3973\n",
      "Epoch [67/400], Train Loss: 76165.1169, Test Loss: 71371.0159\n",
      "Epoch [68/400], Train Loss: 75604.7114, Test Loss: 70950.7137\n",
      "Epoch [69/400], Train Loss: 74991.5594, Test Loss: 70530.5735\n",
      "Epoch [70/400], Train Loss: 74513.0691, Test Loss: 70150.9809\n",
      "Epoch [71/400], Train Loss: 74119.3937, Test Loss: 69779.4894\n",
      "Epoch [72/400], Train Loss: 73434.3608, Test Loss: 69424.4515\n",
      "Epoch [73/400], Train Loss: 73012.3737, Test Loss: 69078.9159\n",
      "Epoch [74/400], Train Loss: 72570.5767, Test Loss: 68759.3040\n",
      "Epoch [75/400], Train Loss: 72089.4174, Test Loss: 68452.9614\n",
      "Epoch [76/400], Train Loss: 71683.8987, Test Loss: 68170.8989\n",
      "Epoch [77/400], Train Loss: 71414.8064, Test Loss: 67889.2879\n",
      "Epoch [78/400], Train Loss: 71114.4149, Test Loss: 67628.7061\n",
      "Epoch [79/400], Train Loss: 70749.4519, Test Loss: 67375.5724\n",
      "Epoch [80/400], Train Loss: 70249.5093, Test Loss: 67147.3950\n",
      "Epoch [81/400], Train Loss: 70041.1012, Test Loss: 66925.9166\n",
      "Epoch [82/400], Train Loss: 69738.0107, Test Loss: 66719.2610\n",
      "Epoch [83/400], Train Loss: 69490.0539, Test Loss: 66525.6121\n",
      "Epoch [84/400], Train Loss: 69146.4041, Test Loss: 66347.1680\n",
      "Epoch [85/400], Train Loss: 68726.3150, Test Loss: 66175.4467\n",
      "Epoch [86/400], Train Loss: 68560.7537, Test Loss: 66014.9203\n",
      "Epoch [87/400], Train Loss: 68259.2231, Test Loss: 65877.5198\n",
      "Epoch [88/400], Train Loss: 67987.1821, Test Loss: 65737.2516\n",
      "Epoch [89/400], Train Loss: 67932.1406, Test Loss: 65614.1174\n",
      "Epoch [90/400], Train Loss: 67696.8971, Test Loss: 65492.0584\n",
      "Epoch [91/400], Train Loss: 67591.7668, Test Loss: 65390.9674\n",
      "Epoch [92/400], Train Loss: 67256.3112, Test Loss: 65290.0609\n",
      "Epoch [93/400], Train Loss: 67026.7388, Test Loss: 65195.9570\n",
      "Epoch [94/400], Train Loss: 66877.3904, Test Loss: 65081.9136\n",
      "Epoch [95/400], Train Loss: 66717.8869, Test Loss: 65003.3394\n",
      "Epoch [96/400], Train Loss: 66632.4520, Test Loss: 64937.1448\n",
      "Epoch [97/400], Train Loss: 66370.4237, Test Loss: 64741.6301\n",
      "Epoch [98/400], Train Loss: 66081.7468, Test Loss: 64736.8097\n",
      "Epoch [99/400], Train Loss: 65859.4796, Test Loss: 64222.8481\n",
      "Epoch [100/400], Train Loss: 65697.8650, Test Loss: 64271.8136\n",
      "Epoch [101/400], Train Loss: 65608.4689, Test Loss: 64147.2567\n",
      "Epoch [102/400], Train Loss: 65411.7434, Test Loss: 64128.1128\n",
      "Epoch [103/400], Train Loss: 65123.6549, Test Loss: 64108.6225\n",
      "Epoch [104/400], Train Loss: 65001.4993, Test Loss: 63692.7502\n",
      "Epoch [105/400], Train Loss: 64578.4635, Test Loss: 63640.5361\n",
      "Epoch [106/400], Train Loss: 64653.5654, Test Loss: 63347.3405\n",
      "Epoch [107/400], Train Loss: 64374.1963, Test Loss: 63597.5106\n",
      "Epoch [108/400], Train Loss: 64212.6330, Test Loss: 63646.2521\n",
      "Epoch [109/400], Train Loss: 63906.3377, Test Loss: 63083.6009\n",
      "Epoch [110/400], Train Loss: 63949.8663, Test Loss: 63099.5287\n",
      "Epoch [111/400], Train Loss: 63855.9683, Test Loss: 63241.0979\n",
      "Epoch [112/400], Train Loss: 63594.6152, Test Loss: 63264.6636\n",
      "Epoch [113/400], Train Loss: 63000.2360, Test Loss: 62989.8670\n",
      "Epoch [114/400], Train Loss: 63056.8469, Test Loss: 62722.7399\n",
      "Epoch [115/400], Train Loss: 63033.8239, Test Loss: 63224.0030\n",
      "Epoch [116/400], Train Loss: 62692.6459, Test Loss: 63017.7102\n",
      "Epoch [117/400], Train Loss: 62668.9463, Test Loss: 62798.3500\n",
      "Epoch [118/400], Train Loss: 62762.2400, Test Loss: 62343.0076\n",
      "Epoch [119/400], Train Loss: 62702.6565, Test Loss: 62181.7043\n",
      "Epoch [120/400], Train Loss: 62281.3044, Test Loss: 61949.3438\n",
      "Epoch [121/400], Train Loss: 61960.4962, Test Loss: 62344.5076\n",
      "Epoch [122/400], Train Loss: 61770.9511, Test Loss: 62056.3290\n",
      "Epoch [123/400], Train Loss: 61564.6553, Test Loss: 61886.9221\n",
      "Epoch [124/400], Train Loss: 61546.3078, Test Loss: 62254.2767\n",
      "Epoch [125/400], Train Loss: 61237.5386, Test Loss: 61687.2790\n",
      "Epoch [126/400], Train Loss: 61628.0586, Test Loss: 61626.3258\n",
      "Epoch [127/400], Train Loss: 61454.0884, Test Loss: 62407.0142\n",
      "Epoch [128/400], Train Loss: 60911.6426, Test Loss: 61191.5928\n",
      "Epoch [129/400], Train Loss: 61340.8596, Test Loss: 61472.1751\n",
      "Epoch [130/400], Train Loss: 60804.1431, Test Loss: 61387.2725\n",
      "Epoch [131/400], Train Loss: 60758.0371, Test Loss: 60916.9844\n",
      "Epoch [132/400], Train Loss: 60990.9310, Test Loss: 61444.8943\n",
      "Epoch [133/400], Train Loss: 61052.7065, Test Loss: 60929.7707\n",
      "Epoch [134/400], Train Loss: 61053.9929, Test Loss: 61061.6643\n",
      "Epoch [135/400], Train Loss: 60211.5682, Test Loss: 59660.0981\n",
      "Epoch [136/400], Train Loss: 60405.1427, Test Loss: 59999.9200\n",
      "Epoch [137/400], Train Loss: 59519.0077, Test Loss: 59443.1831\n",
      "Epoch [138/400], Train Loss: 60137.6231, Test Loss: 60116.4125\n",
      "Epoch [139/400], Train Loss: 59734.5498, Test Loss: 59845.4152\n",
      "Epoch [140/400], Train Loss: 59531.8651, Test Loss: 59689.7541\n",
      "Epoch [141/400], Train Loss: 59677.8654, Test Loss: 59695.3840\n",
      "Epoch [142/400], Train Loss: 58322.9101, Test Loss: 59349.7739\n",
      "Epoch [143/400], Train Loss: 58952.2063, Test Loss: 58825.2243\n",
      "Epoch [144/400], Train Loss: 58317.1129, Test Loss: 58097.0338\n",
      "Epoch [145/400], Train Loss: 58139.4225, Test Loss: 59894.5512\n",
      "Epoch [146/400], Train Loss: 57820.2076, Test Loss: 57865.1758\n",
      "Epoch [147/400], Train Loss: 58142.3323, Test Loss: 57099.3741\n",
      "Epoch [148/400], Train Loss: 56951.1352, Test Loss: 56491.0616\n",
      "Epoch [149/400], Train Loss: 57427.7951, Test Loss: 56577.8555\n",
      "Epoch [150/400], Train Loss: 57653.2053, Test Loss: 56658.1645\n",
      "Epoch [151/400], Train Loss: 57725.7322, Test Loss: 57347.1958\n",
      "Epoch [152/400], Train Loss: 57234.2140, Test Loss: 56925.8051\n",
      "Epoch [153/400], Train Loss: 56670.0506, Test Loss: 55553.5386\n",
      "Epoch [154/400], Train Loss: 56149.7312, Test Loss: 56179.4913\n",
      "Epoch [155/400], Train Loss: 55907.9145, Test Loss: 55910.5875\n",
      "Epoch [156/400], Train Loss: 55759.1378, Test Loss: 55265.6503\n",
      "Epoch [157/400], Train Loss: 55456.3957, Test Loss: 57210.8279\n",
      "Epoch [158/400], Train Loss: 57806.1697, Test Loss: 55448.1579\n",
      "Epoch [159/400], Train Loss: 55767.9211, Test Loss: 55013.9552\n",
      "Epoch [160/400], Train Loss: 56003.9419, Test Loss: 55482.7872\n",
      "Epoch [161/400], Train Loss: 55487.1757, Test Loss: 54927.3474\n",
      "Epoch [162/400], Train Loss: 54690.0270, Test Loss: 54693.9021\n",
      "Epoch [163/400], Train Loss: 55216.0541, Test Loss: 55260.7902\n",
      "Epoch [164/400], Train Loss: 54752.9518, Test Loss: 53515.1491\n",
      "Epoch [165/400], Train Loss: 53739.9709, Test Loss: 54854.5770\n",
      "Epoch [166/400], Train Loss: 53818.5235, Test Loss: 57927.3748\n",
      "Epoch [167/400], Train Loss: 55232.4225, Test Loss: 55864.3387\n",
      "Epoch [168/400], Train Loss: 53599.2427, Test Loss: 54058.6914\n",
      "Epoch [169/400], Train Loss: 53612.8885, Test Loss: 54068.8743\n",
      "Epoch [170/400], Train Loss: 53064.6613, Test Loss: 53028.7493\n",
      "Epoch [171/400], Train Loss: 53159.8136, Test Loss: 55053.2238\n",
      "Epoch [172/400], Train Loss: 52605.0627, Test Loss: 53937.9207\n",
      "Epoch [173/400], Train Loss: 52625.4380, Test Loss: 54158.6186\n",
      "Epoch [174/400], Train Loss: 54428.4022, Test Loss: 53200.7971\n",
      "Epoch [175/400], Train Loss: 52244.3315, Test Loss: 53607.4837\n",
      "Epoch [176/400], Train Loss: 52718.9319, Test Loss: 52852.6002\n",
      "Epoch [177/400], Train Loss: 51808.8587, Test Loss: 53430.4081\n",
      "Epoch [178/400], Train Loss: 51479.5694, Test Loss: 52929.2341\n",
      "Epoch [179/400], Train Loss: 51305.4309, Test Loss: 53055.6218\n",
      "Epoch [180/400], Train Loss: 50818.3732, Test Loss: 52519.3977\n",
      "Epoch [181/400], Train Loss: 51153.0588, Test Loss: 52906.9699\n",
      "Epoch [182/400], Train Loss: 51196.0401, Test Loss: 52690.6484\n",
      "Epoch [183/400], Train Loss: 51210.4817, Test Loss: 53937.0735\n",
      "Epoch [184/400], Train Loss: 50569.5406, Test Loss: 52889.6981\n",
      "Epoch [185/400], Train Loss: 52773.7702, Test Loss: 58784.6613\n",
      "Epoch [186/400], Train Loss: 51086.7557, Test Loss: 56006.9901\n",
      "Epoch [187/400], Train Loss: 51991.6312, Test Loss: 52705.2250\n",
      "Epoch [188/400], Train Loss: 48924.1670, Test Loss: 52072.5136\n",
      "Epoch [189/400], Train Loss: 49195.1245, Test Loss: 52204.8856\n",
      "Epoch [190/400], Train Loss: 49713.2884, Test Loss: 55616.5326\n",
      "Epoch [191/400], Train Loss: 49641.1846, Test Loss: 53281.9478\n",
      "Epoch [192/400], Train Loss: 50113.9212, Test Loss: 54312.2438\n",
      "Epoch [193/400], Train Loss: 49340.9090, Test Loss: 53279.8768\n",
      "Epoch [194/400], Train Loss: 49657.8440, Test Loss: 52302.2116\n",
      "Epoch [195/400], Train Loss: 48275.4145, Test Loss: 51765.7314\n",
      "Epoch [196/400], Train Loss: 47699.2584, Test Loss: 51633.9476\n",
      "Epoch [197/400], Train Loss: 48090.7822, Test Loss: 52491.8208\n",
      "Epoch [198/400], Train Loss: 47551.3374, Test Loss: 52315.0078\n",
      "Epoch [199/400], Train Loss: 47432.9596, Test Loss: 50772.8621\n",
      "Epoch [200/400], Train Loss: 48625.2876, Test Loss: 51293.6912\n",
      "Epoch [201/400], Train Loss: 48323.1290, Test Loss: 53641.6861\n",
      "Epoch [202/400], Train Loss: 50871.0270, Test Loss: 52709.8185\n",
      "Epoch [203/400], Train Loss: 49050.6232, Test Loss: 51847.5512\n",
      "Epoch [204/400], Train Loss: 47652.4344, Test Loss: 51250.9446\n",
      "Epoch [205/400], Train Loss: 47199.7853, Test Loss: 51462.3205\n",
      "Epoch [206/400], Train Loss: 48110.5810, Test Loss: 52069.7739\n",
      "Epoch [207/400], Train Loss: 46904.1906, Test Loss: 53472.7619\n",
      "Epoch [208/400], Train Loss: 48266.4836, Test Loss: 55242.8371\n",
      "Epoch [209/400], Train Loss: 46759.3250, Test Loss: 51280.2498\n",
      "Epoch [210/400], Train Loss: 46835.9227, Test Loss: 52401.6027\n",
      "Epoch [211/400], Train Loss: 47433.5884, Test Loss: 50348.0960\n",
      "Epoch [212/400], Train Loss: 46711.6078, Test Loss: 52878.1714\n",
      "Epoch [213/400], Train Loss: 46589.6175, Test Loss: 51014.9676\n",
      "Epoch [214/400], Train Loss: 48638.3372, Test Loss: 51792.1020\n",
      "Epoch [215/400], Train Loss: 46410.6645, Test Loss: 51453.5779\n",
      "Epoch [216/400], Train Loss: 45115.3363, Test Loss: 52355.2769\n",
      "Epoch [217/400], Train Loss: 45036.5620, Test Loss: 50779.9529\n",
      "Epoch [218/400], Train Loss: 45678.9047, Test Loss: 50047.4956\n",
      "Epoch [219/400], Train Loss: 45074.2213, Test Loss: 52068.7004\n",
      "Epoch [220/400], Train Loss: 44471.7042, Test Loss: 51610.8564\n",
      "Epoch [221/400], Train Loss: 46046.6017, Test Loss: 51395.9065\n",
      "Epoch [222/400], Train Loss: 44068.6522, Test Loss: 51040.2969\n",
      "Epoch [223/400], Train Loss: 44430.7323, Test Loss: 51349.1000\n",
      "Epoch [224/400], Train Loss: 44679.5605, Test Loss: 50815.8941\n",
      "Epoch [225/400], Train Loss: 43775.0586, Test Loss: 50772.2776\n",
      "Epoch [226/400], Train Loss: 43358.2153, Test Loss: 54616.0219\n",
      "Epoch [227/400], Train Loss: 44670.5135, Test Loss: 50746.1255\n",
      "Epoch [228/400], Train Loss: 44576.0040, Test Loss: 52910.5574\n",
      "Epoch [229/400], Train Loss: 44028.1310, Test Loss: 55817.2707\n",
      "Epoch [230/400], Train Loss: 45490.4416, Test Loss: 52091.6356\n",
      "Epoch [231/400], Train Loss: 44463.2028, Test Loss: 51451.1220\n",
      "Epoch [232/400], Train Loss: 44325.9471, Test Loss: 52202.7778\n",
      "Epoch [233/400], Train Loss: 44539.1484, Test Loss: 52046.5825\n",
      "Epoch [234/400], Train Loss: 44657.8726, Test Loss: 53514.0055\n",
      "Epoch [235/400], Train Loss: 43695.2329, Test Loss: 51899.0503\n",
      "Epoch [236/400], Train Loss: 43723.5698, Test Loss: 50734.4474\n",
      "Epoch [237/400], Train Loss: 43269.2761, Test Loss: 53039.8842\n",
      "Epoch [238/400], Train Loss: 43449.6369, Test Loss: 51628.8104\n",
      "Epoch [239/400], Train Loss: 43226.3206, Test Loss: 54316.8261\n",
      "Epoch [240/400], Train Loss: 45642.4324, Test Loss: 52881.2300\n",
      "Epoch [241/400], Train Loss: 42883.9152, Test Loss: 51109.2773\n",
      "Epoch [242/400], Train Loss: 43622.8790, Test Loss: 51675.7801\n",
      "Epoch [243/400], Train Loss: 42946.8817, Test Loss: 50321.3892\n",
      "Epoch [244/400], Train Loss: 41652.2721, Test Loss: 50484.7517\n",
      "Epoch [245/400], Train Loss: 41694.9847, Test Loss: 55240.9040\n",
      "Epoch [246/400], Train Loss: 47132.2480, Test Loss: 52098.5115\n",
      "Epoch [247/400], Train Loss: 46980.9531, Test Loss: 49682.5656\n",
      "Epoch [248/400], Train Loss: 44376.0011, Test Loss: 52300.0457\n",
      "Epoch [249/400], Train Loss: 43443.1785, Test Loss: 51136.7808\n",
      "Epoch [250/400], Train Loss: 43891.7772, Test Loss: 51744.6064\n",
      "Epoch [251/400], Train Loss: 43214.9869, Test Loss: 51211.0928\n",
      "Epoch [252/400], Train Loss: 42510.9172, Test Loss: 51489.6648\n",
      "Epoch [253/400], Train Loss: 45035.6261, Test Loss: 53874.4352\n",
      "Epoch [254/400], Train Loss: 43762.4782, Test Loss: 49956.6163\n",
      "Epoch [255/400], Train Loss: 47042.1618, Test Loss: 51348.4517\n",
      "Epoch [256/400], Train Loss: 45722.6262, Test Loss: 50109.1301\n",
      "Epoch [257/400], Train Loss: 43232.8806, Test Loss: 49393.7761\n",
      "Epoch [258/400], Train Loss: 43807.1696, Test Loss: 50796.4559\n",
      "Epoch [259/400], Train Loss: 43041.3203, Test Loss: 50872.1518\n",
      "Epoch [260/400], Train Loss: 41513.8356, Test Loss: 50558.4415\n",
      "Epoch [261/400], Train Loss: 41186.6187, Test Loss: 49029.1759\n",
      "Epoch [262/400], Train Loss: 41315.5306, Test Loss: 50228.3616\n",
      "Epoch [263/400], Train Loss: 41258.7122, Test Loss: 50223.6556\n",
      "Epoch [264/400], Train Loss: 40839.5854, Test Loss: 50311.1222\n",
      "Epoch [265/400], Train Loss: 40152.9195, Test Loss: 50884.5926\n",
      "Epoch [266/400], Train Loss: 40118.2124, Test Loss: 50055.7058\n",
      "Epoch [267/400], Train Loss: 40508.4902, Test Loss: 50620.6537\n",
      "Epoch [268/400], Train Loss: 42548.1680, Test Loss: 53466.6756\n",
      "Epoch [269/400], Train Loss: 49931.6326, Test Loss: 51325.8127\n",
      "Epoch [270/400], Train Loss: 42088.6831, Test Loss: 51451.7626\n",
      "Epoch [271/400], Train Loss: 41335.5216, Test Loss: 50892.4150\n",
      "Epoch [272/400], Train Loss: 40065.5651, Test Loss: 51157.5900\n",
      "Epoch [273/400], Train Loss: 40232.5138, Test Loss: 49977.7907\n",
      "Epoch [274/400], Train Loss: 41876.8537, Test Loss: 50298.7597\n",
      "Epoch [275/400], Train Loss: 40143.2141, Test Loss: 49928.5497\n",
      "Epoch [276/400], Train Loss: 39438.2029, Test Loss: 49194.1145\n",
      "Epoch [277/400], Train Loss: 39954.0925, Test Loss: 48325.2283\n",
      "Epoch [278/400], Train Loss: 39675.0998, Test Loss: 49428.0301\n",
      "Epoch [279/400], Train Loss: 39536.7739, Test Loss: 49820.7082\n",
      "Epoch [280/400], Train Loss: 39271.7340, Test Loss: 48785.7268\n",
      "Epoch [281/400], Train Loss: 38588.7984, Test Loss: 48574.6970\n",
      "Epoch [282/400], Train Loss: 41043.9455, Test Loss: 58846.2378\n",
      "Epoch [283/400], Train Loss: 48035.9745, Test Loss: 48052.0979\n",
      "Epoch [284/400], Train Loss: 40872.8313, Test Loss: 48941.7034\n",
      "Epoch [285/400], Train Loss: 39124.4323, Test Loss: 48336.6432\n",
      "Epoch [286/400], Train Loss: 39066.2805, Test Loss: 49102.2349\n",
      "Epoch [287/400], Train Loss: 38901.0907, Test Loss: 49737.3991\n",
      "Epoch [288/400], Train Loss: 38357.5491, Test Loss: 48654.3443\n",
      "Epoch [289/400], Train Loss: 38511.3674, Test Loss: 47748.5582\n",
      "Epoch [290/400], Train Loss: 37925.2047, Test Loss: 50245.3658\n",
      "Epoch [291/400], Train Loss: 38938.3613, Test Loss: 57283.1261\n",
      "Epoch [292/400], Train Loss: 41915.9667, Test Loss: 48854.0340\n",
      "Epoch [293/400], Train Loss: 37875.1897, Test Loss: 50417.5128\n",
      "Epoch [294/400], Train Loss: 37649.6400, Test Loss: 48754.3267\n",
      "Epoch [295/400], Train Loss: 37534.5853, Test Loss: 48849.9237\n",
      "Epoch [296/400], Train Loss: 38415.3393, Test Loss: 48862.3599\n",
      "Epoch [297/400], Train Loss: 38330.9039, Test Loss: 52470.3968\n",
      "Epoch [298/400], Train Loss: 53053.4277, Test Loss: 53819.6969\n",
      "Epoch [299/400], Train Loss: 46986.3550, Test Loss: 49181.8458\n",
      "Epoch [300/400], Train Loss: 39026.8007, Test Loss: 48235.1415\n",
      "Epoch [301/400], Train Loss: 37559.6513, Test Loss: 48153.6080\n",
      "Epoch [302/400], Train Loss: 37261.2159, Test Loss: 55112.6790\n",
      "Epoch [303/400], Train Loss: 38867.5991, Test Loss: 47764.8298\n",
      "Epoch [304/400], Train Loss: 38440.7701, Test Loss: 47889.2177\n",
      "Epoch [305/400], Train Loss: 37904.7891, Test Loss: 45879.4945\n",
      "Epoch [306/400], Train Loss: 36876.8854, Test Loss: 47754.1827\n",
      "Epoch [307/400], Train Loss: 37987.5832, Test Loss: 47448.3884\n",
      "Epoch [308/400], Train Loss: 37653.5419, Test Loss: 47604.7856\n",
      "Epoch [309/400], Train Loss: 37198.5707, Test Loss: 48537.6305\n",
      "Epoch [310/400], Train Loss: 38117.4617, Test Loss: 46860.5527\n",
      "Epoch [311/400], Train Loss: 37179.4798, Test Loss: 48158.9701\n",
      "Epoch [312/400], Train Loss: 36453.2993, Test Loss: 49116.2468\n",
      "Epoch [313/400], Train Loss: 37251.9570, Test Loss: 49505.2628\n",
      "Epoch [314/400], Train Loss: 35697.5070, Test Loss: 46869.3256\n",
      "Epoch [315/400], Train Loss: 35303.8508, Test Loss: 49438.4335\n",
      "Epoch [316/400], Train Loss: 39960.6460, Test Loss: 50824.3550\n",
      "Epoch [317/400], Train Loss: 42521.6078, Test Loss: 54259.2420\n",
      "Epoch [318/400], Train Loss: 46608.1888, Test Loss: 47617.6801\n",
      "Epoch [319/400], Train Loss: 40216.1212, Test Loss: 53305.4846\n",
      "Epoch [320/400], Train Loss: 39842.7260, Test Loss: 47561.4644\n",
      "Epoch [321/400], Train Loss: 37505.1004, Test Loss: 48603.4548\n",
      "Epoch [322/400], Train Loss: 36650.4176, Test Loss: 47305.4954\n",
      "Epoch [323/400], Train Loss: 38521.8265, Test Loss: 48367.7485\n",
      "Epoch [324/400], Train Loss: 40908.8781, Test Loss: 51420.7401\n",
      "Epoch [325/400], Train Loss: 40461.8455, Test Loss: 48937.3190\n",
      "Epoch [326/400], Train Loss: 38107.8354, Test Loss: 48858.3017\n",
      "Epoch [327/400], Train Loss: 37399.7033, Test Loss: 47767.4315\n",
      "Epoch [328/400], Train Loss: 38185.2469, Test Loss: 45644.7724\n",
      "Epoch [329/400], Train Loss: 37510.6829, Test Loss: 45785.4106\n",
      "Epoch [330/400], Train Loss: 36646.9277, Test Loss: 46833.2898\n",
      "Epoch [331/400], Train Loss: 37451.6991, Test Loss: 48434.0332\n",
      "Epoch [332/400], Train Loss: 39270.3979, Test Loss: 46593.3141\n",
      "Epoch [333/400], Train Loss: 38369.4541, Test Loss: 49298.5091\n",
      "Epoch [334/400], Train Loss: 37900.2014, Test Loss: 48958.6483\n",
      "Epoch [335/400], Train Loss: 36869.1074, Test Loss: 46957.9500\n",
      "Epoch [336/400], Train Loss: 38833.5045, Test Loss: 46538.3653\n",
      "Epoch [337/400], Train Loss: 37218.9749, Test Loss: 46403.2848\n",
      "Epoch [338/400], Train Loss: 37593.3674, Test Loss: 46753.3629\n",
      "Epoch [339/400], Train Loss: 38411.7669, Test Loss: 44378.6101\n",
      "Epoch [340/400], Train Loss: 37378.7593, Test Loss: 47204.5310\n",
      "Epoch [341/400], Train Loss: 38700.1134, Test Loss: 51233.8858\n",
      "Epoch [342/400], Train Loss: 39370.1821, Test Loss: 51990.6477\n",
      "Epoch [343/400], Train Loss: 38815.0551, Test Loss: 50276.4844\n",
      "Epoch [344/400], Train Loss: 38327.7952, Test Loss: 49021.5533\n",
      "Epoch [345/400], Train Loss: 37148.9110, Test Loss: 48841.7780\n",
      "Epoch [346/400], Train Loss: 36722.9313, Test Loss: 49465.5430\n",
      "Epoch [347/400], Train Loss: 38587.4886, Test Loss: 48013.2790\n",
      "Epoch [348/400], Train Loss: 36947.2046, Test Loss: 47993.5049\n",
      "Epoch [349/400], Train Loss: 35894.9614, Test Loss: 48067.0194\n",
      "Epoch [350/400], Train Loss: 36259.2692, Test Loss: 50321.6482\n",
      "Epoch [351/400], Train Loss: 36608.2943, Test Loss: 47748.5398\n",
      "Epoch [352/400], Train Loss: 35162.2879, Test Loss: 46180.3222\n",
      "Epoch [353/400], Train Loss: 34787.1107, Test Loss: 47584.3077\n",
      "Epoch [354/400], Train Loss: 35415.6727, Test Loss: 50370.6498\n",
      "Epoch [355/400], Train Loss: 37625.5328, Test Loss: 47852.2114\n",
      "Epoch [356/400], Train Loss: 35007.3332, Test Loss: 51407.0595\n",
      "Epoch [357/400], Train Loss: 34971.2870, Test Loss: 48079.5429\n",
      "Epoch [358/400], Train Loss: 33479.1377, Test Loss: 45798.2902\n",
      "Epoch [359/400], Train Loss: 34391.6971, Test Loss: 48803.0869\n",
      "Epoch [360/400], Train Loss: 34069.1913, Test Loss: 46212.9606\n",
      "Epoch [361/400], Train Loss: 35668.5085, Test Loss: 48277.7073\n",
      "Epoch [362/400], Train Loss: 34258.2741, Test Loss: 46933.6119\n",
      "Epoch [363/400], Train Loss: 37566.2129, Test Loss: 52537.7006\n",
      "Epoch [364/400], Train Loss: 35023.1172, Test Loss: 48646.7437\n",
      "Epoch [365/400], Train Loss: 33531.1937, Test Loss: 47140.1955\n",
      "Epoch [366/400], Train Loss: 33404.2904, Test Loss: 49177.1745\n",
      "Epoch [367/400], Train Loss: 34469.2589, Test Loss: 47801.2170\n",
      "Epoch [368/400], Train Loss: 32988.0017, Test Loss: 48326.7547\n",
      "Epoch [369/400], Train Loss: 35891.8192, Test Loss: 52677.3273\n",
      "Epoch [370/400], Train Loss: 38942.5946, Test Loss: 48834.1156\n",
      "Epoch [371/400], Train Loss: 35283.0843, Test Loss: 52895.7352\n",
      "Epoch [372/400], Train Loss: 39349.1488, Test Loss: 49749.3219\n",
      "Epoch [373/400], Train Loss: 35266.8590, Test Loss: 47948.2873\n",
      "Epoch [374/400], Train Loss: 34279.2293, Test Loss: 46426.0767\n",
      "Epoch [375/400], Train Loss: 33571.8103, Test Loss: 48809.9488\n",
      "Epoch [376/400], Train Loss: 39146.4139, Test Loss: 50500.4330\n",
      "Epoch [377/400], Train Loss: 39422.3763, Test Loss: 45271.7785\n",
      "Epoch [378/400], Train Loss: 35508.2365, Test Loss: 49770.9704\n",
      "Epoch [379/400], Train Loss: 34688.2673, Test Loss: 47807.3070\n",
      "Epoch [380/400], Train Loss: 34411.0056, Test Loss: 47574.1774\n",
      "Epoch [381/400], Train Loss: 32674.1009, Test Loss: 46590.3146\n",
      "Epoch [382/400], Train Loss: 32096.3421, Test Loss: 46303.4389\n",
      "Epoch [383/400], Train Loss: 31821.2162, Test Loss: 46879.7147\n",
      "Epoch [384/400], Train Loss: 30809.9719, Test Loss: 46510.8595\n",
      "Epoch [385/400], Train Loss: 31681.0661, Test Loss: 45478.0145\n",
      "Epoch [386/400], Train Loss: 30383.3759, Test Loss: 45806.0888\n",
      "Epoch [387/400], Train Loss: 34588.3408, Test Loss: 74026.3686\n",
      "Epoch [388/400], Train Loss: 65402.1048, Test Loss: 62818.5556\n",
      "Epoch [389/400], Train Loss: 59390.3279, Test Loss: 62301.6592\n",
      "Epoch [390/400], Train Loss: 56167.5291, Test Loss: 63644.7946\n",
      "Epoch [391/400], Train Loss: 47980.0179, Test Loss: 51132.2741\n",
      "Epoch [392/400], Train Loss: 44325.3076, Test Loss: 52810.4324\n",
      "Epoch [393/400], Train Loss: 43638.3867, Test Loss: 61287.2837\n",
      "Epoch [394/400], Train Loss: 51999.8802, Test Loss: 52890.0487\n",
      "Epoch [395/400], Train Loss: 43562.7570, Test Loss: 49623.1722\n",
      "Epoch [396/400], Train Loss: 54886.5128, Test Loss: 62543.4180\n",
      "Epoch [397/400], Train Loss: 58126.8938, Test Loss: 55605.7688\n",
      "Epoch [398/400], Train Loss: 52041.1258, Test Loss: 54026.2670\n",
      "Epoch [399/400], Train Loss: 52447.6418, Test Loss: 57083.1055\n",
      "Epoch [400/400], Train Loss: 51912.1642, Test Loss: 54168.2495\n",
      "Epoch [1/400], Train Loss: 217.7069, Test Loss: 153.5432\n",
      "Epoch [2/400], Train Loss: 124.0602, Test Loss: 111.0582\n",
      "Epoch [3/400], Train Loss: 101.1735, Test Loss: 98.7008\n",
      "Epoch [4/400], Train Loss: 95.0614, Test Loss: 95.3734\n",
      "Epoch [5/400], Train Loss: 93.9683, Test Loss: 94.1152\n",
      "Epoch [6/400], Train Loss: 88.3621, Test Loss: 82.3734\n",
      "Epoch [7/400], Train Loss: 74.0470, Test Loss: 61.4232\n",
      "Epoch [8/400], Train Loss: 56.5813, Test Loss: 44.7077\n",
      "Epoch [9/400], Train Loss: 45.4791, Test Loss: 36.6500\n",
      "Epoch [10/400], Train Loss: 42.6140, Test Loss: 51.7996\n",
      "Epoch [11/400], Train Loss: 31.6626, Test Loss: 27.5097\n",
      "Epoch [12/400], Train Loss: 26.2218, Test Loss: 23.2100\n",
      "Epoch [13/400], Train Loss: 21.3366, Test Loss: 19.8835\n",
      "Epoch [14/400], Train Loss: 15.9847, Test Loss: 14.5400\n",
      "Epoch [15/400], Train Loss: 15.5284, Test Loss: 14.8351\n",
      "Epoch [16/400], Train Loss: 11.3703, Test Loss: 9.8760\n",
      "Epoch [17/400], Train Loss: 9.0369, Test Loss: 8.7983\n",
      "Epoch [18/400], Train Loss: 10.4081, Test Loss: 9.6888\n",
      "Epoch [19/400], Train Loss: 9.0401, Test Loss: 8.3647\n",
      "Epoch [20/400], Train Loss: 10.1473, Test Loss: 8.0203\n",
      "Epoch [21/400], Train Loss: 6.9028, Test Loss: 6.2201\n",
      "Epoch [22/400], Train Loss: 5.5239, Test Loss: 5.9904\n",
      "Epoch [23/400], Train Loss: 5.7550, Test Loss: 5.5109\n",
      "Epoch [24/400], Train Loss: 5.1315, Test Loss: 4.8235\n",
      "Epoch [25/400], Train Loss: 5.2845, Test Loss: 5.0236\n",
      "Epoch [26/400], Train Loss: 4.6577, Test Loss: 5.3461\n",
      "Epoch [27/400], Train Loss: 4.4723, Test Loss: 4.3792\n",
      "Epoch [28/400], Train Loss: 4.3556, Test Loss: 4.5673\n",
      "Epoch [29/400], Train Loss: 3.8677, Test Loss: 5.0480\n",
      "Epoch [30/400], Train Loss: 4.7715, Test Loss: 5.2037\n",
      "Epoch [31/400], Train Loss: 3.9201, Test Loss: 4.6477\n",
      "Epoch [32/400], Train Loss: 4.0501, Test Loss: 4.0606\n",
      "Epoch [33/400], Train Loss: 3.6409, Test Loss: 4.5150\n",
      "Epoch [34/400], Train Loss: 3.5089, Test Loss: 6.1247\n",
      "Epoch [35/400], Train Loss: 3.3525, Test Loss: 3.3004\n",
      "Epoch [36/400], Train Loss: 3.0696, Test Loss: 3.2287\n",
      "Epoch [37/400], Train Loss: 2.9519, Test Loss: 3.5067\n",
      "Epoch [38/400], Train Loss: 2.9332, Test Loss: 3.3366\n",
      "Epoch [39/400], Train Loss: 2.5137, Test Loss: 3.2112\n",
      "Epoch [40/400], Train Loss: 2.7900, Test Loss: 3.2003\n",
      "Epoch [41/400], Train Loss: 2.8804, Test Loss: 4.0764\n",
      "Epoch [42/400], Train Loss: 2.7229, Test Loss: 3.2127\n",
      "Epoch [43/400], Train Loss: 5.0941, Test Loss: 4.6349\n",
      "Epoch [44/400], Train Loss: 4.8252, Test Loss: 3.7251\n",
      "Epoch [45/400], Train Loss: 2.9848, Test Loss: 3.5244\n",
      "Epoch [46/400], Train Loss: 2.2826, Test Loss: 3.0247\n",
      "Epoch [47/400], Train Loss: 2.4297, Test Loss: 2.8877\n",
      "Epoch [48/400], Train Loss: 2.1893, Test Loss: 2.9355\n",
      "Epoch [49/400], Train Loss: 1.9637, Test Loss: 2.4745\n",
      "Epoch [50/400], Train Loss: 1.9823, Test Loss: 2.7452\n",
      "Epoch [51/400], Train Loss: 1.8368, Test Loss: 2.3689\n",
      "Epoch [52/400], Train Loss: 2.0097, Test Loss: 2.5306\n",
      "Epoch [53/400], Train Loss: 1.9381, Test Loss: 2.7850\n",
      "Epoch [54/400], Train Loss: 1.9717, Test Loss: 2.7366\n",
      "Epoch [55/400], Train Loss: 1.7987, Test Loss: 2.8751\n",
      "Epoch [56/400], Train Loss: 1.7462, Test Loss: 2.6529\n",
      "Epoch [57/400], Train Loss: 1.7832, Test Loss: 3.4100\n",
      "Epoch [58/400], Train Loss: 10.1407, Test Loss: 7.5281\n",
      "Epoch [59/400], Train Loss: 40.9062, Test Loss: 38.3928\n",
      "Epoch [60/400], Train Loss: 34.4415, Test Loss: 59.0638\n",
      "Epoch [61/400], Train Loss: 26.1333, Test Loss: 20.0406\n",
      "Epoch [62/400], Train Loss: 13.1946, Test Loss: 11.4151\n",
      "Epoch [63/400], Train Loss: 8.3239, Test Loss: 9.0367\n",
      "Epoch [64/400], Train Loss: 9.2769, Test Loss: 11.3148\n",
      "Epoch [65/400], Train Loss: 7.0864, Test Loss: 5.1997\n",
      "Epoch [66/400], Train Loss: 5.3490, Test Loss: 4.7677\n",
      "Epoch [67/400], Train Loss: 3.8973, Test Loss: 4.5346\n",
      "Epoch [68/400], Train Loss: 3.5109, Test Loss: 4.8681\n",
      "Epoch [69/400], Train Loss: 4.5883, Test Loss: 5.6914\n",
      "Epoch [70/400], Train Loss: 3.2576, Test Loss: 3.4342\n",
      "Epoch [71/400], Train Loss: 2.6629, Test Loss: 3.4435\n",
      "Epoch [72/400], Train Loss: 2.4316, Test Loss: 3.3842\n",
      "Epoch [73/400], Train Loss: 2.3409, Test Loss: 3.7186\n",
      "Epoch [74/400], Train Loss: 2.6567, Test Loss: 3.5144\n",
      "Epoch [75/400], Train Loss: 2.6428, Test Loss: 2.9782\n",
      "Epoch [76/400], Train Loss: 2.3044, Test Loss: 3.5566\n",
      "Epoch [77/400], Train Loss: 2.4154, Test Loss: 2.7923\n",
      "Epoch [78/400], Train Loss: 2.2501, Test Loss: 2.9048\n",
      "Epoch [79/400], Train Loss: 2.0733, Test Loss: 2.9104\n",
      "Epoch [80/400], Train Loss: 6.6977, Test Loss: 5.9423\n",
      "Epoch [81/400], Train Loss: 3.7380, Test Loss: 4.2261\n",
      "Epoch [82/400], Train Loss: 2.6924, Test Loss: 2.9664\n",
      "Epoch [83/400], Train Loss: 2.1697, Test Loss: 2.7633\n",
      "Epoch [84/400], Train Loss: 1.9060, Test Loss: 2.6879\n",
      "Epoch [85/400], Train Loss: 2.2175, Test Loss: 2.6587\n",
      "Epoch [86/400], Train Loss: 1.9785, Test Loss: 3.1248\n",
      "Epoch [87/400], Train Loss: 1.8945, Test Loss: 2.9000\n",
      "Epoch [88/400], Train Loss: 1.9088, Test Loss: 2.8764\n",
      "Epoch [89/400], Train Loss: 1.8177, Test Loss: 2.7051\n",
      "Epoch [90/400], Train Loss: 1.6760, Test Loss: 2.9103\n",
      "Epoch [91/400], Train Loss: 1.8510, Test Loss: 2.7007\n",
      "Epoch [92/400], Train Loss: 2.0899, Test Loss: 3.1514\n",
      "Epoch [93/400], Train Loss: 2.2948, Test Loss: 2.4546\n",
      "Epoch [94/400], Train Loss: 1.8959, Test Loss: 2.5741\n",
      "Epoch [95/400], Train Loss: 2.0810, Test Loss: 2.7127\n",
      "Epoch [96/400], Train Loss: 1.6908, Test Loss: 2.3285\n",
      "Epoch [97/400], Train Loss: 1.6163, Test Loss: 2.4006\n",
      "Epoch [98/400], Train Loss: 1.7400, Test Loss: 2.9524\n",
      "Epoch [99/400], Train Loss: 1.7954, Test Loss: 2.5572\n",
      "Epoch [100/400], Train Loss: 1.6239, Test Loss: 2.5588\n",
      "Epoch [101/400], Train Loss: 1.5476, Test Loss: 2.2644\n",
      "Epoch [102/400], Train Loss: 1.4787, Test Loss: 2.1370\n",
      "Epoch [103/400], Train Loss: 1.5779, Test Loss: 2.5829\n",
      "Epoch [104/400], Train Loss: 1.4296, Test Loss: 2.3868\n",
      "Epoch [105/400], Train Loss: 1.3467, Test Loss: 2.7738\n",
      "Epoch [106/400], Train Loss: 1.5226, Test Loss: 2.3460\n",
      "Epoch [107/400], Train Loss: 1.4329, Test Loss: 2.9152\n",
      "Epoch [108/400], Train Loss: 1.5552, Test Loss: 3.0213\n",
      "Epoch [109/400], Train Loss: 1.4766, Test Loss: 2.6351\n",
      "Epoch [110/400], Train Loss: 1.5716, Test Loss: 2.0893\n",
      "Epoch [111/400], Train Loss: 1.4036, Test Loss: 2.3490\n",
      "Epoch [112/400], Train Loss: 1.3967, Test Loss: 2.4190\n",
      "Epoch [113/400], Train Loss: 1.7466, Test Loss: 3.1716\n",
      "Epoch [114/400], Train Loss: 2.4298, Test Loss: 4.6481\n",
      "Epoch [115/400], Train Loss: 2.3943, Test Loss: 3.6148\n",
      "Epoch [116/400], Train Loss: 1.9547, Test Loss: 2.3248\n",
      "Epoch [117/400], Train Loss: 1.3837, Test Loss: 2.3862\n",
      "Epoch [118/400], Train Loss: 1.3136, Test Loss: 2.2482\n",
      "Epoch [119/400], Train Loss: 1.4171, Test Loss: 2.2380\n",
      "Epoch [120/400], Train Loss: 1.5280, Test Loss: 2.4389\n",
      "Epoch [121/400], Train Loss: 1.2744, Test Loss: 2.5889\n",
      "Epoch [122/400], Train Loss: 1.2138, Test Loss: 2.0098\n",
      "Epoch [123/400], Train Loss: 1.3015, Test Loss: 2.0333\n",
      "Epoch [124/400], Train Loss: 1.2279, Test Loss: 2.2243\n",
      "Epoch [125/400], Train Loss: 1.1525, Test Loss: 2.0309\n",
      "Epoch [126/400], Train Loss: 1.0784, Test Loss: 2.1239\n",
      "Epoch [127/400], Train Loss: 1.1931, Test Loss: 2.1755\n",
      "Epoch [128/400], Train Loss: 1.1509, Test Loss: 1.9136\n",
      "Epoch [129/400], Train Loss: 1.1390, Test Loss: 1.9953\n",
      "Epoch [130/400], Train Loss: 1.0883, Test Loss: 2.1903\n",
      "Epoch [131/400], Train Loss: 1.0769, Test Loss: 2.1606\n",
      "Epoch [132/400], Train Loss: 1.0918, Test Loss: 2.0039\n",
      "Epoch [133/400], Train Loss: 1.1614, Test Loss: 2.1576\n",
      "Epoch [134/400], Train Loss: 1.1572, Test Loss: 3.0388\n",
      "Epoch [135/400], Train Loss: 1.1696, Test Loss: 2.2298\n",
      "Epoch [136/400], Train Loss: 4.2823, Test Loss: 12.0879\n",
      "Epoch [137/400], Train Loss: 18.3820, Test Loss: 8.0940\n",
      "Epoch [138/400], Train Loss: 8.2227, Test Loss: 5.2634\n",
      "Epoch [139/400], Train Loss: 3.6553, Test Loss: 4.2144\n",
      "Epoch [140/400], Train Loss: 2.4521, Test Loss: 3.4337\n",
      "Epoch [141/400], Train Loss: 2.0025, Test Loss: 2.8297\n",
      "Epoch [142/400], Train Loss: 2.6319, Test Loss: 4.3858\n",
      "Epoch [143/400], Train Loss: 2.1446, Test Loss: 2.6495\n",
      "Epoch [144/400], Train Loss: 1.5997, Test Loss: 2.5528\n",
      "Epoch [145/400], Train Loss: 1.4542, Test Loss: 2.3070\n",
      "Epoch [146/400], Train Loss: 1.4064, Test Loss: 2.3137\n",
      "Epoch [147/400], Train Loss: 1.4340, Test Loss: 2.3839\n",
      "Epoch [148/400], Train Loss: 1.3593, Test Loss: 2.5716\n",
      "Epoch [149/400], Train Loss: 1.4121, Test Loss: 2.2782\n",
      "Epoch [150/400], Train Loss: 1.2455, Test Loss: 2.1441\n",
      "Epoch [151/400], Train Loss: 1.2468, Test Loss: 2.3903\n",
      "Epoch [152/400], Train Loss: 1.1501, Test Loss: 1.9724\n",
      "Epoch [153/400], Train Loss: 1.0386, Test Loss: 2.2342\n",
      "Epoch [154/400], Train Loss: 1.0789, Test Loss: 2.1924\n",
      "Epoch [155/400], Train Loss: 1.1615, Test Loss: 2.2908\n",
      "Epoch [156/400], Train Loss: 1.1158, Test Loss: 1.9862\n",
      "Epoch [157/400], Train Loss: 1.0112, Test Loss: 2.4226\n",
      "Epoch [158/400], Train Loss: 0.9907, Test Loss: 2.2208\n",
      "Epoch [159/400], Train Loss: 0.9776, Test Loss: 2.2188\n",
      "Epoch [160/400], Train Loss: 1.2409, Test Loss: 2.4453\n",
      "Epoch [161/400], Train Loss: 1.3671, Test Loss: 2.1313\n",
      "Epoch [162/400], Train Loss: 1.0239, Test Loss: 2.0869\n",
      "Epoch [163/400], Train Loss: 0.9495, Test Loss: 1.9872\n",
      "Epoch [164/400], Train Loss: 0.8930, Test Loss: 1.8784\n",
      "Epoch [165/400], Train Loss: 0.9474, Test Loss: 2.0054\n",
      "Epoch [166/400], Train Loss: 0.9060, Test Loss: 1.7744\n",
      "Epoch [167/400], Train Loss: 0.8455, Test Loss: 1.8281\n",
      "Epoch [168/400], Train Loss: 0.8171, Test Loss: 1.9518\n",
      "Epoch [169/400], Train Loss: 0.8619, Test Loss: 1.8256\n",
      "Epoch [170/400], Train Loss: 0.8033, Test Loss: 1.8284\n",
      "Epoch [171/400], Train Loss: 1.2930, Test Loss: 3.9952\n",
      "Epoch [172/400], Train Loss: 2.8341, Test Loss: 3.1630\n",
      "Epoch [173/400], Train Loss: 7.4581, Test Loss: 11.0061\n",
      "Epoch [174/400], Train Loss: 5.0436, Test Loss: 3.9359\n",
      "Epoch [175/400], Train Loss: 2.1450, Test Loss: 2.9374\n",
      "Epoch [176/400], Train Loss: 1.7317, Test Loss: 2.5995\n",
      "Epoch [177/400], Train Loss: 1.2700, Test Loss: 1.8708\n",
      "Epoch [178/400], Train Loss: 1.0891, Test Loss: 1.8660\n",
      "Epoch [179/400], Train Loss: 0.9963, Test Loss: 1.9149\n",
      "Epoch [180/400], Train Loss: 0.9389, Test Loss: 1.8561\n",
      "Epoch [181/400], Train Loss: 1.0454, Test Loss: 1.8167\n",
      "Epoch [182/400], Train Loss: 0.9148, Test Loss: 1.8338\n",
      "Epoch [183/400], Train Loss: 0.8970, Test Loss: 1.7650\n",
      "Epoch [184/400], Train Loss: 0.8770, Test Loss: 2.0239\n",
      "Epoch [185/400], Train Loss: 0.8492, Test Loss: 1.7585\n",
      "Epoch [186/400], Train Loss: 0.8300, Test Loss: 1.9631\n",
      "Epoch [187/400], Train Loss: 0.8176, Test Loss: 1.9175\n",
      "Epoch [188/400], Train Loss: 0.8495, Test Loss: 2.0218\n",
      "Epoch [189/400], Train Loss: 0.7915, Test Loss: 1.9708\n",
      "Epoch [190/400], Train Loss: 0.8168, Test Loss: 1.8902\n",
      "Epoch [191/400], Train Loss: 0.7522, Test Loss: 1.8693\n",
      "Epoch [192/400], Train Loss: 0.8041, Test Loss: 1.6872\n",
      "Epoch [193/400], Train Loss: 0.8138, Test Loss: 2.2750\n",
      "Epoch [194/400], Train Loss: 0.9829, Test Loss: 2.1446\n",
      "Epoch [195/400], Train Loss: 0.7713, Test Loss: 2.3250\n",
      "Epoch [196/400], Train Loss: 0.8421, Test Loss: 1.7342\n",
      "Epoch [197/400], Train Loss: 0.8271, Test Loss: 2.0614\n",
      "Epoch [198/400], Train Loss: 0.8825, Test Loss: 1.8538\n",
      "Epoch [199/400], Train Loss: 0.8004, Test Loss: 1.8862\n",
      "Epoch [200/400], Train Loss: 0.8187, Test Loss: 2.1239\n",
      "Epoch [201/400], Train Loss: 0.7690, Test Loss: 1.7072\n",
      "Epoch [202/400], Train Loss: 0.6985, Test Loss: 1.8538\n",
      "Epoch [203/400], Train Loss: 0.7491, Test Loss: 2.0063\n",
      "Epoch [204/400], Train Loss: 0.7843, Test Loss: 1.9197\n",
      "Epoch [205/400], Train Loss: 0.6669, Test Loss: 1.5953\n",
      "Epoch [206/400], Train Loss: 0.7208, Test Loss: 3.1103\n",
      "Epoch [207/400], Train Loss: 2.9406, Test Loss: 3.3766\n",
      "Epoch [208/400], Train Loss: 1.4255, Test Loss: 1.9913\n",
      "Epoch [209/400], Train Loss: 0.9469, Test Loss: 2.3269\n",
      "Epoch [210/400], Train Loss: 0.8297, Test Loss: 1.7096\n",
      "Epoch [211/400], Train Loss: 0.7621, Test Loss: 1.8936\n",
      "Epoch [212/400], Train Loss: 0.6573, Test Loss: 1.6790\n",
      "Epoch [213/400], Train Loss: 0.6524, Test Loss: 1.7205\n",
      "Epoch [214/400], Train Loss: 0.6769, Test Loss: 1.6606\n",
      "Epoch [215/400], Train Loss: 0.6429, Test Loss: 1.7537\n",
      "Epoch [216/400], Train Loss: 0.6525, Test Loss: 1.6621\n",
      "Epoch [217/400], Train Loss: 0.6628, Test Loss: 1.8272\n",
      "Epoch [218/400], Train Loss: 0.6556, Test Loss: 1.8538\n",
      "Epoch [219/400], Train Loss: 0.5937, Test Loss: 1.7604\n",
      "Epoch [220/400], Train Loss: 0.6273, Test Loss: 1.8274\n",
      "Epoch [221/400], Train Loss: 0.5898, Test Loss: 1.8280\n",
      "Epoch [222/400], Train Loss: 0.6167, Test Loss: 1.8672\n",
      "Epoch [223/400], Train Loss: 0.5474, Test Loss: 1.7694\n",
      "Epoch [224/400], Train Loss: 0.6009, Test Loss: 1.7710\n",
      "Epoch [225/400], Train Loss: 0.5828, Test Loss: 1.9423\n",
      "Epoch [226/400], Train Loss: 0.6147, Test Loss: 1.8970\n",
      "Epoch [227/400], Train Loss: 0.9619, Test Loss: 2.8062\n",
      "Epoch [228/400], Train Loss: 24.2511, Test Loss: 24.7244\n",
      "Epoch [229/400], Train Loss: 12.8306, Test Loss: 6.7936\n",
      "Epoch [230/400], Train Loss: 13.4520, Test Loss: 8.6027\n",
      "Epoch [231/400], Train Loss: 4.9230, Test Loss: 3.9028\n",
      "Epoch [232/400], Train Loss: 2.7428, Test Loss: 2.8114\n",
      "Epoch [233/400], Train Loss: 2.2264, Test Loss: 2.8443\n",
      "Epoch [234/400], Train Loss: 1.9381, Test Loss: 2.2795\n",
      "Epoch [235/400], Train Loss: 1.7548, Test Loss: 2.2831\n",
      "Epoch [236/400], Train Loss: 1.6306, Test Loss: 2.3120\n",
      "Epoch [237/400], Train Loss: 1.5470, Test Loss: 2.1731\n",
      "Epoch [238/400], Train Loss: 1.3848, Test Loss: 2.0659\n",
      "Epoch [239/400], Train Loss: 1.3786, Test Loss: 2.0148\n",
      "Epoch [240/400], Train Loss: 1.2114, Test Loss: 2.0446\n",
      "Epoch [241/400], Train Loss: 1.2129, Test Loss: 1.9655\n",
      "Epoch [242/400], Train Loss: 1.2212, Test Loss: 1.9871\n",
      "Epoch [243/400], Train Loss: 1.1918, Test Loss: 2.0432\n",
      "Epoch [244/400], Train Loss: 1.0683, Test Loss: 2.1181\n",
      "Epoch [245/400], Train Loss: 1.2011, Test Loss: 1.9495\n",
      "Epoch [246/400], Train Loss: 1.0603, Test Loss: 1.8374\n",
      "Epoch [247/400], Train Loss: 1.1545, Test Loss: 1.7796\n",
      "Epoch [248/400], Train Loss: 0.9438, Test Loss: 1.6937\n",
      "Epoch [249/400], Train Loss: 0.9482, Test Loss: 1.8802\n",
      "Epoch [250/400], Train Loss: 0.9711, Test Loss: 2.1048\n",
      "Epoch [251/400], Train Loss: 1.0763, Test Loss: 1.9544\n",
      "Epoch [252/400], Train Loss: 1.0786, Test Loss: 2.2918\n",
      "Epoch [253/400], Train Loss: 1.6573, Test Loss: 2.3191\n",
      "Epoch [254/400], Train Loss: 1.1429, Test Loss: 1.9048\n",
      "Epoch [255/400], Train Loss: 0.9733, Test Loss: 1.7803\n",
      "Epoch [256/400], Train Loss: 0.8953, Test Loss: 1.8289\n",
      "Epoch [257/400], Train Loss: 0.8515, Test Loss: 1.7092\n",
      "Epoch [258/400], Train Loss: 0.8348, Test Loss: 2.0144\n",
      "Epoch [259/400], Train Loss: 1.0474, Test Loss: 1.7548\n",
      "Epoch [260/400], Train Loss: 0.7923, Test Loss: 1.5379\n",
      "Epoch [261/400], Train Loss: 0.7257, Test Loss: 1.5901\n",
      "Epoch [262/400], Train Loss: 0.6697, Test Loss: 1.6207\n",
      "Epoch [263/400], Train Loss: 0.6886, Test Loss: 1.6597\n",
      "Epoch [264/400], Train Loss: 0.7139, Test Loss: 1.6407\n",
      "Epoch [265/400], Train Loss: 0.6670, Test Loss: 1.6642\n",
      "Epoch [266/400], Train Loss: 0.6769, Test Loss: 1.7559\n",
      "Epoch [267/400], Train Loss: 0.6802, Test Loss: 1.6877\n",
      "Epoch [268/400], Train Loss: 0.6804, Test Loss: 1.7228\n",
      "Epoch [269/400], Train Loss: 0.6263, Test Loss: 1.6035\n",
      "Epoch [270/400], Train Loss: 0.5771, Test Loss: 1.5620\n",
      "Epoch [271/400], Train Loss: 0.6805, Test Loss: 1.7387\n",
      "Epoch [272/400], Train Loss: 0.7014, Test Loss: 1.8469\n",
      "Epoch [273/400], Train Loss: 0.6262, Test Loss: 1.5544\n",
      "Epoch [274/400], Train Loss: 0.6784, Test Loss: 1.6907\n",
      "Epoch [275/400], Train Loss: 0.6049, Test Loss: 1.6669\n",
      "Epoch [276/400], Train Loss: 0.6165, Test Loss: 1.6582\n",
      "Epoch [277/400], Train Loss: 0.5939, Test Loss: 1.7378\n",
      "Epoch [278/400], Train Loss: 0.5702, Test Loss: 1.6436\n",
      "Epoch [279/400], Train Loss: 0.5464, Test Loss: 1.5605\n",
      "Epoch [280/400], Train Loss: 0.5391, Test Loss: 1.5950\n",
      "Epoch [281/400], Train Loss: 0.5421, Test Loss: 1.7662\n",
      "Epoch [282/400], Train Loss: 0.6230, Test Loss: 1.5925\n",
      "Epoch [283/400], Train Loss: 0.5989, Test Loss: 1.7195\n",
      "Epoch [284/400], Train Loss: 0.6131, Test Loss: 1.6414\n",
      "Epoch [285/400], Train Loss: 0.5376, Test Loss: 1.5908\n",
      "Epoch [286/400], Train Loss: 0.5841, Test Loss: 1.7143\n",
      "Epoch [287/400], Train Loss: 0.7109, Test Loss: 1.7789\n",
      "Epoch [288/400], Train Loss: 0.6380, Test Loss: 1.5842\n",
      "Epoch [289/400], Train Loss: 0.4610, Test Loss: 1.6589\n",
      "Epoch [290/400], Train Loss: 0.5123, Test Loss: 1.6016\n",
      "Epoch [291/400], Train Loss: 0.4850, Test Loss: 1.5779\n",
      "Epoch [292/400], Train Loss: 0.5151, Test Loss: 1.7974\n",
      "Epoch [293/400], Train Loss: 0.4503, Test Loss: 1.6090\n",
      "Epoch [294/400], Train Loss: 0.4792, Test Loss: 1.7554\n",
      "Epoch [295/400], Train Loss: 0.6214, Test Loss: 1.8923\n",
      "Epoch [296/400], Train Loss: 0.5840, Test Loss: 1.5981\n",
      "Epoch [297/400], Train Loss: 0.5680, Test Loss: 1.9514\n",
      "Epoch [298/400], Train Loss: 0.7770, Test Loss: 1.8564\n",
      "Epoch [299/400], Train Loss: 0.8192, Test Loss: 1.7744\n",
      "Epoch [300/400], Train Loss: 0.6613, Test Loss: 1.9867\n",
      "Epoch [301/400], Train Loss: 0.9932, Test Loss: 1.9417\n",
      "Epoch [302/400], Train Loss: 0.8362, Test Loss: 1.8409\n",
      "Epoch [303/400], Train Loss: 0.5509, Test Loss: 1.6292\n",
      "Epoch [304/400], Train Loss: 0.5650, Test Loss: 1.6402\n",
      "Epoch [305/400], Train Loss: 0.4838, Test Loss: 1.7819\n",
      "Epoch [306/400], Train Loss: 0.4720, Test Loss: 1.7073\n",
      "Epoch [307/400], Train Loss: 0.6053, Test Loss: 1.7418\n",
      "Epoch [308/400], Train Loss: 0.4971, Test Loss: 1.6612\n",
      "Epoch [309/400], Train Loss: 0.4093, Test Loss: 1.6132\n",
      "Epoch [310/400], Train Loss: 0.3888, Test Loss: 1.6242\n",
      "Epoch [311/400], Train Loss: 0.4008, Test Loss: 1.6207\n",
      "Epoch [312/400], Train Loss: 0.4138, Test Loss: 1.6924\n",
      "Epoch [313/400], Train Loss: 0.6673, Test Loss: 1.9542\n",
      "Epoch [314/400], Train Loss: 2.2419, Test Loss: 10.2660\n",
      "Epoch [315/400], Train Loss: 8.2409, Test Loss: 7.9123\n",
      "Epoch [316/400], Train Loss: 6.5105, Test Loss: 9.2073\n",
      "Epoch [317/400], Train Loss: 7.9220, Test Loss: 4.6872\n",
      "Epoch [318/400], Train Loss: 6.9756, Test Loss: 4.7801\n",
      "Epoch [319/400], Train Loss: 2.5841, Test Loss: 3.1120\n",
      "Epoch [320/400], Train Loss: 1.5181, Test Loss: 2.6962\n",
      "Epoch [321/400], Train Loss: 1.3378, Test Loss: 2.4139\n",
      "Epoch [322/400], Train Loss: 1.1370, Test Loss: 2.3560\n",
      "Epoch [323/400], Train Loss: 1.0480, Test Loss: 2.2606\n",
      "Epoch [324/400], Train Loss: 0.9505, Test Loss: 2.1666\n",
      "Epoch [325/400], Train Loss: 0.9070, Test Loss: 2.0703\n",
      "Epoch [326/400], Train Loss: 0.8410, Test Loss: 2.1253\n",
      "Epoch [327/400], Train Loss: 0.7835, Test Loss: 1.8391\n",
      "Epoch [328/400], Train Loss: 0.7080, Test Loss: 2.0335\n",
      "Epoch [329/400], Train Loss: 0.7896, Test Loss: 1.8887\n",
      "Epoch [330/400], Train Loss: 0.6698, Test Loss: 1.9165\n",
      "Epoch [331/400], Train Loss: 0.5997, Test Loss: 1.8543\n",
      "Epoch [332/400], Train Loss: 0.8060, Test Loss: 1.7513\n",
      "Epoch [333/400], Train Loss: 0.6753, Test Loss: 1.8348\n",
      "Epoch [334/400], Train Loss: 0.6088, Test Loss: 1.8023\n",
      "Epoch [335/400], Train Loss: 0.5385, Test Loss: 1.7288\n",
      "Epoch [336/400], Train Loss: 0.5526, Test Loss: 1.7436\n",
      "Epoch [337/400], Train Loss: 0.5292, Test Loss: 1.8693\n",
      "Epoch [338/400], Train Loss: 0.5634, Test Loss: 1.8096\n",
      "Epoch [339/400], Train Loss: 0.4711, Test Loss: 1.7946\n",
      "Epoch [340/400], Train Loss: 0.5236, Test Loss: 1.7556\n",
      "Epoch [341/400], Train Loss: 0.4910, Test Loss: 1.7532\n",
      "Epoch [342/400], Train Loss: 0.4940, Test Loss: 1.7083\n",
      "Epoch [343/400], Train Loss: 0.4498, Test Loss: 1.8358\n",
      "Epoch [344/400], Train Loss: 0.4977, Test Loss: 1.9937\n",
      "Epoch [345/400], Train Loss: 0.4882, Test Loss: 1.9228\n",
      "Epoch [346/400], Train Loss: 0.4646, Test Loss: 1.8682\n",
      "Epoch [347/400], Train Loss: 0.4331, Test Loss: 1.9859\n",
      "Epoch [348/400], Train Loss: 0.4391, Test Loss: 1.6561\n",
      "Epoch [349/400], Train Loss: 0.4194, Test Loss: 1.8632\n",
      "Epoch [350/400], Train Loss: 0.3893, Test Loss: 1.6700\n",
      "Epoch [351/400], Train Loss: 0.3925, Test Loss: 1.7416\n",
      "Epoch [352/400], Train Loss: 0.4104, Test Loss: 1.7808\n",
      "Epoch [353/400], Train Loss: 0.3975, Test Loss: 1.7311\n",
      "Epoch [354/400], Train Loss: 0.3655, Test Loss: 1.6933\n",
      "Epoch [355/400], Train Loss: 0.3717, Test Loss: 1.9000\n",
      "Epoch [356/400], Train Loss: 0.4111, Test Loss: 1.8580\n",
      "Epoch [357/400], Train Loss: 0.4183, Test Loss: 1.8383\n",
      "Epoch [358/400], Train Loss: 0.4054, Test Loss: 1.7662\n",
      "Epoch [359/400], Train Loss: 0.3347, Test Loss: 1.7923\n",
      "Epoch [360/400], Train Loss: 0.3366, Test Loss: 1.8265\n",
      "Epoch [361/400], Train Loss: 0.3300, Test Loss: 1.7474\n",
      "Epoch [362/400], Train Loss: 0.3421, Test Loss: 1.9475\n",
      "Epoch [363/400], Train Loss: 0.3675, Test Loss: 1.8152\n",
      "Epoch [364/400], Train Loss: 0.3425, Test Loss: 1.7662\n",
      "Epoch [365/400], Train Loss: 0.3129, Test Loss: 1.7722\n",
      "Epoch [366/400], Train Loss: 0.3605, Test Loss: 1.7184\n",
      "Epoch [367/400], Train Loss: 0.3571, Test Loss: 1.7278\n",
      "Epoch [368/400], Train Loss: 0.3493, Test Loss: 1.8283\n",
      "Epoch [369/400], Train Loss: 0.3667, Test Loss: 1.6972\n",
      "Epoch [370/400], Train Loss: 0.4086, Test Loss: 1.7411\n",
      "Epoch [371/400], Train Loss: 0.3527, Test Loss: 1.7818\n",
      "Epoch [372/400], Train Loss: 0.3777, Test Loss: 1.8734\n",
      "Epoch [373/400], Train Loss: 0.3303, Test Loss: 1.8988\n",
      "Epoch [374/400], Train Loss: 0.3146, Test Loss: 1.8842\n",
      "Epoch [375/400], Train Loss: 0.3540, Test Loss: 1.8791\n",
      "Epoch [376/400], Train Loss: 0.3599, Test Loss: 1.6672\n",
      "Epoch [377/400], Train Loss: 0.2925, Test Loss: 1.6841\n",
      "Epoch [378/400], Train Loss: 0.3285, Test Loss: 1.7709\n",
      "Epoch [379/400], Train Loss: 0.3133, Test Loss: 1.6659\n",
      "Epoch [380/400], Train Loss: 0.2839, Test Loss: 2.0112\n",
      "Epoch [381/400], Train Loss: 0.3206, Test Loss: 1.6653\n",
      "Epoch [382/400], Train Loss: 0.3288, Test Loss: 1.6601\n",
      "Epoch [383/400], Train Loss: 0.3223, Test Loss: 1.6932\n",
      "Epoch [384/400], Train Loss: 0.3081, Test Loss: 1.8939\n",
      "Epoch [385/400], Train Loss: 0.3839, Test Loss: 1.9427\n",
      "Epoch [386/400], Train Loss: 0.2994, Test Loss: 1.8304\n",
      "Epoch [387/400], Train Loss: 0.2902, Test Loss: 1.7846\n",
      "Epoch [388/400], Train Loss: 0.3052, Test Loss: 1.8193\n",
      "Epoch [389/400], Train Loss: 0.2803, Test Loss: 1.9365\n",
      "Epoch [390/400], Train Loss: 0.2790, Test Loss: 1.7615\n",
      "Epoch [391/400], Train Loss: 0.2846, Test Loss: 1.9291\n",
      "Epoch [392/400], Train Loss: 0.2922, Test Loss: 1.6887\n",
      "Epoch [393/400], Train Loss: 0.2919, Test Loss: 1.8000\n",
      "Epoch [394/400], Train Loss: 0.3045, Test Loss: 1.8172\n",
      "Epoch [395/400], Train Loss: 0.2567, Test Loss: 2.0678\n",
      "Epoch [396/400], Train Loss: 0.2936, Test Loss: 1.7292\n",
      "Epoch [397/400], Train Loss: 1.7207, Test Loss: 7.2889\n",
      "Epoch [398/400], Train Loss: 5.5313, Test Loss: 4.9214\n",
      "Epoch [399/400], Train Loss: 5.1798, Test Loss: 7.4641\n",
      "Epoch [400/400], Train Loss: 2.9318, Test Loss: 3.2255\n"
     ]
    }
   ],
   "source": [
    "#['max_Temp','min_Temp','hum','widdir','wind','rain','sun_Time','sun_Qy','condens_Time','soil_Temp']\n",
    "for x in ['max_Temp','min_Temp','hum','widdir','wind','rain','sun_Time','sun_Qy','condens_Time','soil_Temp']:\n",
    "    df = pd.read_csv(\"data/weather_data_total.csv\")\n",
    "    TARGET = x\n",
    "    df[\"target\"] = df[TARGET].shift(-1*timestamp)\n",
    "    df = df.dropna()\n",
    "    X = df.drop([\"date\",\"target\"], axis=1)\n",
    "    y = df[\"target\"]\n",
    "    time_steps = 200\n",
    "    X_train, y_train = create_dataset(X, y, time_steps)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    X_train = torch.FloatTensor(X_train)\n",
    "    X_test = torch.FloatTensor(X_test)\n",
    "    y_train = torch.FloatTensor(y_train)\n",
    "    y_test = torch.FloatTensor(y_test)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "    # 50일치 데이터를 보고 1일치 데이터를 예측하는 모델이므로 input_size는 X.shape[1]\n",
    "    model = LSTM(X.shape[1], 64, 2, 1)\n",
    "\n",
    "    # 모델 컴파일\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    # 학습 및 평가\n",
    "    num_epochs = 400\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "        test_loss = evaluate(model, test_loader, criterion, device)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "    # 모델 저장\n",
    "    torch.save(model.state_dict(), f\"model_{TARGET}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 예측\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs = X_test\n",
    "    outputs = model(inputs)\n",
    "    predicted = torch.round(outputs)\n",
    "    \n",
    "# 예측 결과를 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(y_test, label=\"True\")\n",
    "plt.plot(predicted, label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.title(TARGET)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/weather_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 최근 날짜로부터 200일까지의 데이터를 모아서 그 다음날 예측하기\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m365\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/weather_data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     df\u001b[38;5;241m.\u001b[39mtail(timestamp) \u001b[38;5;66;03m# 해당 데이터에서 date와 target열을 제거한 다음, 50일치 데이터를 (1,50,10)형태로 갖고오기\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     last_50 \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mtail(timestamp)\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TEXT_017_220_38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TEXT_017_220_38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TEXT_017_220_38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TEXT_017_220_38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TEXT_017_220_38\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/weather_data.csv'"
     ]
    }
   ],
   "source": [
    "# 최근 날짜로부터 200일까지의 데이터를 모아서 그 다음날 예측하기\n",
    "for _ in range(365):\n",
    "    df = pd.read_csv(\"data/weather_data.csv\")\n",
    "    df.tail(timestamp) # 해당 데이터에서 date와 target열을 제거한 다음, 50일치 데이터를 (1,50,10)형태로 갖고오기\n",
    "    last_50 = df.tail(timestamp).drop([\"date\"], axis=1)\n",
    "    last_50 = torch.FloatTensor(last_50.values).unsqueeze(0)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(last_50)\n",
    "        print(output)\n",
    "        print(output.item())\n",
    "        print(f\"Predicted Max Temp for Next Day: {output.item()}\")\n",
    "    #df에 예측값 추가하기\n",
    "    # df[\"date\"].iloc[-1]을 date 타입으로 변환\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    next_date = df[\"date\"].iloc[-1] + pd.DateOffset(days=1)\n",
    "    new_row = pd.DataFrame({\"date\": [next_date], \"max_Temp\": [output.item()]})\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    df.to_csv(\"data/weather_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>max_Temp</th>\n",
       "      <th>min_Temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>widdir</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>sun_Time</th>\n",
       "      <th>sun_Qy</th>\n",
       "      <th>condens_Time</th>\n",
       "      <th>soil_Temp</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 13:00:00</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>66.7</td>\n",
       "      <td>148.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>755.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>27.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-02 13:00:00</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>66.5</td>\n",
       "      <td>175.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>26.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-03 13:00:00</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>41.8</td>\n",
       "      <td>306.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>637.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>25.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-04 13:00:00</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>60.8</td>\n",
       "      <td>293.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>479.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-05 13:00:00</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>65.4</td>\n",
       "      <td>186.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>27.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>2023-04-10 13:00:00</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>20.5</td>\n",
       "      <td>227.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>2023-04-12 13:00:00</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>283.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>504.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>2023-04-13 13:00:00</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>15.9</td>\n",
       "      <td>294.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>2023-04-14 13:00:00</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.4</td>\n",
       "      <td>260.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>2023-04-15 13:00:00</td>\n",
       "      <td>22.391977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1484 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date   max_Temp  min_Temp   hum  widdir  wind  rain  \\\n",
       "0    2017-01-01 13:00:00   6.100000      -6.3  66.7   148.5   0.5   0.0   \n",
       "1    2017-01-02 13:00:00   7.800000      -5.9  66.5   175.1   0.6   0.0   \n",
       "2    2017-01-03 13:00:00   6.500000      -4.1  41.8   306.6   2.5   0.0   \n",
       "3    2017-01-04 13:00:00   8.100000      -5.4  60.8   293.9   1.4   0.0   \n",
       "4    2017-01-05 13:00:00   7.700000      -4.8  65.4   186.1   1.6   0.0   \n",
       "...                  ...        ...       ...   ...     ...   ...   ...   \n",
       "1479 2023-04-10 13:00:00  18.400000      -1.6  20.5   227.4   1.4   0.0   \n",
       "1480 2023-04-12 13:00:00  16.400000       1.0  15.8   283.8   3.5   0.0   \n",
       "1481 2023-04-13 13:00:00  19.100000      -1.5  15.9   294.1   1.9   0.0   \n",
       "1482 2023-04-14 13:00:00  18.400000       4.0  35.4   260.6   0.3   0.0   \n",
       "1483 2023-04-15 13:00:00  22.391977       NaN   NaN     NaN   NaN   NaN   \n",
       "\n",
       "      sun_Time  sun_Qy  condens_Time  soil_Temp  target  \n",
       "0        232.0     4.2         755.0        0.6    27.9  \n",
       "1        118.0     4.0         697.0        0.7    26.8  \n",
       "2        254.0     5.9         637.0        0.8    25.9  \n",
       "3        241.0     5.4         479.0        0.9    22.5  \n",
       "4         29.0     3.0         464.0        1.1    27.6  \n",
       "...        ...     ...           ...        ...     ...  \n",
       "1479     335.0    12.7           0.0       10.6    15.6  \n",
       "1480     344.0    14.3         504.0       12.4    16.6  \n",
       "1481     302.0    10.9           0.0       11.3    21.0  \n",
       "1482     136.0     6.1           0.0       12.0    24.1  \n",
       "1483       NaN     NaN           NaN        NaN     NaN  \n",
       "\n",
       "[1484 rows x 12 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 df의 마지막 날짜 뽑아오기\n",
    "last_date = df[\"date\"].iloc[-1]\n",
    "# 13:00 제거\n",
    "last_date = last_date.split(\" \")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-31\n"
     ]
    }
   ],
   "source": [
    "#last_date에서 1일을 더한 날짜 출력\n",
    "from datetime import datetime, timedelta\n",
    "last_date = datetime.strptime(last_date, \"%Y-%m-%d\")\n",
    "next_date = last_date + timedelta(days=1)\n",
    "next_date = next_date.strftime(\"%Y-%m-%d\")\n",
    "print(next_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TEXT_017_220_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
